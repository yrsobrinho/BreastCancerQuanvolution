{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from pydicom import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from medmnist import BreastMNIST\n",
    "from medmnist import INFO\n",
    "\n",
    "import pennylane as qml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "CUDA: 12.4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BreastMNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "info = INFO['breastmnist']\n",
    "data_flag = 'breastmnist'\n",
    "DataClass = BreastMNIST\n",
    "\n",
    "task = info['task']  \n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "print(f\"Number of classes:\", n_classes)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  \n",
    "    transforms.RandomRotation(degrees=15),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]),\n",
    "    lambda x: x.unsqueeze(0)\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]),\n",
    "    lambda x: x.unsqueeze(0)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Configuration for 28x28 and 64x64 Images**\n",
    "\n",
    "In the following code, the dataset is configured to use images of size 28x28, which is the default setting for the BreastMNIST dataset (and other similar datasets like MedMNIST). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist.npz\n"
     ]
    }
   ],
   "source": [
    "data_train28 = DataClass(split='train', transform=train_transform, download=True)\n",
    "data_test28 = DataClass(split='test', transform=eval_transform, download=True)\n",
    "data_eval28 = DataClass(split='val', transform=eval_transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the case you want to use images of size 64x64, the code can be adjusted to load the dataset with this specific size by setting the `size` parameter to 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist_64.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist_64.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist_64.npz\n"
     ]
    }
   ],
   "source": [
    "data_train64 = DataClass(split='train', transform=train_transform, download=True, size=64)\n",
    "data_test64 = DataClass(split='test', transform=eval_transform, download=True, size=64)\n",
    "data_eval64 = DataClass(split='val', transform=eval_transform, download=True, size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataloader: Train, Test and Validation**\n",
    "\n",
    "The following code snippet demonstrates how to load the training, test, and validation splits of the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of images in training dataset: 546\n",
      "Number of images in test dataset: 156\n",
      "Number of images in validation dataset: 78\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataloader_train = data.DataLoader(dataset=data_train28, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = data.DataLoader(dataset=data_test28, batch_size=batch_size, shuffle=False)\n",
    "dataloader_eval = data.DataLoader(dataset=data_eval28, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nNumber of images in training dataset: {len(data_train28)}\")\n",
    "print(f\"Number of images in test dataset: {len(data_test28)}\")\n",
    "print(f\"Number of images in validation dataset: {len(data_eval28)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Quanvolution**\n",
    "\n",
    "Designed to process an image by applying a quantum circuit to extract features from it. It works similarly to a convolutional layer in a neural network, but instead of using traditional mathematical filters, it leverages a quantum circuit to process small patches of the image and generate new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanvolution(image, circuit, patch_size, n_qubits):\n",
    "    \"\"\"\n",
    "    Perform quanvolution on the input image using the given quantum circuit.\n",
    "    \n",
    "    Args:\n",
    "    - image (ndarray): The input image (2D or 3D with channels).\n",
    "    - circuit (function): The quantum circuit function to extract features.\n",
    "    - patch_size (int): The size of the patches to divide the image into.\n",
    "    - n_qubits (int): Number of qubits in the quantum circuit.\n",
    "    \n",
    "    Returns:\n",
    "    - out (ndarray): The output tensor after quanvolution.\n",
    "    \"\"\"\n",
    "    if image.ndim == 2:\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "    \n",
    "    height_patches = image.shape[0] // patch_size\n",
    "    width_patches = image.shape[1] // patch_size\n",
    "    \n",
    "    out = np.zeros((height_patches, width_patches, n_qubits))\n",
    "    \n",
    "    for j in range(height_patches):\n",
    "        for k in range(width_patches):\n",
    "            patch = []\n",
    "            for i in range(patch_size):\n",
    "                for l in range(patch_size):\n",
    "                    if (j * patch_size + i < image.shape[0]) and (k * patch_size + l < image.shape[1]):\n",
    "                        patch.append(image[j * patch_size + i, k * patch_size + l, 0])\n",
    "                    else:\n",
    "                        patch.append(0)\n",
    "            \n",
    "            q_results = circuit(patch)\n",
    "\n",
    "            # Camada de atenção relacionar os patches e multiplicar atencao pelas features !!!\n",
    "            \n",
    "            for c in range(n_qubits):\n",
    "                out[j, k, c] = q_results[c]\n",
    "    \n",
    "    return out\n",
    "\n",
    "def quanvolution_batch(images, circuit, patch_size, n_qubits):\n",
    "    \"\"\"\n",
    "    Applies quanvolution to a batch of images.\n",
    "\n",
    "    Args:\n",
    "    - images: Input tensor (batch_size, H, W, C).\n",
    "    - circuit: Quantum circuit used for the quanvolution.\n",
    "    - patch_size: Size of the patches used in the quanvolution.\n",
    "    - n_qubits: Number of qubits in the quantum circuit.\n",
    "\n",
    "    Returns:\n",
    "    - Processed tensor after quanvolution.\n",
    "    \"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    processed = [\n",
    "        quanvolution(images[i].detach().cpu().numpy(), circuit, patch_size, n_qubits)\n",
    "        for i in range(batch_size)\n",
    "    ]\n",
    "\n",
    "    processed = np.array(processed)\n",
    "    return torch.tensor(processed, dtype=torch.float32).to(images.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY────────────────┤  <Z>\n",
      "1: ──RY──RY─╭●─────────┤  <Z>\n",
      "2: ──RY──RX─│───RZ──RX─┤  <Z>\n",
      "3: ──RY─────╰X─────────┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "n_layers = 1\n",
    "\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, n_qubits))\n",
    "\n",
    "def get_device(n_qubits):\n",
    "    return qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "def define_circuit(rand_params):\n",
    "    \"\"\"\n",
    "    Define a parametrized quantum circuit with custom layers and RandomLayers.\n",
    "\n",
    "    Args:\n",
    "    - rand_params: Parameters for the circuit layers.\n",
    "\n",
    "    Returns:\n",
    "    - A quantum circuit function (qml.QNode).\n",
    "    \"\"\"\n",
    "    dev = get_device(n_qubits)\n",
    "\n",
    "    @qml.qnode(dev, interface='torch')\n",
    "    def circuit(phi):\n",
    "        for j in range(n_qubits):\n",
    "            qml.RY(np.pi * phi[j], wires=j)\n",
    "\n",
    "        qml.templates.layers.RandomLayers(rand_params, list(range(n_qubits)))\n",
    "\n",
    "        return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]\n",
    "\n",
    "    return circuit\n",
    "\n",
    "rand_circuit = define_circuit(rand_params)\n",
    "\n",
    "phi = np.random.uniform(size=n_qubits)\n",
    "\n",
    "result = rand_circuit(phi)\n",
    "\n",
    "expanded_circuit = rand_circuit.qtape.expand()\n",
    "print(expanded_circuit.draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quanvolution4x1**\n",
    "\n",
    "*4 qubits & 1 quanvolution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quanvolution4x1Model(nn.Module):\n",
    "    def __init__(self, rand_params, output_size = (14, 14), patch_size = 2, n_qubits = 4, num_classes = 2):\n",
    "        \"\"\"\n",
    "        Defines the CNN with quanvolution.\n",
    "\n",
    "        Args:\n",
    "        - rand_params: Parameters of the quantum circuit.\n",
    "        - output_size: Output size after quanvolution.\n",
    "        - n_qubits: Number of qubits in the quantum circuit.\n",
    "        - num_classes: Number of classes for classification.\n",
    "        \"\"\"\n",
    "        super(Quanvolution4x1Model, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_qubits = n_qubits\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.circuit = define_circuit(rand_params)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(output_size[0] * output_size[1] * n_qubits, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Passes the data through the network.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (batch_size, C, H, W).\n",
    "        \n",
    "        Returns:\n",
    "        - Logarithmic probabilities of the classes (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        x = torch.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Quanvolution4x1Model(rand_params).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "\n",
      "[Training]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 1/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6156, Accuracy: 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 2/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.3720, Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 3/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.0143, Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 4/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 15.0812, Accuracy: 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 5/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7574, Accuracy: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 6/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.2496, Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 7/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10.9672, Accuracy: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 8/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.2709, Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 9/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8.1594, Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 10/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.6251, Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 11/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.9223, Accuracy: 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 12/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3288, Accuracy: 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 13/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.9483, Accuracy: 0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 14/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.8448, Accuracy: 0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 15/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.4217, Accuracy: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 16/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.3062, Accuracy: 0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 17/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4241, Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 18/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.2181, Accuracy: 0.000\n",
      "Epoch 1 Training Loss: 6.0848\n",
      "\n",
      "[Validation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 1/3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4386, Accuracy: 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 2/3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7259, Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5741, Accuracy: 0.786\n",
      "\n",
      "Epoch 1 Summary:\n",
      "Train Loss: 6.0848, Val Loss: 1.5795, Accuracy: 0.731, Precision: 0.753, Recall: 0.731, F1: 0.739, AUC: 0.782\n",
      "\n",
      "Epoch 2/20\n",
      "\n",
      "[Training]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 1/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8083, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 2/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.0795, Accuracy: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 3/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.1597, Accuracy: 0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 4/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5000, Accuracy: 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 5/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5245, Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 6/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.8340, Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 7/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.5710, Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 8/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4661, Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 9/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1437, Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 10/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.0968, Accuracy: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 11/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9331, Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 12/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.0794, Accuracy: 0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 13/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.8230, Accuracy: 0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 14/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.6076, Accuracy: 0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 15/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4149, Accuracy: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 16/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5220, Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 17/18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.5301, Accuracy: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 18/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0911, Accuracy: 1.000\n",
      "Epoch 2 Training Loss: 2.7880\n",
      "\n",
      "[Validation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Batches: 0/3"
     ]
    }
   ],
   "source": [
    "last_model_path = \"/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/BreastMNIST/1/last_model.pth\"\n",
    "checkpoint_frequency = 2\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1_scores = []\n",
    "val_aucs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    print(\"\\n[Training]\")\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(dataloader_train, desc=\"Training Batches\", bar_format=\"{desc}: {n}/{total}\")):\n",
    "        images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        batch_accuracy = accuracy_score(\n",
    "            labels.cpu().numpy(), output.argmax(dim=1).cpu().numpy()\n",
    "        )\n",
    "\n",
    "        print(f\"Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.3f}\")\n",
    "\n",
    "    epoch_train_loss = total_loss / len(dataloader_train)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    print(f\"Epoch {epoch + 1} Training Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels, val_predictions = [], []\n",
    "\n",
    "    print(\"\\n[Validation]\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(tqdm(dataloader_eval, desc=\"Validation Batches\", bar_format=\"{desc}: {n}/{total}\")):\n",
    "            images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_labels.append(labels)\n",
    "            val_predictions.append(output)\n",
    "\n",
    "            batch_accuracy = accuracy_score(\n",
    "                labels.cpu().numpy(), output.argmax(dim=1).cpu().numpy()\n",
    "            )\n",
    "            print(f\"Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.3f}\")\n",
    "\n",
    "    epoch_val_loss = val_loss / len(dataloader_eval)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "    val_predictions = torch.cat(val_predictions)\n",
    "\n",
    "    val_accuracy = accuracy_score(\n",
    "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy())\n",
    "    val_precision = precision_score(\n",
    "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(),\n",
    "        average=\"weighted\", zero_division=0)\n",
    "    val_recall = recall_score(\n",
    "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(),\n",
    "        average=\"weighted\", zero_division=0)\n",
    "    val_f1 = f1_score(\n",
    "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(),\n",
    "        average=\"weighted\", zero_division=0)\n",
    "    val_auc = roc_auc_score(\n",
    "        val_labels.cpu().numpy(), val_predictions[:, 1].cpu().numpy())\n",
    "\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1_scores.append(val_f1)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch {epoch + 1} Summary:\\n\"\n",
    "        f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "        f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "        f\"Accuracy: {val_accuracy:.3f}, \"\n",
    "        f\"Precision: {val_precision:.3f}, \"\n",
    "        f\"Recall: {val_recall:.3f}, \"\n",
    "        f\"F1: {val_f1:.3f}, \"\n",
    "        f\"AUC: {val_auc:.3f}\"\n",
    "    )\n",
    "\n",
    "    if (epoch + 1) % checkpoint_frequency == 0:\n",
    "        checkpoint_path = f\"/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/BreastMNIST/1/model_checkpoint_epoch_{epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved.\")\n",
    "\n",
    "torch.save(model.state_dict(), last_model_path)\n",
    "print(\"Last model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='s', color='g')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/BreastMNIST/best_model.pth\"\n",
    "# model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "\n",
    "test_loss = 0.0\n",
    "test_labels, test_predictions = [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()\n",
    "        test_labels.append(labels)\n",
    "        test_predictions.append(output)\n",
    "\n",
    "test_labels = torch.cat(test_labels)\n",
    "test_predictions = torch.cat(test_predictions)\n",
    "\n",
    "test_accuracy = accuracy_score(\n",
    "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy()\n",
    ")\n",
    "test_precision = precision_score(\n",
    "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), \n",
    "    average=\"weighted\", zero_division=0\n",
    ")\n",
    "test_recall = recall_score(\n",
    "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), \n",
    "    average=\"weighted\", zero_division=0\n",
    ")\n",
    "test_f1 = f1_score(\n",
    "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), \n",
    "    average=\"weighted\", zero_division=0\n",
    ")\n",
    "test_auc = roc_auc_score(\n",
    "    test_labels.cpu().numpy(), test_predictions[:, 1].cpu().numpy()\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Test Evaluation:\")\n",
    "print(f\"Test Loss: {test_loss / len(dataloader_test):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
    "    test_labels.cpu().numpy(), test_predictions[:, 1].cpu().numpy()\n",
    ")\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--') \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "dataset_name = \"BreastMNIST\"\n",
    "roc_data = pd.DataFrame({\n",
    "    'Dataset': [dataset_name] * len(false_positive_rate),\n",
    "    'False Positive Rate': false_positive_rate,\n",
    "    'True Positive Rate': true_positive_rate,\n",
    "    'Thresholds': thresholds\n",
    "})\n",
    "roc_data.to_csv(f'/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/BreastMNIST/1/roc_curve_data_{dataset_name}.csv', index=False)\n",
    "\n",
    "print(f\"ROC curve data exported to 'roc_curve_data_{dataset_name}.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), labels=[0, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantumEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
