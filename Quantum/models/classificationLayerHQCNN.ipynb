{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.017426Z",
     "start_time": "2024-08-29T20:17:54.207404Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function, Variable\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.io import read_image\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Qiskit imports\n",
    "import qiskit\n",
    "from qiskit import transpile\n",
    "from qiskit import QuantumCircuit as QiskitQuantumCircuit\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "# Additional libraries\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Qiskit: 1.2.4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {torch.cuda.get_device_name(device)}\")\n",
    "print(f\"Qiskit: {qiskit.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.025396Z",
     "start_time": "2024-08-29T20:17:57.020898Z"
    }
   },
   "outputs": [],
   "source": [
    "class MammoDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True, data_augmentation=False):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Define the base transform\n",
    "        base_transform = [transforms.Resize((250, 250)),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize(mean=[0.3577, 0.3577, 0.3577], std=[0.2662, 0.2662, 0.2662])]\n",
    "        \n",
    "        # Add data augmentation if specified\n",
    "        if train and data_augmentation:\n",
    "            augmentation_transform = [transforms.RandomVerticalFlip(),\n",
    "                                      transforms.GaussianBlur(kernel_size=(3, 3))]\n",
    "            self.transform = transforms.Compose(augmentation_transform + base_transform)\n",
    "        else:\n",
    "            self.transform = transforms.Compose(base_transform)\n",
    "        \n",
    "        # Collect image paths and labels\n",
    "        for label in ['0', '1']:\n",
    "            folder_path = os.path.join(root_dir, label)\n",
    "            self.image_paths.extend([os.path.join(folder_path, img_name) for img_name in os.listdir(folder_path)])\n",
    "            self.labels.extend([int(label)] * len(os.listdir(folder_path)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(torch.nn.Module):\n",
    "    def __init__(self, out_features = 2):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, out_features)\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.036477Z",
     "start_time": "2024-08-29T20:17:57.030381Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuantumCircuit:    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta_0 = qiskit.circuit.Parameter('theta0')\n",
    "        \n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta_0, all_qubits)\n",
    "        #self._circuit.rx(self.theta, all_qubits)\n",
    "        \n",
    "        self._circuit.measure_all()\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "    \n",
    "    def run(self, thetas):\n",
    "        param_values = {\n",
    "            self.theta_0: thetas[0],\n",
    "        }\n",
    "        \n",
    "        bound_circuit = self._circuit.assign_parameters(param_values)\n",
    "        transpiled_circuit = transpile(bound_circuit, self.backend)\n",
    "        job = self.backend.run(transpiled_circuit, shots=self.shots)\n",
    "        \n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        expectations = []\n",
    "\n",
    "        if isinstance(result, list):\n",
    "            for i in result:\n",
    "                counts = np.array(list(i.values()))\n",
    "                states = np.array(list(i.keys())).astype(float)\n",
    "                \n",
    "                # Compute probabilities for each state\n",
    "                probabilities = counts / self.shots\n",
    "                \n",
    "                # Get state expectation\n",
    "                expectation = np.sum(states * probabilities)\n",
    "                expectations.append(expectation)\n",
    "        else:\n",
    "            # If result is not a list, treat it as a single result\n",
    "            counts = np.array(list(result.values()))\n",
    "            states = np.array(list(result.keys())).astype(float)\n",
    "            \n",
    "            probabilities = counts / self.shots\n",
    "            expectation = np.sum(states * probabilities)\n",
    "            expectations.append(expectation)\n",
    "            return np.array(expectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.041872Z",
     "start_time": "2024-08-29T20:17:57.037481Z"
    }
   },
   "outputs": [],
   "source": [
    "class HybridFunction(torch.autograd.Function):\n",
    "    \"\"\" Hybrid quantum-classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "        \n",
    "        # Run the quantum circuit and get the expectation value\n",
    "        expectation_z = ctx.quantum_circuit.run(input.tolist()[0])\n",
    "        \n",
    "        # Ensure the result tensor is created on the same device as the input\n",
    "        result = torch.tensor([expectation_z], device=input.device)\n",
    "        \n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = input.tolist()[0]  # Get the input values as a list\n",
    "        \n",
    "        # Convert input_list to a tensor for arithmetic operations\n",
    "        input_tensor = torch.tensor(input_list, device=input.device)\n",
    "        \n",
    "        shift_value = ctx.shift * torch.ones_like(input_tensor)  # Create a tensor for shift\n",
    "        \n",
    "        shift_right = input_tensor + shift_value\n",
    "        shift_left = input_tensor - shift_value\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(input_tensor)):\n",
    "            expectation_right = ctx.quantum_circuit.run([shift_right[i].item()])\n",
    "            expectation_left  = ctx.quantum_circuit.run([shift_left[i].item()])\n",
    "            \n",
    "            # Compute the gradient as the difference\n",
    "            gradient = expectation_right - expectation_left\n",
    "            gradients.append(gradient)\n",
    "\n",
    "        # Convert the list of gradients to a tensor\n",
    "        gradients = torch.tensor(gradients, device=input.device).float()  # Ensure gradients are on the same device\n",
    "        return gradients * grad_output.float(), None, None\n",
    "\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(n_qubits, backend, shots)\n",
    "        self.shift = shift\n",
    "        \n",
    "    def forward(self, input):\n",
    "        batch_results = []\n",
    "        for i in range(input.shape[0]):\n",
    "            result = HybridFunction.apply(input[i].unsqueeze(0), self.quantum_circuit, self.shift)\n",
    "            batch_results.append(result)\n",
    "        return torch.cat(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.048735Z",
     "start_time": "2024-08-29T20:17:57.041872Z"
    }
   },
   "outputs": [],
   "source": [
    "class qcNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(qcNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 15, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.drop1 = nn.Dropout2d(p=0.2)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(55815, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        sim = Aer.get_backend('aer_simulator_statevector')\n",
    "        self.hybrid = Hybrid(self.fc3.out_features, sim, 1000, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.hybrid(x)\n",
    "        x = torch.cat((x, 1 - x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         # Load pre-trained ResNet50 model\n",
    "#         self.resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "#         # Modify the fully connected layer to match the required output features\n",
    "#         self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 84)\n",
    "        \n",
    "#         self.drop1 = nn.Dropout2d(p=0.2)\n",
    "#         self.drop2 = nn.Dropout2d(p=0.5)\n",
    "#         self.fc1 = nn.Linear(84, 1)\n",
    "#         sim = AerSimulator()\n",
    "#         self.hybrid = Hybrid(self.fc1.out_features, sim, 1000, np.pi / 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.resnet(x)\n",
    "#         x = self.drop1(x)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.hybrid(x)\n",
    "#         x = torch.cat((x, 1 - x), -1)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.054984Z",
     "start_time": "2024-08-29T20:17:57.050739Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/mnt/c/Users/Win10/Desktop/researchData/data/png/train'\n",
    "test_dir = '/mnt/c/Users/Win10/Desktop/researchData/data/png/test'\n",
    "\n",
    "# Instancia os datasets\n",
    "\n",
    "train_dataset = MammoDataset(root_dir=train_dir, data_augmentation=True)\n",
    "test_dataset = MammoDataset(root_dir=test_dir, train=False)\n",
    "\n",
    "# Cria os DataLoaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.844112Z",
     "start_time": "2024-08-29T20:17:57.054984Z"
    }
   },
   "outputs": [],
   "source": [
    "model = qcNet().to(device)\n",
    "loss_func = nn.NLLLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 10\n",
    "loss_list = []\n",
    "thetas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.845117Z",
     "start_time": "2024-08-29T20:17:57.845117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5810, 0.4190],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.5630, 0.4370],\n",
      "        [0.5820, 0.4180],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.5270, 0.4730],\n",
      "        [0.5860, 0.4140],\n",
      "        [0.5520, 0.4480],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.5770, 0.4230],\n",
      "        [0.6070, 0.3930],\n",
      "        [0.5640, 0.4360],\n",
      "        [0.5120, 0.4880],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.5410, 0.4590],\n",
      "        [0.5920, 0.4080],\n",
      "        [0.5510, 0.4490],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.5610, 0.4390],\n",
      "        [0.5830, 0.4170],\n",
      "        [0.6020, 0.3980],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.5330, 0.4670],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.5640, 0.4360],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.5150, 0.4850],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.5810, 0.4190],\n",
      "        [0.5390, 0.4610],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5550, 0.4450],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.5520, 0.4480],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.5520, 0.4480],\n",
      "        [0.5600, 0.4400],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.5320, 0.4680],\n",
      "        [0.5370, 0.4630],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.5270, 0.4730],\n",
      "        [0.5520, 0.4480],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.6060, 0.3940],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.5390, 0.4610],\n",
      "        [0.5760, 0.4240],\n",
      "        [0.5650, 0.4350],\n",
      "        [0.5510, 0.4490],\n",
      "        [0.5690, 0.4310],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5680, 0.4320],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.5690, 0.4310],\n",
      "        [0.5820, 0.4180],\n",
      "        [0.5610, 0.4390],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5590, 0.4410],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5920, 0.4080],\n",
      "        [0.5280, 0.4720],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.5770, 0.4230],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.5600, 0.4400],\n",
      "        [0.5860, 0.4140],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.5610, 0.4390],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.5890, 0.4110],\n",
      "        [0.5680, 0.4320],\n",
      "        [0.5640, 0.4360],\n",
      "        [0.5660, 0.4340],\n",
      "        [0.5640, 0.4360],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.5280, 0.4720],\n",
      "        [0.5620, 0.4380],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.5350, 0.4650],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5520, 0.4480],\n",
      "        [0.5220, 0.4780],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.5920, 0.4080],\n",
      "        [0.5620, 0.4380],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5880, 0.4120],\n",
      "        [0.5280, 0.4720],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.5600, 0.4400],\n",
      "        [0.5450, 0.4550]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.5165\n",
      "tensor([[0.9070, 0.0930],\n",
      "        [0.0910, 0.9090],\n",
      "        [0.3080, 0.6920],\n",
      "        [0.8320, 0.1680],\n",
      "        [0.3870, 0.6130],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9070, 0.0930],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.1720, 0.8280],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.8890, 0.1110],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.5360, 0.4640],\n",
      "        [0.8900, 0.1100],\n",
      "        [0.8930, 0.1070],\n",
      "        [0.6290, 0.3710],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.5130, 0.4870],\n",
      "        [0.6410, 0.3590],\n",
      "        [0.8640, 0.1360],\n",
      "        [0.3200, 0.6800],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.3810, 0.6190],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.2630, 0.7370],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.1460, 0.8540],\n",
      "        [0.6590, 0.3410],\n",
      "        [0.3640, 0.6360],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.8730, 0.1270],\n",
      "        [0.8580, 0.1420],\n",
      "        [0.3110, 0.6890],\n",
      "        [0.8580, 0.1420],\n",
      "        [0.9280, 0.0720],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.9320, 0.0680],\n",
      "        [0.6780, 0.3220],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.1470, 0.8530],\n",
      "        [0.7320, 0.2680],\n",
      "        [0.9250, 0.0750],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.7140, 0.2860],\n",
      "        [0.2930, 0.7070],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.3710, 0.6290],\n",
      "        [0.8090, 0.1910],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.5230, 0.4770],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.0960, 0.9040],\n",
      "        [0.0950, 0.9050],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.2600, 0.7400],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.1370, 0.8630],\n",
      "        [0.8670, 0.1330],\n",
      "        [0.7860, 0.2140],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.1010, 0.8990],\n",
      "        [0.8110, 0.1890],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.4850, 0.5150],\n",
      "        [0.6160, 0.3840],\n",
      "        [0.8900, 0.1100],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.6630, 0.3370],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.5730, 0.4270],\n",
      "        [0.3080, 0.6920],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.1690, 0.8310],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.6630, 0.3370],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.4450, 0.5550],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.3410, 0.6590],\n",
      "        [0.8870, 0.1130],\n",
      "        [0.1590, 0.8410],\n",
      "        [0.3510, 0.6490],\n",
      "        [0.1960, 0.8040],\n",
      "        [0.6840, 0.3160],\n",
      "        [0.2820, 0.7180],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.2440, 0.7560],\n",
      "        [0.7650, 0.2350],\n",
      "        [0.2720, 0.7280]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5209\n",
      "tensor([[0.0300, 0.9700],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.4500, 0.5500],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.3870, 0.6130],\n",
      "        [0.8600, 0.1400],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.2810, 0.7190],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.7190, 0.2810],\n",
      "        [0.0100, 0.9900],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0730, 0.9270],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.9320, 0.0680],\n",
      "        [0.0940, 0.9060],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.6910, 0.3090],\n",
      "        [0.0380, 0.9620],\n",
      "        [0.7840, 0.2160],\n",
      "        [0.8810, 0.1190],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.8510, 0.1490],\n",
      "        [0.2760, 0.7240],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.4820, 0.5180],\n",
      "        [0.3040, 0.6960],\n",
      "        [0.6950, 0.3050],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.4140, 0.5860],\n",
      "        [0.3740, 0.6260],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.6030, 0.3970],\n",
      "        [0.5630, 0.4370],\n",
      "        [0.8500, 0.1500],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.1880, 0.8120],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.1470, 0.8530],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.7550, 0.2450],\n",
      "        [0.8970, 0.1030],\n",
      "        [0.7780, 0.2220],\n",
      "        [0.5220, 0.4780],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.3780, 0.6220],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.2660, 0.7340],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.4570, 0.5430],\n",
      "        [0.3720, 0.6280],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.1200, 0.8800],\n",
      "        [0.7400, 0.2600],\n",
      "        [0.0500, 0.9500],\n",
      "        [0.3660, 0.6340],\n",
      "        [0.7350, 0.2650],\n",
      "        [0.0980, 0.9020],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.2520, 0.7480],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.0010, 0.9990]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.4721\n",
      "Epoch 1/10, Loss: -0.5031750578703704\n",
      "tensor([[0.3610, 0.6390],\n",
      "        [0.2120, 0.7880],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.3890, 0.6110],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.2740, 0.7260],\n",
      "        [0.5270, 0.4730],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.7140, 0.2860],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.7060, 0.2940],\n",
      "        [0.2190, 0.7810],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.3900, 0.6100],\n",
      "        [0.1490, 0.8510],\n",
      "        [0.1240, 0.8760],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.8220, 0.1780],\n",
      "        [0.8010, 0.1990],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.7350, 0.2650],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.7220, 0.2780],\n",
      "        [0.5830, 0.4170],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.8660, 0.1340],\n",
      "        [0.2110, 0.7890],\n",
      "        [0.5090, 0.4910],\n",
      "        [0.0580, 0.9420],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.5280, 0.4720],\n",
      "        [0.1290, 0.8710],\n",
      "        [0.5170, 0.4830],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.3800, 0.6200],\n",
      "        [0.7950, 0.2050],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.1760, 0.8240],\n",
      "        [0.5920, 0.4080],\n",
      "        [0.3430, 0.6570],\n",
      "        [0.0010, 0.9990],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.0300, 0.9700],\n",
      "        [0.3380, 0.6620],\n",
      "        [0.6240, 0.3760],\n",
      "        [0.6120, 0.3880],\n",
      "        [0.8840, 0.1160],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.3660, 0.6340],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.5750, 0.4250],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.3260, 0.6740],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.1890, 0.8110],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.6410, 0.3590],\n",
      "        [0.2730, 0.7270],\n",
      "        [0.9340, 0.0660],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3130, 0.6870],\n",
      "        [0.5290, 0.4710],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.9170, 0.0830],\n",
      "        [0.8800, 0.1200],\n",
      "        [0.8630, 0.1370],\n",
      "        [0.5780, 0.4220],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.7260, 0.2740],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8770, 0.1230],\n",
      "        [0.8380, 0.1620],\n",
      "        [0.6910, 0.3090],\n",
      "        [0.2680, 0.7320],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.5110, 0.4890],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.4370, 0.5630],\n",
      "        [0.3250, 0.6750],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.6170, 0.3830],\n",
      "        [0.8930, 0.1070],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.8090, 0.1910],\n",
      "        [0.5220, 0.4780],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.2870, 0.7130],\n",
      "        [0.6790, 0.3210],\n",
      "        [0.1110, 0.8890],\n",
      "        [0.8440, 0.1560],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.9190, 0.0810],\n",
      "        [0.6720, 0.3280],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.3090, 0.6910],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.5800, 0.4200],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1600, 0.8400],\n",
      "        [0.0780, 0.9220]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4525\n",
      "tensor([[0.3480, 0.6520],\n",
      "        [0.1980, 0.8020],\n",
      "        [0.4530, 0.5470],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.5980, 0.4020],\n",
      "        [0.5220, 0.4780],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.5960, 0.4040],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.1800, 0.8200],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.8060, 0.1940],\n",
      "        [0.7020, 0.2980],\n",
      "        [0.9760, 0.0240],\n",
      "        [0.9080, 0.0920],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.3770, 0.6230],\n",
      "        [0.0910, 0.9090],\n",
      "        [0.3920, 0.6080],\n",
      "        [0.1590, 0.8410],\n",
      "        [0.2370, 0.7630],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.8480, 0.1520],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.3410, 0.6590],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.4150, 0.5850],\n",
      "        [0.6780, 0.3220],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.0890, 0.9110],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.7670, 0.2330],\n",
      "        [0.4670, 0.5330],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.0380, 0.9620],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.2400, 0.7600],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.2240, 0.7760],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.0170, 0.9830],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1940, 0.8060],\n",
      "        [0.6650, 0.3350],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.7890, 0.2110],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.3740, 0.6260],\n",
      "        [0.9310, 0.0690],\n",
      "        [0.2300, 0.7700],\n",
      "        [0.5510, 0.4490],\n",
      "        [0.2200, 0.7800],\n",
      "        [0.6880, 0.3120],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.7340, 0.2660],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.0870, 0.9130],\n",
      "        [0.8680, 0.1320],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.3440, 0.6560],\n",
      "        [0.7120, 0.2880],\n",
      "        [0.6260, 0.3740],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.7020, 0.2980],\n",
      "        [0.3760, 0.6240],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.4510, 0.5490],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.4270, 0.5730],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.3110, 0.6890],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.2050, 0.7950],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.7790, 0.2210],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.1580, 0.8420],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.5370, 0.4630],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.0970, 0.9030],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.2000, 0.8000],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.7880, 0.2120],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.2350, 0.7650],\n",
      "        [0.6750, 0.3250],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.5630, 0.4370],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.0110, 0.9890]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4708\n",
      "tensor([[0.0040, 0.9960],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.2970, 0.7030],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.7070, 0.2930],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.6260, 0.3740],\n",
      "        [0.6770, 0.3230],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.0830, 0.9170],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.5320, 0.4680],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.2430, 0.7570],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.1690, 0.8310],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.8550, 0.1450],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.9370, 0.0630],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.4390, 0.5610],\n",
      "        [0.3270, 0.6730],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.9380, 0.0620],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.7390, 0.2610],\n",
      "        [0.3530, 0.6470],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.8810, 0.1190],\n",
      "        [0.3850, 0.6150],\n",
      "        [0.8860, 0.1140],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.8900, 0.1100],\n",
      "        [0.3480, 0.6520],\n",
      "        [0.7940, 0.2060],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.8590, 0.1410],\n",
      "        [0.8080, 0.1920],\n",
      "        [0.1770, 0.8230],\n",
      "        [0.6850, 0.3150],\n",
      "        [0.4430, 0.5570],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.1750, 0.8250],\n",
      "        [0.2160, 0.7840],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.6110, 0.3890],\n",
      "        [0.5830, 0.4170],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.4930, 0.5070],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.1350, 0.8650]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.4963\n",
      "Epoch 2/10, Loss: -0.4731993634259259\n",
      "tensor([[0.6160, 0.3840],\n",
      "        [0.5800, 0.4200],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1490, 0.8510],\n",
      "        [0.3030, 0.6970],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.7230, 0.2770],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.3730, 0.6270],\n",
      "        [0.7680, 0.2320],\n",
      "        [0.8550, 0.1450],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.1020, 0.8980],\n",
      "        [0.2350, 0.7650],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.9390, 0.0610],\n",
      "        [0.7010, 0.2990],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.3190, 0.6810],\n",
      "        [0.6480, 0.3520],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.7130, 0.2870],\n",
      "        [0.2340, 0.7660],\n",
      "        [0.2940, 0.7060],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.7110, 0.2890],\n",
      "        [0.6940, 0.3060],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.7980, 0.2020],\n",
      "        [0.1590, 0.8410],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.2120, 0.7880],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.5620, 0.4380],\n",
      "        [0.7950, 0.2050],\n",
      "        [0.9350, 0.0650],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.1900, 0.8100],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.9390, 0.0610],\n",
      "        [0.1200, 0.8800],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.2610, 0.7390],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.8140, 0.1860],\n",
      "        [0.8810, 0.1190],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.9300, 0.0700],\n",
      "        [0.7780, 0.2220],\n",
      "        [0.2600, 0.7400],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.7490, 0.2510],\n",
      "        [0.6160, 0.3840],\n",
      "        [0.6270, 0.3730],\n",
      "        [0.7700, 0.2300],\n",
      "        [0.9070, 0.0930],\n",
      "        [0.7030, 0.2970],\n",
      "        [0.5550, 0.4450],\n",
      "        [0.4440, 0.5560],\n",
      "        [0.4320, 0.5680],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.1880, 0.8120],\n",
      "        [0.5980, 0.4020],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.8400, 0.1600],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.1660, 0.8340],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.3470, 0.6530],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.9040, 0.0960],\n",
      "        [0.9630, 0.0370],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0380, 0.9620],\n",
      "        [0.2850, 0.7150],\n",
      "        [0.3140, 0.6860],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1360, 0.8640],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.6550, 0.3450],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.3960, 0.6040],\n",
      "        [0.8940, 0.1060],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.3170, 0.6830],\n",
      "        [0.4490, 0.5510],\n",
      "        [0.1600, 0.8400],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.9670, 0.0330],\n",
      "        [0.8870, 0.1130],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.7950, 0.2050],\n",
      "        [0.8370, 0.1630]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.5226\n",
      "tensor([[0.1640, 0.8360],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.6530, 0.3470],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.6540, 0.3460],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.7450, 0.2550],\n",
      "        [0.1260, 0.8740],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.1940, 0.8060],\n",
      "        [0.3160, 0.6840],\n",
      "        [0.2980, 0.7020],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.1020, 0.8980],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.0300, 0.9700],\n",
      "        [0.3460, 0.6540],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.2330, 0.7670],\n",
      "        [0.7560, 0.2440],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.7940, 0.2060],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.4850, 0.5150],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.8330, 0.1670],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.0380, 0.9620],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.1020, 0.8980],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.4030, 0.5970],\n",
      "        [0.3250, 0.6750],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.5460, 0.4540],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.6110, 0.3890],\n",
      "        [0.8610, 0.1390],\n",
      "        [0.5450, 0.4550],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.6970, 0.3030],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.7100, 0.2900],\n",
      "        [0.2080, 0.7920],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.8080, 0.1920],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.6000, 0.4000],\n",
      "        [0.2480, 0.7520],\n",
      "        [0.6220, 0.3780],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9760, 0.0240],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.4490, 0.5510],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9520, 0.0480],\n",
      "        [0.7320, 0.2680],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8010, 0.1990],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.1300, 0.8700],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.7140, 0.2860],\n",
      "        [0.7240, 0.2760],\n",
      "        [0.3290, 0.6710],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.4570, 0.5430],\n",
      "        [0.1690, 0.8310],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.7910, 0.2090],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.6190, 0.3810],\n",
      "        [0.9500, 0.0500],\n",
      "        [0.1210, 0.8790],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.6760, 0.3240],\n",
      "        [0.6400, 0.3600],\n",
      "        [0.4820, 0.5180],\n",
      "        [0.7090, 0.2910],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.8870, 0.1130],\n",
      "        [0.3550, 0.6450],\n",
      "        [0.0910, 0.9090],\n",
      "        [0.9340, 0.0660],\n",
      "        [0.1980, 0.8020],\n",
      "        [0.9010, 0.0990],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.8720, 0.1280],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.3220, 0.6780],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.2580, 0.7420],\n",
      "        [0.0770, 0.9230],\n",
      "        [0.3220, 0.6780],\n",
      "        [0.9190, 0.0810],\n",
      "        [0.6990, 0.3010],\n",
      "        [0.3830, 0.6170],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.9990, 0.0010]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4737\n",
      "tensor([[0.0840, 0.9160],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.9200, 0.0800],\n",
      "        [0.3490, 0.6510],\n",
      "        [0.7710, 0.2290],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.2410, 0.7590],\n",
      "        [0.2600, 0.7400],\n",
      "        [0.7350, 0.2650],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.3590, 0.6410],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9180, 0.0820],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.7260, 0.2740],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.4220, 0.5780],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.9560, 0.0440],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.5170, 0.4830],\n",
      "        [0.0760, 0.9240],\n",
      "        [0.9040, 0.0960],\n",
      "        [0.7240, 0.2760],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.1440, 0.8560],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.3220, 0.6780],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.7760, 0.2240],\n",
      "        [0.4990, 0.5010],\n",
      "        [0.9970, 0.0030],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.6550, 0.3450],\n",
      "        [0.8910, 0.1090],\n",
      "        [0.2030, 0.7970],\n",
      "        [0.0370, 0.9630],\n",
      "        [0.5260, 0.4740],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.1310, 0.8690],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.8630, 0.1370],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.2120, 0.7880],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.5750, 0.4250],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.6020, 0.3980],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.1820, 0.8180],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.1460, 0.8540],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.7030, 0.2970],\n",
      "        [0.3740, 0.6260],\n",
      "        [0.1900, 0.8100],\n",
      "        [0.9340, 0.0660]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5300\n",
      "Epoch 3/10, Loss: -0.5087421874999999\n",
      "tensor([[0.0980, 0.9020],\n",
      "        [0.9690, 0.0310],\n",
      "        [0.3490, 0.6510],\n",
      "        [0.3540, 0.6460],\n",
      "        [0.3670, 0.6330],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.7960, 0.2040],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.3150, 0.6850],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.1200, 0.8800],\n",
      "        [0.3420, 0.6580],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.6780, 0.3220],\n",
      "        [0.1640, 0.8360],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.7780, 0.2220],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8970, 0.1030],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.3970, 0.6030],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.4900, 0.5100],\n",
      "        [0.9360, 0.0640],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.3560, 0.6440],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.2670, 0.7330],\n",
      "        [0.7980, 0.2020],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.5280, 0.4720],\n",
      "        [0.2790, 0.7210],\n",
      "        [0.1640, 0.8360],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.2440, 0.7560],\n",
      "        [0.5260, 0.4740],\n",
      "        [0.7620, 0.2380],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.1110, 0.8890],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.2650, 0.7350],\n",
      "        [0.6650, 0.3350],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.8800, 0.1200],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.6550, 0.3450],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.5820, 0.4180],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.1900, 0.8100],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.4160, 0.5840],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.6620, 0.3380],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.8010, 0.1990],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.3800, 0.6200],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9780, 0.0220],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.9670, 0.0330],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.2570, 0.7430],\n",
      "        [0.6720, 0.3280],\n",
      "        [0.6210, 0.3790],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.7360, 0.2640],\n",
      "        [0.3070, 0.6930],\n",
      "        [0.3710, 0.6290],\n",
      "        [0.6310, 0.3690],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.4410, 0.5590],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.9170, 0.0830],\n",
      "        [0.6600, 0.3400],\n",
      "        [0.1620, 0.8380],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.1790, 0.8210],\n",
      "        [0.2860, 0.7140],\n",
      "        [0.7030, 0.2970],\n",
      "        [0.6300, 0.3700],\n",
      "        [0.5840, 0.4160],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.3870, 0.6130],\n",
      "        [0.9550, 0.0450]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.5363\n",
      "tensor([[0.3620, 0.6380],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.2280, 0.7720],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.8330, 0.1670],\n",
      "        [0.2400, 0.7600],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.7820, 0.2180],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9560, 0.0440],\n",
      "        [0.3540, 0.6460],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.3160, 0.6840],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.6900, 0.3100],\n",
      "        [0.8050, 0.1950],\n",
      "        [0.4260, 0.5740],\n",
      "        [0.7440, 0.2560],\n",
      "        [0.7460, 0.2540],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.7340, 0.2660],\n",
      "        [0.7080, 0.2920],\n",
      "        [0.3710, 0.6290],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.3530, 0.6470],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.7000, 0.3000],\n",
      "        [0.2040, 0.7960],\n",
      "        [0.6490, 0.3510],\n",
      "        [0.2920, 0.7080],\n",
      "        [0.8320, 0.1680],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.7660, 0.2340],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.1800, 0.8200],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.3300, 0.6700],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.9760, 0.0240],\n",
      "        [0.3190, 0.6810],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.5270, 0.4730],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.8850, 0.1150],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.4120, 0.5880],\n",
      "        [0.7630, 0.2370],\n",
      "        [0.9200, 0.0800],\n",
      "        [0.6290, 0.3710],\n",
      "        [0.1120, 0.8880],\n",
      "        [0.5210, 0.4790],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.0610, 0.9390],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.8870, 0.1130],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.8360, 0.1640],\n",
      "        [0.8180, 0.1820],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.1990, 0.8010],\n",
      "        [0.6370, 0.3630],\n",
      "        [0.8220, 0.1780],\n",
      "        [0.3900, 0.6100],\n",
      "        [0.4460, 0.5540],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.8350, 0.1650],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.2160, 0.7840],\n",
      "        [0.3140, 0.6860],\n",
      "        [0.1670, 0.8330],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.5320, 0.4680],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0810, 0.9190],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.8990, 0.1010],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.7320, 0.2680],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4740, 0.5260],\n",
      "        [0.8280, 0.1720],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.2900, 0.7100],\n",
      "        [0.2090, 0.7910],\n",
      "        [0.9440, 0.0560],\n",
      "        [0.6850, 0.3150],\n",
      "        [0.6340, 0.3660],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.1390, 0.8610],\n",
      "        [0.6480, 0.3520],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.8730, 0.1270],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.3110, 0.6890]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4716\n",
      "tensor([[0.0020, 0.9980],\n",
      "        [0.6720, 0.3280],\n",
      "        [0.4060, 0.5940],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.4510, 0.5490],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.2640, 0.7360],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.8010, 0.1990],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.4270, 0.5730],\n",
      "        [0.2240, 0.7760],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.7830, 0.2170],\n",
      "        [0.1260, 0.8740],\n",
      "        [0.3490, 0.6510],\n",
      "        [0.6450, 0.3550],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.0500, 0.9500],\n",
      "        [0.4650, 0.5350],\n",
      "        [0.6770, 0.3230],\n",
      "        [0.0970, 0.9030],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.4180, 0.5820],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.4200, 0.5800],\n",
      "        [0.7810, 0.2190],\n",
      "        [0.8810, 0.1190],\n",
      "        [0.1380, 0.8620],\n",
      "        [0.5780, 0.4220],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.1950, 0.8050],\n",
      "        [0.6460, 0.3540],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.6190, 0.3810],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.2480, 0.7520],\n",
      "        [0.8870, 0.1130],\n",
      "        [0.3430, 0.6570],\n",
      "        [0.0340, 0.9660],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.1800, 0.8200],\n",
      "        [0.2570, 0.7430],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.8660, 0.1340],\n",
      "        [0.3350, 0.6650],\n",
      "        [0.0730, 0.9270],\n",
      "        [0.9370, 0.0630],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.1710, 0.8290],\n",
      "        [0.1580, 0.8420],\n",
      "        [0.4430, 0.5570],\n",
      "        [0.0000, 1.0000]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5004\n",
      "Epoch 4/10, Loss: -0.5027919560185184\n",
      "tensor([[0.5580, 0.4420],\n",
      "        [0.1250, 0.8750],\n",
      "        [0.3260, 0.6740],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.2960, 0.7040],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.6710, 0.3290],\n",
      "        [0.4100, 0.5900],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.6840, 0.3160],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.8650, 0.1350],\n",
      "        [0.8620, 0.1380],\n",
      "        [0.9250, 0.0750],\n",
      "        [0.4720, 0.5280],\n",
      "        [0.6960, 0.3040],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.2940, 0.7060],\n",
      "        [0.4330, 0.5670],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.8950, 0.1050],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.8800, 0.1200],\n",
      "        [0.1260, 0.8740],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.6680, 0.3320],\n",
      "        [0.3920, 0.6080],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.4910, 0.5090],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.2380, 0.7620],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.2280, 0.7720],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.7980, 0.2020],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.9320, 0.0680],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.2020, 0.7980],\n",
      "        [0.3230, 0.6770],\n",
      "        [0.6790, 0.3210],\n",
      "        [0.0700, 0.9300],\n",
      "        [0.3900, 0.6100],\n",
      "        [0.1120, 0.8880],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.8960, 0.1040],\n",
      "        [0.8820, 0.1180],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.6990, 0.3010],\n",
      "        [0.3010, 0.6990],\n",
      "        [0.5240, 0.4760],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.7960, 0.2040],\n",
      "        [0.1890, 0.8110],\n",
      "        [0.7720, 0.2280],\n",
      "        [0.8280, 0.1720],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.6800, 0.3200],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0960, 0.9040],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.4200, 0.5800],\n",
      "        [0.3170, 0.6830],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.7620, 0.2380],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.4830, 0.5170],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.1080, 0.8920],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.3830, 0.6170],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.1470, 0.8530],\n",
      "        [0.9080, 0.0920],\n",
      "        [0.2890, 0.7110],\n",
      "        [0.3950, 0.6050],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.0760, 0.9240],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.1410, 0.8590],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.5770, 0.4230],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.6510, 0.3490],\n",
      "        [0.1820, 0.8180],\n",
      "        [0.8710, 0.1290],\n",
      "        [0.8610, 0.1390],\n",
      "        [0.6620, 0.3380],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.7790, 0.2210],\n",
      "        [0.0390, 0.9610],\n",
      "        [0.9370, 0.0630],\n",
      "        [0.6540, 0.3460],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.5690, 0.4310],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.7990, 0.2010],\n",
      "        [0.7250, 0.2750],\n",
      "        [0.6270, 0.3730],\n",
      "        [0.7070, 0.2930],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.3850, 0.6150],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.3720, 0.6280],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.5010, 0.4990],\n",
      "        [0.8070, 0.1930]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.5288\n",
      "tensor([[0.0170, 0.9830],\n",
      "        [0.4330, 0.5670],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.1810, 0.8190],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.2030, 0.7970],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.2590, 0.7410],\n",
      "        [0.3300, 0.6700],\n",
      "        [0.5670, 0.4330],\n",
      "        [0.8420, 0.1580],\n",
      "        [0.3690, 0.6310],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.9560, 0.0440],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.1360, 0.8640],\n",
      "        [0.1690, 0.8310],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.4200, 0.5800],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.8290, 0.1710],\n",
      "        [0.5270, 0.4730],\n",
      "        [0.4130, 0.5870],\n",
      "        [0.8560, 0.1440],\n",
      "        [0.8630, 0.1370],\n",
      "        [0.8190, 0.1810],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.0640, 0.9360],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.7290, 0.2710],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.8410, 0.1590],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.6790, 0.3210],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.2170, 0.7830],\n",
      "        [0.8750, 0.1250],\n",
      "        [0.3690, 0.6310],\n",
      "        [0.2650, 0.7350],\n",
      "        [0.3850, 0.6150],\n",
      "        [0.7260, 0.2740],\n",
      "        [0.7100, 0.2900],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.3840, 0.6160],\n",
      "        [0.0610, 0.9390],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.6240, 0.3760],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.4820, 0.5180],\n",
      "        [0.8620, 0.1380],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.1200, 0.8800],\n",
      "        [0.6510, 0.3490],\n",
      "        [0.3100, 0.6900],\n",
      "        [0.8950, 0.1050],\n",
      "        [0.9460, 0.0540],\n",
      "        [0.3570, 0.6430],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.4640, 0.5360],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.1850, 0.8150],\n",
      "        [0.2830, 0.7170],\n",
      "        [0.4360, 0.5640],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.9380, 0.0620],\n",
      "        [0.7480, 0.2520],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.9300, 0.0700],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.4250, 0.5750],\n",
      "        [0.8540, 0.1460],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.8920, 0.1080],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.8900, 0.1100],\n",
      "        [0.8200, 0.1800],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.0850, 0.9150],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.3960, 0.6040],\n",
      "        [0.8360, 0.1640],\n",
      "        [0.4570, 0.5430],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.6300, 0.3700],\n",
      "        [0.8930, 0.1070],\n",
      "        [0.6160, 0.3840],\n",
      "        [0.2730, 0.7270],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.3670, 0.6330],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.0760, 0.9240],\n",
      "        [0.6360, 0.3640],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2230, 0.7770]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5633\n",
      "tensor([[0.8270, 0.1730],\n",
      "        [0.2390, 0.7610],\n",
      "        [0.5980, 0.4020],\n",
      "        [0.4550, 0.5450],\n",
      "        [0.6750, 0.3250],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.4170, 0.5830],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.6140, 0.3860],\n",
      "        [0.4170, 0.5830],\n",
      "        [0.4130, 0.5870],\n",
      "        [0.6250, 0.3750],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.1700, 0.8300],\n",
      "        [0.7670, 0.2330],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.8680, 0.1320],\n",
      "        [0.8670, 0.1330],\n",
      "        [0.5970, 0.4030],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.7600, 0.2400],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.5920, 0.4080],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.2650, 0.7350],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.7450, 0.2550],\n",
      "        [0.3970, 0.6030],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.6620, 0.3380],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.0320, 0.9680],\n",
      "        [0.6440, 0.3560],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.0380, 0.9620],\n",
      "        [0.8520, 0.1480],\n",
      "        [0.6630, 0.3370],\n",
      "        [0.0740, 0.9260],\n",
      "        [0.8320, 0.1680],\n",
      "        [0.6230, 0.3770],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.1040, 0.8960],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.5950, 0.4050],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.5310, 0.4690],\n",
      "        [0.5050, 0.4950],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.7970, 0.2030],\n",
      "        [0.5890, 0.4110],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.9900, 0.0100]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.4648\n",
      "Epoch 5/10, Loss: -0.5189742476851852\n",
      "tensor([[0.8270, 0.1730],\n",
      "        [0.2930, 0.7070],\n",
      "        [0.8150, 0.1850],\n",
      "        [0.7640, 0.2360],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.1240, 0.8760],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.5460, 0.4540],\n",
      "        [0.1350, 0.8650],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.6400, 0.3600],\n",
      "        [0.7270, 0.2730],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.9670, 0.0330],\n",
      "        [0.7670, 0.2330],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0940, 0.9060],\n",
      "        [0.6150, 0.3850],\n",
      "        [0.7740, 0.2260],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.9350, 0.0650],\n",
      "        [0.0870, 0.9130],\n",
      "        [0.2260, 0.7740],\n",
      "        [0.8580, 0.1420],\n",
      "        [0.7780, 0.2220],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.7070, 0.2930],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.3200, 0.6800],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.4460, 0.5540],\n",
      "        [0.5550, 0.4450],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.1480, 0.8520],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.8970, 0.1030],\n",
      "        [0.5670, 0.4330],\n",
      "        [0.4530, 0.5470],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.0530, 0.9470],\n",
      "        [0.9380, 0.0620],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.7570, 0.2430],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.8520, 0.1480],\n",
      "        [0.7910, 0.2090],\n",
      "        [0.1340, 0.8660],\n",
      "        [0.4870, 0.5130],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2870, 0.7130],\n",
      "        [0.0770, 0.9230],\n",
      "        [0.7790, 0.2210],\n",
      "        [0.8410, 0.1590],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.3590, 0.6410],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.3780, 0.6220],\n",
      "        [0.2410, 0.7590],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.4170, 0.5830],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.7170, 0.2830],\n",
      "        [0.7390, 0.2610],\n",
      "        [0.8650, 0.1350],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.6240, 0.3760],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.7730, 0.2270],\n",
      "        [0.2490, 0.7510],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.7300, 0.2700],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.8580, 0.1420],\n",
      "        [0.1790, 0.8210],\n",
      "        [0.4710, 0.5290],\n",
      "        [0.3800, 0.6200],\n",
      "        [0.8950, 0.1050],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.6990, 0.3010],\n",
      "        [0.6530, 0.3470],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.1440, 0.8560],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.5050, 0.4950],\n",
      "        [0.3570, 0.6430],\n",
      "        [0.9040, 0.0960],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.3670, 0.6330],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3940, 0.6060],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9730, 0.0270],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.4440, 0.5560],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.3720, 0.6280],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9740, 0.0260],\n",
      "        [0.3070, 0.6930],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.9020, 0.0980]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4665\n",
      "tensor([[0.8310, 0.1690],\n",
      "        [0.7790, 0.2210],\n",
      "        [0.9070, 0.0930],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.7020, 0.2980],\n",
      "        [0.7780, 0.2220],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.4090, 0.5910],\n",
      "        [0.8190, 0.1810],\n",
      "        [0.3820, 0.6180],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.3800, 0.6200],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.8340, 0.1660],\n",
      "        [0.0470, 0.9530],\n",
      "        [0.6460, 0.3540],\n",
      "        [0.7410, 0.2590],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.6650, 0.3350],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.3870, 0.6130],\n",
      "        [0.6620, 0.3380],\n",
      "        [0.1240, 0.8760],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.2930, 0.7070],\n",
      "        [0.7550, 0.2450],\n",
      "        [0.7880, 0.2120],\n",
      "        [0.4260, 0.5740],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.8560, 0.1440],\n",
      "        [0.0990, 0.9010],\n",
      "        [0.8270, 0.1730],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.8920, 0.1080],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.4290, 0.5710],\n",
      "        [0.8840, 0.1160],\n",
      "        [0.8560, 0.1440],\n",
      "        [0.7840, 0.2160],\n",
      "        [0.6170, 0.3830],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.8270, 0.1730],\n",
      "        [0.6640, 0.3360],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.6570, 0.3430],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.4760, 0.5240],\n",
      "        [0.4830, 0.5170],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.6600, 0.3400],\n",
      "        [0.0300, 0.9700],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.8640, 0.1360],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.2580, 0.7420],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0060, 0.9940],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.2060, 0.7940],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.3430, 0.6570],\n",
      "        [0.7090, 0.2910],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.4190, 0.5810],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.4010, 0.5990],\n",
      "        [0.9370, 0.0630],\n",
      "        [0.3190, 0.6810],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.3280, 0.6720],\n",
      "        [0.5840, 0.4160],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.2960, 0.7040],\n",
      "        [0.1340, 0.8660],\n",
      "        [0.2270, 0.7730],\n",
      "        [0.3520, 0.6480],\n",
      "        [0.7750, 0.2250],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.6690, 0.3310],\n",
      "        [0.7280, 0.2720],\n",
      "        [0.6540, 0.3460],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.3380, 0.6620],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.1430, 0.8570],\n",
      "        [0.8520, 0.1480],\n",
      "        [0.4160, 0.5840],\n",
      "        [0.1540, 0.8460],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.5540, 0.4460],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.2400, 0.7600],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.5510, 0.4490],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.6630, 0.3370],\n",
      "        [0.7040, 0.2960],\n",
      "        [0.7860, 0.2140],\n",
      "        [0.3430, 0.6570],\n",
      "        [0.6790, 0.3210],\n",
      "        [0.7760, 0.2240]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5337\n",
      "tensor([[0.4970, 0.5030],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.9010, 0.0990],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.4810, 0.5190],\n",
      "        [0.6110, 0.3890],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.5950, 0.4050],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.5150, 0.4850],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.5620, 0.4380],\n",
      "        [0.2830, 0.7170],\n",
      "        [0.7180, 0.2820],\n",
      "        [0.8380, 0.1620],\n",
      "        [0.8660, 0.1340],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3170, 0.6830],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.7950, 0.2050],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.5860, 0.4140],\n",
      "        [0.7110, 0.2890],\n",
      "        [0.3940, 0.6060],\n",
      "        [0.5650, 0.4350],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.4080, 0.5920],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.7820, 0.2180],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.2410, 0.7590],\n",
      "        [0.9520, 0.0480],\n",
      "        [0.4040, 0.5960],\n",
      "        [0.7960, 0.2040],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.8620, 0.1380],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.6840, 0.3160],\n",
      "        [0.9190, 0.0810],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0720, 0.9280],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0310, 0.9690],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.9680, 0.0320],\n",
      "        [0.5780, 0.4220],\n",
      "        [0.7840, 0.2160],\n",
      "        [0.2330, 0.7670],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.7600, 0.2400],\n",
      "        [0.7370, 0.2630],\n",
      "        [0.9140, 0.0860],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.1460, 0.8540],\n",
      "        [0.8490, 0.1510],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.3520, 0.6480]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5163\n",
      "Epoch 6/10, Loss: -0.5055141782407407\n",
      "tensor([[0.8520, 0.1480],\n",
      "        [0.8250, 0.1750],\n",
      "        [0.9690, 0.0310],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.3040, 0.6960],\n",
      "        [0.3350, 0.6650],\n",
      "        [0.2490, 0.7510],\n",
      "        [0.7210, 0.2790],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.4640, 0.5360],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.4230, 0.5770],\n",
      "        [0.1510, 0.8490],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8840, 0.1160],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.6210, 0.3790],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.0750, 0.9250],\n",
      "        [0.9870, 0.0130],\n",
      "        [0.7440, 0.2560],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.8130, 0.1870],\n",
      "        [0.9070, 0.0930],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.7130, 0.2870],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.5670, 0.4330],\n",
      "        [0.6390, 0.3610],\n",
      "        [0.2750, 0.7250],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.2830, 0.7170],\n",
      "        [0.3480, 0.6520],\n",
      "        [0.1280, 0.8720],\n",
      "        [0.2640, 0.7360],\n",
      "        [0.1830, 0.8170],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.2020, 0.7980],\n",
      "        [0.1110, 0.8890],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.0720, 0.9280],\n",
      "        [0.5380, 0.4620],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1420, 0.8580],\n",
      "        [0.0500, 0.9500],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.3350, 0.6650],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.2490, 0.7510],\n",
      "        [0.7620, 0.2380],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.2430, 0.7570],\n",
      "        [0.5570, 0.4430],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.3370, 0.6630],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.8050, 0.1950],\n",
      "        [0.9320, 0.0680],\n",
      "        [0.8410, 0.1590],\n",
      "        [0.4120, 0.5880],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.5070, 0.4930],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.7860, 0.2140],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.3890, 0.6110],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.4410, 0.5590],\n",
      "        [0.3370, 0.6630],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.6000, 0.4000],\n",
      "        [0.5860, 0.4140],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.6440, 0.3560],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.7170, 0.2830],\n",
      "        [0.7670, 0.2330],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.3350, 0.6650],\n",
      "        [0.8650, 0.1350],\n",
      "        [0.6820, 0.3180],\n",
      "        [0.1360, 0.8640],\n",
      "        [0.9120, 0.0880],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9070, 0.0930],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.4990, 0.5010],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.1920, 0.8080],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.6260, 0.3740],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.5920, 0.4080],\n",
      "        [0.3520, 0.6480],\n",
      "        [0.6840, 0.3160],\n",
      "        [0.4890, 0.5110],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.2050, 0.7950],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.4370, 0.5630],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.5770, 0.4230],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.2360, 0.7640],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.7860, 0.2140],\n",
      "        [0.8020, 0.1980],\n",
      "        [0.0510, 0.9490]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.5010\n",
      "tensor([[0.2080, 0.7920],\n",
      "        [0.9230, 0.0770],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.1870, 0.8130],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.9400, 0.0600],\n",
      "        [0.7750, 0.2250],\n",
      "        [0.1320, 0.8680],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.6940, 0.3060],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.0920, 0.9080],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.5790, 0.4210],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1680, 0.8320],\n",
      "        [0.4750, 0.5250],\n",
      "        [0.0640, 0.9360],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.6010, 0.3990],\n",
      "        [0.7880, 0.2120],\n",
      "        [0.1110, 0.8890],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.2570, 0.7430],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.6040, 0.3960],\n",
      "        [0.7420, 0.2580],\n",
      "        [0.7420, 0.2580],\n",
      "        [0.9200, 0.0800],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.4990, 0.5010],\n",
      "        [0.4440, 0.5560],\n",
      "        [0.0520, 0.9480],\n",
      "        [0.3570, 0.6430],\n",
      "        [0.2380, 0.7620],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.5340, 0.4660],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.1970, 0.8030],\n",
      "        [0.6250, 0.3750],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.0510, 0.9490],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.2560, 0.7440],\n",
      "        [0.6180, 0.3820],\n",
      "        [0.2620, 0.7380],\n",
      "        [0.9180, 0.0820],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.2350, 0.7650],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.3830, 0.6170],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.7390, 0.2610],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.9130, 0.0870],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.5330, 0.4670],\n",
      "        [0.8680, 0.1320],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.0260, 0.9740],\n",
      "        [0.1230, 0.8770],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.8400, 0.1600],\n",
      "        [0.6320, 0.3680],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.4260, 0.5740],\n",
      "        [0.1370, 0.8630],\n",
      "        [0.9270, 0.0730],\n",
      "        [0.1740, 0.8260],\n",
      "        [0.2270, 0.7730],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.3810, 0.6190],\n",
      "        [0.8440, 0.1560],\n",
      "        [0.5630, 0.4370],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.7040, 0.2960],\n",
      "        [0.1870, 0.8130],\n",
      "        [0.4650, 0.5350],\n",
      "        [0.8730, 0.1270],\n",
      "        [0.5780, 0.4220],\n",
      "        [0.6860, 0.3140],\n",
      "        [0.5030, 0.4970],\n",
      "        [0.8310, 0.1690],\n",
      "        [0.8550, 0.1450],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.3610, 0.6390],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.2360, 0.7640],\n",
      "        [0.6300, 0.3700],\n",
      "        [0.9920, 0.0080],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.1740, 0.8260],\n",
      "        [0.3210, 0.6790],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.8720, 0.1280],\n",
      "        [0.4280, 0.5720],\n",
      "        [0.2720, 0.7280],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.5850, 0.4150],\n",
      "        [0.3020, 0.6980],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.0850, 0.9150]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.4536\n",
      "tensor([[0.3860, 0.6140],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.1860, 0.8140],\n",
      "        [0.4460, 0.5540],\n",
      "        [0.2210, 0.7790],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.6640, 0.3360],\n",
      "        [0.9010, 0.0990],\n",
      "        [0.9120, 0.0880],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.6810, 0.3190],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.2840, 0.7160],\n",
      "        [0.8920, 0.1080],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.3260, 0.6740],\n",
      "        [0.7730, 0.2270],\n",
      "        [0.3330, 0.6670],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.5040, 0.4960],\n",
      "        [0.2720, 0.7280],\n",
      "        [0.2830, 0.7170],\n",
      "        [0.7840, 0.2160],\n",
      "        [0.4940, 0.5060],\n",
      "        [0.5800, 0.4200],\n",
      "        [0.5530, 0.4470],\n",
      "        [0.7640, 0.2360],\n",
      "        [0.1490, 0.8510],\n",
      "        [0.8050, 0.1950],\n",
      "        [0.4390, 0.5610],\n",
      "        [0.5050, 0.4950],\n",
      "        [0.9510, 0.0490],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.6210, 0.3790],\n",
      "        [0.2570, 0.7430],\n",
      "        [0.8730, 0.1270],\n",
      "        [0.0440, 0.9560],\n",
      "        [0.3110, 0.6890],\n",
      "        [0.9060, 0.0940],\n",
      "        [0.1540, 0.8460],\n",
      "        [0.3250, 0.6750],\n",
      "        [0.4570, 0.5430],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.3440, 0.6560],\n",
      "        [0.3990, 0.6010],\n",
      "        [0.7370, 0.2630],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.3240, 0.6760],\n",
      "        [0.2230, 0.7770],\n",
      "        [0.3540, 0.6460],\n",
      "        [0.7260, 0.2740],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.7430, 0.2570],\n",
      "        [0.4510, 0.5490],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.1800, 0.8200],\n",
      "        [0.8440, 0.1560]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.4780\n",
      "Epoch 7/10, Loss: -0.47752256944444443\n",
      "tensor([[0.4210, 0.5790],\n",
      "        [0.2150, 0.7850],\n",
      "        [0.7690, 0.2310],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.3110, 0.6890],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.5870, 0.4130],\n",
      "        [0.5900, 0.4100],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8460, 0.1540],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.2650, 0.7350],\n",
      "        [0.7730, 0.2270],\n",
      "        [0.2100, 0.7900],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.6420, 0.3580],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.4930, 0.5070],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.3520, 0.6480],\n",
      "        [0.9110, 0.0890],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.1120, 0.8880],\n",
      "        [0.8440, 0.1560],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.1910, 0.8090],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.5870, 0.4130],\n",
      "        [0.9690, 0.0310],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.4860, 0.5140],\n",
      "        [0.1730, 0.8270],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.8820, 0.1180],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.4150, 0.5850],\n",
      "        [0.3150, 0.6850],\n",
      "        [0.7860, 0.2140],\n",
      "        [0.1340, 0.8660],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.3730, 0.6270],\n",
      "        [0.1020, 0.8980],\n",
      "        [0.2710, 0.7290],\n",
      "        [0.8020, 0.1980],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.7220, 0.2780],\n",
      "        [0.8850, 0.1150],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.1460, 0.8540],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.1640, 0.8360],\n",
      "        [0.9980, 0.0020],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.6210, 0.3790],\n",
      "        [0.4610, 0.5390],\n",
      "        [0.6980, 0.3020],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.8460, 0.1540],\n",
      "        [0.1640, 0.8360],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.0710, 0.9290],\n",
      "        [0.9560, 0.0440],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.6680, 0.3320],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.0340, 0.9660],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4870, 0.5130],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.7000, 0.3000],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.7300, 0.2700],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.7520, 0.2480],\n",
      "        [0.1600, 0.8400],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.8120, 0.1880],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.3850, 0.6150],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.9230, 0.0770],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3980, 0.6020],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7550, 0.2450],\n",
      "        [0.5790, 0.4210],\n",
      "        [0.2920, 0.7080],\n",
      "        [0.3080, 0.6920],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.4300, 0.5700],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.2010, 0.7990],\n",
      "        [0.5630, 0.4370],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9010, 0.0990],\n",
      "        [0.2190, 0.7810],\n",
      "        [0.5190, 0.4810],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.6140, 0.3860],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.6330, 0.3670],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.7710, 0.2290],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.0350, 0.9650],\n",
      "        [0.6550, 0.3450],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.8750, 0.1250],\n",
      "        [0.6150, 0.3850],\n",
      "        [0.8050, 0.1950]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4947\n",
      "tensor([[0.0190, 0.9810],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.8990, 0.1010],\n",
      "        [0.7880, 0.2120],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.1450, 0.8550],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.0870, 0.9130],\n",
      "        [0.2280, 0.7720],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.7630, 0.2370],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4960, 0.5040],\n",
      "        [0.1180, 0.8820],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.3410, 0.6590],\n",
      "        [0.1830, 0.8170],\n",
      "        [0.3460, 0.6540],\n",
      "        [0.7990, 0.2010],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.9770, 0.0230],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1820, 0.8180],\n",
      "        [0.6470, 0.3530],\n",
      "        [0.3900, 0.6100],\n",
      "        [0.9050, 0.0950],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.4360, 0.5640],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.3060, 0.6940],\n",
      "        [0.2110, 0.7890],\n",
      "        [0.5850, 0.4150],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.6640, 0.3360],\n",
      "        [0.4550, 0.5450],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.1030, 0.8970],\n",
      "        [0.0580, 0.9420],\n",
      "        [0.4290, 0.5710],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.2390, 0.7610],\n",
      "        [0.6520, 0.3480],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.2950, 0.7050],\n",
      "        [0.3630, 0.6370],\n",
      "        [0.7010, 0.2990],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1950, 0.8050],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.6830, 0.3170],\n",
      "        [0.8110, 0.1890],\n",
      "        [0.1500, 0.8500],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.6950, 0.3050],\n",
      "        [0.8800, 0.1200],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.9030, 0.0970],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.5940, 0.4060],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.9150, 0.0850],\n",
      "        [0.7950, 0.2050],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.7580, 0.2420],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.2700, 0.7300],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.1630, 0.8370],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.1520, 0.8480],\n",
      "        [0.7210, 0.2790],\n",
      "        [0.7240, 0.2760],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.8720, 0.1280],\n",
      "        [0.0970, 0.9030],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.9120, 0.0880],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.6730, 0.3270],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.2140, 0.7860],\n",
      "        [0.0790, 0.9210],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.0960, 0.9040],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.9910, 0.0090],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.5680, 0.4320],\n",
      "        [0.6290, 0.3710],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.0910, 0.9090],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.0400, 0.9600],\n",
      "        [0.1320, 0.8680],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.2770, 0.7230],\n",
      "        [0.6150, 0.3850],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9670, 0.0330],\n",
      "        [0.0120, 0.9880],\n",
      "        [0.1550, 0.8450]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5289\n",
      "tensor([[0.6190, 0.3810],\n",
      "        [0.8250, 0.1750],\n",
      "        [0.2310, 0.7690],\n",
      "        [0.9320, 0.0680],\n",
      "        [0.8940, 0.1060],\n",
      "        [0.5840, 0.4160],\n",
      "        [0.5870, 0.4130],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.2890, 0.7110],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.4720, 0.5280],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1610, 0.8390],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.7600, 0.2400],\n",
      "        [0.3220, 0.6780],\n",
      "        [0.2770, 0.7230],\n",
      "        [0.2920, 0.7080],\n",
      "        [0.0500, 0.9500],\n",
      "        [0.4390, 0.5610],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.6500, 0.3500],\n",
      "        [0.3890, 0.6110],\n",
      "        [0.1030, 0.8970],\n",
      "        [0.7070, 0.2930],\n",
      "        [0.7180, 0.2820],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.4680, 0.5320],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.8210, 0.1790],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.6830, 0.3170],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.8970, 0.1030],\n",
      "        [0.4560, 0.5440],\n",
      "        [0.0990, 0.9010],\n",
      "        [0.0930, 0.9070],\n",
      "        [0.0300, 0.9700],\n",
      "        [0.2100, 0.7900],\n",
      "        [0.0660, 0.9340],\n",
      "        [0.5550, 0.4450],\n",
      "        [0.1580, 0.8420],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.6730, 0.3270],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.6350, 0.3650],\n",
      "        [0.0910, 0.9090],\n",
      "        [0.3900, 0.6100],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.1750, 0.8250],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.4710, 0.5290],\n",
      "        [0.8260, 0.1740],\n",
      "        [0.5400, 0.4600],\n",
      "        [0.5920, 0.4080],\n",
      "        [0.7230, 0.2770],\n",
      "        [0.9200, 0.0800],\n",
      "        [0.9220, 0.0780],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.8310, 0.1690],\n",
      "        [0.5200, 0.4800],\n",
      "        [0.9320, 0.0680],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.8620, 0.1380],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.3420, 0.6580],\n",
      "        [0.6200, 0.3800]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5391\n",
      "Epoch 8/10, Loss: -0.5208929398148148\n",
      "tensor([[0.3450, 0.6550],\n",
      "        [0.7030, 0.2970],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.4180, 0.5820],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.6740, 0.3260],\n",
      "        [0.3170, 0.6830],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3130, 0.6870],\n",
      "        [0.1920, 0.8080],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.7620, 0.2380],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.7510, 0.2490],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.6450, 0.3550],\n",
      "        [0.7870, 0.2130],\n",
      "        [0.8780, 0.1220],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.9640, 0.0360],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.8750, 0.1250],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.3180, 0.6820],\n",
      "        [0.6650, 0.3350],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.1790, 0.8210],\n",
      "        [0.4640, 0.5360],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.3080, 0.6920],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.6850, 0.3150],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.5240, 0.4760],\n",
      "        [0.8790, 0.1210],\n",
      "        [0.8430, 0.1570],\n",
      "        [0.6300, 0.3700],\n",
      "        [0.3010, 0.6990],\n",
      "        [0.6230, 0.3770],\n",
      "        [0.5790, 0.4210],\n",
      "        [0.1600, 0.8400],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.3300, 0.6700],\n",
      "        [0.5900, 0.4100],\n",
      "        [0.0720, 0.9280],\n",
      "        [0.2220, 0.7780],\n",
      "        [0.7020, 0.2980],\n",
      "        [0.9190, 0.0810],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.1360, 0.8640],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.4140, 0.5860],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.0930, 0.9070],\n",
      "        [0.6870, 0.3130],\n",
      "        [0.8230, 0.1770],\n",
      "        [0.4550, 0.5450],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.2740, 0.7260],\n",
      "        [0.3200, 0.6800],\n",
      "        [0.8840, 0.1160],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.3740, 0.6260],\n",
      "        [0.7460, 0.2540],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9330, 0.0670],\n",
      "        [0.0940, 0.9060],\n",
      "        [0.3780, 0.6220],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.4880, 0.5120],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.6640, 0.3360],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.6610, 0.3390],\n",
      "        [0.3270, 0.6730],\n",
      "        [0.1790, 0.8210],\n",
      "        [0.2400, 0.7600],\n",
      "        [0.9670, 0.0330],\n",
      "        [0.6200, 0.3800],\n",
      "        [0.6460, 0.3540],\n",
      "        [0.0610, 0.9390],\n",
      "        [0.0990, 0.9010],\n",
      "        [0.6070, 0.3930],\n",
      "        [0.2390, 0.7610],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.8390, 0.1610],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.4890, 0.5110],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.3680, 0.6320],\n",
      "        [0.9350, 0.0650],\n",
      "        [0.6950, 0.3050],\n",
      "        [0.5940, 0.4060],\n",
      "        [0.8520, 0.1480],\n",
      "        [0.1080, 0.8920],\n",
      "        [0.1010, 0.8990],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.4520, 0.5480],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.3210, 0.6790],\n",
      "        [0.0470, 0.9530],\n",
      "        [0.1150, 0.8850],\n",
      "        [0.8460, 0.1540],\n",
      "        [0.8900, 0.1100],\n",
      "        [0.9340, 0.0660],\n",
      "        [0.1410, 0.8590],\n",
      "        [0.8940, 0.1060],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0970, 0.9030],\n",
      "        [0.4770, 0.5230]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4793\n",
      "tensor([[0.1020, 0.8980],\n",
      "        [0.6530, 0.3470],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.6830, 0.3170],\n",
      "        [0.2700, 0.7300],\n",
      "        [0.7940, 0.2060],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.8860, 0.1140],\n",
      "        [0.6480, 0.3520],\n",
      "        [0.2020, 0.7980],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.3620, 0.6380],\n",
      "        [0.9140, 0.0860],\n",
      "        [0.0770, 0.9230],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.9670, 0.0330],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.5230, 0.4770],\n",
      "        [0.8460, 0.1540],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.9860, 0.0140],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.0930, 0.9070],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9470, 0.0530],\n",
      "        [0.1240, 0.8760],\n",
      "        [0.8160, 0.1840],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.5130, 0.4870],\n",
      "        [0.6060, 0.3940],\n",
      "        [0.1720, 0.8280],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.7380, 0.2620],\n",
      "        [0.2500, 0.7500],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.6880, 0.3120],\n",
      "        [0.1260, 0.8740],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.6560, 0.3440],\n",
      "        [0.1560, 0.8440],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.0810, 0.9190],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.3250, 0.6750],\n",
      "        [0.0680, 0.9320],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.6060, 0.3940],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.6000, 0.4000],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.7290, 0.2710],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.4230, 0.5770],\n",
      "        [0.8730, 0.1270],\n",
      "        [0.0970, 0.9030],\n",
      "        [0.0410, 0.9590],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.0760, 0.9240],\n",
      "        [0.7570, 0.2430],\n",
      "        [0.6990, 0.3010],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.2380, 0.7620],\n",
      "        [0.6210, 0.3790],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.9530, 0.0470],\n",
      "        [0.2590, 0.7410],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.7260, 0.2740],\n",
      "        [0.1490, 0.8510],\n",
      "        [0.9670, 0.0330],\n",
      "        [0.8290, 0.1710],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.8990, 0.1010],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.9550, 0.0450],\n",
      "        [0.4730, 0.5270],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.6890, 0.3110],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.8030, 0.1970],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.0250, 0.9750],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0170, 0.9830],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.6790, 0.3210],\n",
      "        [0.8330, 0.1670],\n",
      "        [0.0990, 0.9010],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.6630, 0.3370],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.1340, 0.8660],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.8040, 0.1960],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8500, 0.1500],\n",
      "        [0.5680, 0.4320],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.0220, 0.9780],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.2980, 0.7020],\n",
      "        [0.1280, 0.8720],\n",
      "        [0.5550, 0.4450],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1090, 0.8910],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.9850, 0.0150],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.2550, 0.7450]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5232\n",
      "tensor([[0.9730, 0.0270],\n",
      "        [0.5370, 0.4630],\n",
      "        [0.4890, 0.5110],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.0080, 0.9920],\n",
      "        [0.9420, 0.0580],\n",
      "        [0.8570, 0.1430],\n",
      "        [0.6100, 0.3900],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.8660, 0.1340],\n",
      "        [0.7920, 0.2080],\n",
      "        [0.2760, 0.7240],\n",
      "        [0.8250, 0.1750],\n",
      "        [0.8180, 0.1820],\n",
      "        [0.9580, 0.0420],\n",
      "        [0.9250, 0.0750],\n",
      "        [0.5240, 0.4760],\n",
      "        [0.7640, 0.2360],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7330, 0.2670],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.2430, 0.7570],\n",
      "        [0.0090, 0.9910],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0460, 0.9540],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.9800, 0.0200],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.6360, 0.3640],\n",
      "        [0.0230, 0.9770],\n",
      "        [0.6480, 0.3520],\n",
      "        [0.1100, 0.8900],\n",
      "        [0.7210, 0.2790],\n",
      "        [0.9630, 0.0370],\n",
      "        [0.0880, 0.9120],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9630, 0.0370],\n",
      "        [0.3380, 0.6620],\n",
      "        [0.3150, 0.6850],\n",
      "        [0.1190, 0.8810],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.6970, 0.3030],\n",
      "        [0.5720, 0.4280],\n",
      "        [0.3690, 0.6310],\n",
      "        [0.3970, 0.6030],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.8670, 0.1330],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.0330, 0.9670],\n",
      "        [0.4780, 0.5220],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9950, 0.0050],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.3640, 0.6360],\n",
      "        [0.2930, 0.7070],\n",
      "        [0.9600, 0.0400],\n",
      "        [0.4770, 0.5230],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.3100, 0.6900],\n",
      "        [0.4580, 0.5420],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.2180, 0.7820],\n",
      "        [0.8980, 0.1020],\n",
      "        [0.0850, 0.9150],\n",
      "        [0.8370, 0.1630],\n",
      "        [0.4310, 0.5690],\n",
      "        [0.6750, 0.3250],\n",
      "        [0.0870, 0.9130],\n",
      "        [0.5420, 0.4580]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5338\n",
      "Epoch 9/10, Loss: -0.512080150462963\n",
      "tensor([[0.4220, 0.5780],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.9380, 0.0620],\n",
      "        [0.5500, 0.4500],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.9930, 0.0070],\n",
      "        [0.9100, 0.0900],\n",
      "        [0.5880, 0.4120],\n",
      "        [0.0890, 0.9110],\n",
      "        [0.0430, 0.9570],\n",
      "        [0.7640, 0.2360],\n",
      "        [0.9450, 0.0550],\n",
      "        [0.8190, 0.1810],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.2400, 0.7600],\n",
      "        [0.2660, 0.7340],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2610, 0.7390],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9020, 0.0980],\n",
      "        [0.0670, 0.9330],\n",
      "        [0.9170, 0.0830],\n",
      "        [0.2980, 0.7020],\n",
      "        [0.1840, 0.8160],\n",
      "        [0.3280, 0.6720],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.4330, 0.5670],\n",
      "        [0.6600, 0.3400],\n",
      "        [0.8050, 0.1950],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.7770, 0.2230],\n",
      "        [0.9610, 0.0390],\n",
      "        [0.4270, 0.5730],\n",
      "        [0.1910, 0.8090],\n",
      "        [0.4930, 0.5070],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.9120, 0.0880],\n",
      "        [0.2180, 0.7820],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.2120, 0.7880],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.2100, 0.7900],\n",
      "        [0.3480, 0.6520],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.2530, 0.7470],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.4250, 0.5750],\n",
      "        [0.9490, 0.0510],\n",
      "        [0.8710, 0.1290],\n",
      "        [0.9840, 0.0160],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.1390, 0.8610],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0040, 0.9960],\n",
      "        [0.2810, 0.7190],\n",
      "        [0.8890, 0.1110],\n",
      "        [0.3550, 0.6450],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.7200, 0.2800],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.1750, 0.8250],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.9830, 0.0170],\n",
      "        [0.8130, 0.1870],\n",
      "        [0.9970, 0.0030],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0030, 0.9970],\n",
      "        [0.0280, 0.9720],\n",
      "        [0.8770, 0.1230],\n",
      "        [0.6590, 0.3410],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.1780, 0.8220],\n",
      "        [0.4870, 0.5130],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9780, 0.0220],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.8560, 0.1440],\n",
      "        [0.6340, 0.3660],\n",
      "        [0.4050, 0.5950],\n",
      "        [0.2160, 0.7840],\n",
      "        [0.0240, 0.9760],\n",
      "        [0.3910, 0.6090],\n",
      "        [0.4160, 0.5840],\n",
      "        [0.7190, 0.2810],\n",
      "        [0.1780, 0.8220],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.7710, 0.2290],\n",
      "        [0.7670, 0.2330],\n",
      "        [0.0550, 0.9450],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.3350, 0.6650],\n",
      "        [0.4800, 0.5200],\n",
      "        [0.6240, 0.3760],\n",
      "        [0.7030, 0.2970],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.8340, 0.1660],\n",
      "        [0.0130, 0.9870],\n",
      "        [0.8650, 0.1350],\n",
      "        [0.2450, 0.7550],\n",
      "        [0.8690, 0.1310],\n",
      "        [0.7660, 0.2340],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.8700, 0.1300],\n",
      "        [0.2840, 0.7160],\n",
      "        [0.8910, 0.1090],\n",
      "        [0.8250, 0.1750],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.2320, 0.7680],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.7220, 0.2780],\n",
      "        [0.3380, 0.6620],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0170, 0.9830],\n",
      "        [0.1470, 0.8530],\n",
      "        [0.4220, 0.5780],\n",
      "        [0.0850, 0.9150],\n",
      "        [0.9170, 0.0830],\n",
      "        [0.1010, 0.8990]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 1 concluído com loss: -0.4951\n",
      "tensor([[0.6010, 0.3990],\n",
      "        [0.5600, 0.4400],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.7420, 0.2580],\n",
      "        [0.0850, 0.9150],\n",
      "        [0.0110, 0.9890],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.7940, 0.2060],\n",
      "        [0.6090, 0.3910],\n",
      "        [0.8100, 0.1900],\n",
      "        [0.8080, 0.1920],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.2950, 0.7050],\n",
      "        [0.8880, 0.1120],\n",
      "        [0.4970, 0.5030],\n",
      "        [0.8460, 0.1540],\n",
      "        [0.7030, 0.2970],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.0870, 0.9130],\n",
      "        [0.0620, 0.9380],\n",
      "        [0.3210, 0.6790],\n",
      "        [0.5290, 0.4710],\n",
      "        [0.9710, 0.0290],\n",
      "        [0.8120, 0.1880],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.9480, 0.0520],\n",
      "        [0.1310, 0.8690],\n",
      "        [0.2380, 0.7620],\n",
      "        [0.8240, 0.1760],\n",
      "        [0.0360, 0.9640],\n",
      "        [0.1490, 0.8510],\n",
      "        [0.2520, 0.7480],\n",
      "        [0.4450, 0.5550],\n",
      "        [0.0660, 0.9340],\n",
      "        [0.4020, 0.5980],\n",
      "        [0.8170, 0.1830],\n",
      "        [0.9430, 0.0570],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.0110, 0.9890],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.0660, 0.9340],\n",
      "        [0.1430, 0.8570],\n",
      "        [0.9380, 0.0620],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.4410, 0.5590],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.2270, 0.7730],\n",
      "        [0.4590, 0.5410],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.1970, 0.8030],\n",
      "        [0.6470, 0.3530],\n",
      "        [0.6130, 0.3870],\n",
      "        [0.3570, 0.6430],\n",
      "        [0.0250, 0.9750],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.9140, 0.0860],\n",
      "        [0.9170, 0.0830],\n",
      "        [0.0010, 0.9990],\n",
      "        [0.1370, 0.8630],\n",
      "        [0.9250, 0.0750],\n",
      "        [0.4340, 0.5660],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.4100, 0.5900],\n",
      "        [0.0150, 0.9850],\n",
      "        [0.0050, 0.9950],\n",
      "        [0.0310, 0.9690],\n",
      "        [0.3050, 0.6950],\n",
      "        [0.0820, 0.9180],\n",
      "        [0.9520, 0.0480],\n",
      "        [0.1350, 0.8650],\n",
      "        [0.9880, 0.0120],\n",
      "        [0.9160, 0.0840],\n",
      "        [0.9690, 0.0310],\n",
      "        [0.6670, 0.3330],\n",
      "        [0.6910, 0.3090],\n",
      "        [0.4360, 0.5640],\n",
      "        [0.1110, 0.8890],\n",
      "        [0.6360, 0.3640],\n",
      "        [0.4370, 0.5630],\n",
      "        [0.0690, 0.9310],\n",
      "        [0.0270, 0.9730],\n",
      "        [0.1030, 0.8970],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.6080, 0.3920],\n",
      "        [0.7550, 0.2450],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.9990, 0.0010],\n",
      "        [0.7230, 0.2770],\n",
      "        [0.2500, 0.7500],\n",
      "        [0.8820, 0.1180],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.2550, 0.7450],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.5740, 0.4260],\n",
      "        [0.0070, 0.9930],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.5000, 0.5000],\n",
      "        [0.2100, 0.7900],\n",
      "        [0.0190, 0.9810],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.5690, 0.4310],\n",
      "        [0.6050, 0.3950],\n",
      "        [0.1140, 0.8860],\n",
      "        [0.7370, 0.2630],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.9410, 0.0590],\n",
      "        [0.0450, 0.9550],\n",
      "        [0.0140, 0.9860],\n",
      "        [0.1390, 0.8610],\n",
      "        [0.0800, 0.9200],\n",
      "        [0.7150, 0.2850],\n",
      "        [0.1910, 0.8090],\n",
      "        [0.9920, 0.0080],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0290, 0.9710],\n",
      "        [0.2920, 0.7080],\n",
      "        [0.7110, 0.2890],\n",
      "        [0.5650, 0.4350],\n",
      "        [0.1920, 0.8080]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 2 concluído com loss: -0.5054\n",
      "tensor([[0.0000, 1.0000],\n",
      "        [0.8850, 0.1150],\n",
      "        [0.2240, 0.7760],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.0600, 0.9400],\n",
      "        [0.0900, 0.9100],\n",
      "        [0.8580, 0.1420],\n",
      "        [0.0880, 0.9120],\n",
      "        [0.7190, 0.2810],\n",
      "        [0.1330, 0.8670],\n",
      "        [0.0480, 0.9520],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.0900, 0.9100],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.1530, 0.8470],\n",
      "        [0.6840, 0.3160],\n",
      "        [0.1680, 0.8320],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.9700, 0.0300],\n",
      "        [0.0420, 0.9580],\n",
      "        [0.9590, 0.0410],\n",
      "        [0.5880, 0.4120],\n",
      "        [0.9790, 0.0210],\n",
      "        [0.7620, 0.2380],\n",
      "        [0.8740, 0.1260],\n",
      "        [0.2280, 0.7720],\n",
      "        [0.0780, 0.9220],\n",
      "        [0.3700, 0.6300],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.0210, 0.9790],\n",
      "        [0.0590, 0.9410],\n",
      "        [0.7040, 0.2960],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.9650, 0.0350],\n",
      "        [0.1050, 0.8950],\n",
      "        [0.1200, 0.8800],\n",
      "        [0.8470, 0.1530],\n",
      "        [0.9260, 0.0740],\n",
      "        [0.0000, 1.0000],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.3310, 0.6690],\n",
      "        [0.3530, 0.6470],\n",
      "        [0.9900, 0.0100],\n",
      "        [0.4510, 0.5490],\n",
      "        [0.4530, 0.5470],\n",
      "        [0.4070, 0.5930],\n",
      "        [0.0300, 0.9700],\n",
      "        [0.1520, 0.8480],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.3120, 0.6880],\n",
      "        [0.0200, 0.9800],\n",
      "        [0.8830, 0.1170],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.1560, 0.8440],\n",
      "        [0.9300, 0.0700],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.6850, 0.3150],\n",
      "        [0.9720, 0.0280],\n",
      "        [0.5710, 0.4290],\n",
      "        [0.2660, 0.7340],\n",
      "        [1.0000, 0.0000],\n",
      "        [0.0090, 0.9910],\n",
      "        [0.3320, 0.6680],\n",
      "        [0.7390, 0.2610],\n",
      "        [0.4870, 0.5130],\n",
      "        [0.9980, 0.0020],\n",
      "        [0.2130, 0.7870],\n",
      "        [0.1080, 0.8920],\n",
      "        [0.9800, 0.0200]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "  Batch 3 concluído com loss: -0.5087\n",
      "Epoch 10/10, Loss: -0.5030813078703703\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        label = label.unsqueeze(1)\n",
    "        \n",
    "        # Converta os tensores para o tipo correto\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zere os gradientes\n",
    "\n",
    "        # Passe as imagens pelo modelo\n",
    "        prediction = model(image.to(device))\n",
    "\n",
    "        prediction = prediction.to(device)\n",
    "\n",
    "        #Get prediction label from the index with the maximum score\n",
    "        #prediction_label = torch.argmax(prediction, dim=1)\n",
    "        print(prediction)\n",
    "\n",
    "        #prediction_label = prediction_label.unsqueeze(1)\n",
    "        # Calcule a perda\n",
    "        \n",
    "        loss = loss_func(prediction, label.squeeze().long())\n",
    "\n",
    "        # Propagação para trás e atualização dos pesos\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Armazene as informações\n",
    "        total_loss.append(loss.item())\n",
    "        print(f\"  Batch {batch_idx + 1} concluído com loss: {loss.item():.4f}\")\n",
    "        \n",
    "    avg_loss = np.mean(total_loss)\n",
    "    loss_list.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "    model_save_path = f\"model_epoch_{epoch}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Oy111XeE_cm-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3077\n",
      "Recall: 0.4800\n",
      "F1 Score: 0.3750\n",
      "Acurácia: 0.5122\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        label = label.unsqueeze(1)\n",
    "        \n",
    "        # Converta os tensores para o tipo correto\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        # image, label = image.type(dtype=torch.cuda.FloatTensor), label.type(dtype=torch.cuda.LongTensor)\n",
    "        try:\n",
    "            prediction = model(image)\n",
    "            predicted_class = prediction.argmax(dim=1)\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(predicted_class.cpu().numpy())\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calcular acurácia\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Acurácia: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGHCAYAAACposvbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI2UlEQVR4nO3deVxU1f8/8NdlG4ZtFBQRWVRQczcTFRfEUknNpbKPC6m4L4AphoaViJWoH3NPbVHU0rQ+Km5FWgJmroikGWkquEKYOyA4wPn94c/5NoHKDAwz3nk9e9zHwzn33Hved2biPefcc++VhBACRERE9MyzMHYAREREVDmY1ImIiGSCSZ2IiEgmmNSJiIhkgkmdiIhIJpjUiYiIZIJJnYiISCaY1ImIiGSCSZ2IiEgmmNTJqNauXQtJkiBJEpKSkkqtF0LA19cXkiQhMDBQrzZWrFiBtWvX6rRNUlLSY2OqLLNmzYIkSZW+35MnT2LEiBGoV68ebG1t4eDggNatW2P+/Pm4efNmpbf3TydOnECXLl2gUqkgSRIWL15c6W1cv34dLVu2hKurK5YvX46DBw+ifv36ld4O0bPIytgBEAGAo6MjVq9eXSpxJycn4/z583B0dNR73ytWrECNGjUQEhJS7m1at26NQ4cOoUmTJnq3awyff/45Jk6ciEaNGiEyMhJNmjSBWq1GSkoKVq1ahUOHDmHbtm0Ga3/kyJHIy8vDpk2bUL16ddStW7fS29i6dStUKhWioqIwf/58REVF4b///W+lt0P0LGJSJ5MwcOBAbNiwAZ988gmcnJw05atXr4a/vz/u3r1bJXGo1WpIkgQnJye0b9++StqsLIcOHcKECRPQvXt3xMfHQ6FQaNZ1794dU6dORUJCgkFj+O233zBmzBj07NnTYG2MGzcO48aNAwAMGjTIYO0QPYs4/E4mYfDgwQCAr7/+WlN2584dbNmyBSNHjixzm5iYGLRr1w7Ozs5wcnJC69atsXr1avzzGUV169bF6dOnkZycrBnmf9R7fDTE/uWXX2Lq1KmoU6cOFAoFzp07V2r4PTMzU7N9WcvT7N69G61atYJCoUC9evWwYMGCMusJIbBixQq0atUKSqUS1atXx4ABA3DhwoWntjFnzhxIkoTPPvtMK6E/YmNjg759+2pel5SUYP78+XjuueegUCjg6uqKYcOG4cqVK1rbBQYGolmzZjh27Bg6d+4MOzs71K9fH3PnzkVJSQmA/zuNUlRUhJUrV2q9L487zfBom8zMTE3Zvn37EBgYCBcXFyiVSnh5eeH1119Hfn6+pk55Pnddjo9ITthTJ5Pg5OSEAQMGYM2aNZpe2Ndffw0LCwsMHDiwzHOzmZmZGDduHLy8vAAAhw8fRnh4OK5evYqZM2cCALZt24YBAwZApVJhxYoVAFAq4UVFRcHf3x+rVq2ChYUFXF1dkZ2drVWndu3aOHTokFbZ9evX8eabb6JOnTpPPLaffvoJ/fr1g7+/PzZt2oTi4mLMnz8ff/31V6m648aNw9q1azFp0iTMmzcPN2/exOzZs9GhQwf8+uuvqFWrVpltFBcXY9++fXjhhRfg6en5xHgemTBhAj777DOEhYXhlVdeQWZmJt5//30kJSUhNTUVNWrU0NTNzs5GcHAwpk6diujoaGzbtg1RUVFwd3fHsGHD0Lt3bxw6dAj+/v4YMGAApk6dWq4Y/ikzMxO9e/dG586dsWbNGlSrVg1Xr15FQkICHjx4ADs7O029p33uuh4fkWwIIiOKi4sTAMSxY8dEYmKiACB+++03IYQQfn5+IiQkRAghRNOmTUWXLl0eu5/i4mKhVqvF7NmzhYuLiygpKdGse9y2j9oLCAh47LrExMQy28vLyxNt27YVtWvXFpmZmU88xnbt2gl3d3dx//59Tdndu3eFs7Oz+Of/gocOHRIAxMcff6y1/eXLl4VSqRTTpk17bBvZ2dkCgBg0aNATY3kkPT1dABATJ07UKj9y5IgAIGbMmKEp69KliwAgjhw5olW3SZMmIigoSKsMgAgNDdUqi46OFmX9qXn02WdkZAghhPjf//4nAIi0tLRyHYMQj//cdTk+Ijnh8DuZjC5dusDHxwdr1qzBqVOncOzYsccOvQMPh2q7desGlUoFS0tLWFtbY+bMmbhx4wZycnLK3e7rr7+uU5zFxcUYOHAg0tPT8d1338Hb2/uxdfPy8nDs2DG89tprsLW11ZQ7OjqiT58+WnV37doFSZLw5ptvoqioSLO4ubmhZcuWlToTPzExEQBKTR5s27YtGjdujJ9++kmr3M3NDW3bttUqa9GiBS5evFhpMbVq1Qo2NjYYO3Ys1q1b99hTDuX53HU9PiK5YFInkyFJEkaMGIGvvvoKq1atQsOGDdG5c+cy6x49ehQ9evQA8HDG9y+//IJjx47h3XffBQDcv3+/3O3Wrl1bpzjHjx+PhIQE/O9//0OrVq2eWPfWrVsoKSmBm5tbqXX/Lvvrr78ghECtWrVgbW2ttRw+fBh///33Y9upUaMG7OzskJGRUa5juHHjBoCyj93d3V2z/hEXF5dS9RQKhU7v89P4+Pjgxx9/hKurK0JDQ+Hj4wMfHx8sWbJEU6e8n7uux0ckFzynTiYlJCQEM2fOxKpVq/DRRx89tt6mTZtgbW2NXbt2afWA4+PjdW5Tl2vFZ82ahS+++AJxcXGa5PIk1atXhyRJpc7RAyhVVqNGDUiShJ9//rnMiW5llT1iaWmJl156Cd9//z2uXLkCDw+PJ8b1KElnZWWVqnvt2rVKPd/86PMpLCzUOoayfqR07twZnTt3RnFxMVJSUrBs2TJMnjwZtWrVwqBBg8r9uVfl8RGZEvbUyaTUqVMHkZGR6NOnD4YPH/7YepIkwcrKCpaWlpqy+/fv48svvyxVt7J6lKtXr0ZMTAxmz55d7mve7e3t0bZtW2zduhUFBQWa8nv37mHnzp1adV955RUIIXD16lW0adOm1NK8efMnthUVFQUhBMaMGYMHDx6UWq9WqzVtvvjiiwCAr776SqvOsWPHkJ6ejpdeeqlcx1cej642OHnypFb5v4//nywtLdGuXTt88sknAIDU1FQA5f/cq/L4iEwJe+pkcubOnfvUOr1798bChQsxZMgQjB07Fjdu3MCCBQvK7M02b94cmzZtwubNm1G/fn3Y2to+NUH+26FDhzB+/Hh07NgR3bt3x+HDh7XWP+ma9g8++AAvv/yy5lrx4uJizJs3D/b29lp3eOvYsSPGjh2LESNGICUlBQEBAbC3t0dWVhYOHDiA5s2bY8KECY9tx9/fHytXrsTEiRPxwgsvYMKECWjatCnUajVOnDiBzz77DM2aNUOfPn3QqFEjjB07FsuWLYOFhQV69uypmR3u6emJKVOm6PT+PEmvXr3g7OyMUaNGYfbs2bCyssLatWtx+fJlrXqrVq3Cvn370Lt3b3h5eaGgoABr1qwBAHTr1g1A+T/3qjw+IpNi5Il6ZOb+Ofv9Scqawb5mzRrRqFEjoVAoRP369UVsbKxYvXq11oxqIYTIzMwUPXr0EI6OjgKA8Pb2FkL83wz3b7/9tlR7/579/ijOxy1Ps2PHDtGiRQthY2MjvLy8xNy5cx87K3zNmjWiXbt2wt7eXiiVSuHj4yOGDRsmUlJSntqOEEKkpaWJ4cOHCy8vL2FjYyPs7e3F888/L2bOnClycnI09YqLi8W8efNEw4YNhbW1tahRo4Z48803xeXLl7X216VLF9G0adNS7QwfPlzzXj6CMma/CyHE0aNHRYcOHYS9vb2oU6eOiI6OFl988YXWZ3Xo0CHx6quvCm9vb6FQKISLi4vo0qWL2LFjR6n3pzyfe3mPj0hOJCH+dccGIiIieibxnDoREZFMMKkTERHJBJM6ERGRTDCpExERGdjKlSvRokULODk5wcnJCf7+/vj+++8164UQmDVrFtzd3aFUKhEYGIjTp0/r3A6TOhERkYF5eHhg7ty5SElJQUpKCl588UX069dPk7jnz5+PhQsXYvny5Th27Bjc3NzQvXt33Lt3T6d2OPudiIjICJydnfHf//4XI0eOhLu7OyZPnozp06cDeHgHxlq1amHevHmaJ1eWB3vqREREeigsLMTdu3e1lsLCwqduV1xcjE2bNiEvLw/+/v7IyMhAdna21q2nFQoFunTpgoMHD+oUkyzvKKd8PszYIRAZnG1Tf2OHQGRwt74KNuj+K5IvpvergZiYGK2y6OhozJo1q8z6p06dgr+/PwoKCuDg4IBt27ahSZMmmsRdq1Ytrfq1atXS+UmIskzqRERE5SLpP2AdFRWFiIgIrbInPXipUaNGSEtLw+3bt7FlyxYMHz4cycnJ/xfKvx4uJYTQ6YFTAJM6ERGZMx2T5j8pFIonJvF/s7Gxga+vLwCgTZs2OHbsGJYsWaI5j56dna31uOCcnJxSvfen4Tl1IiIyX5KF/ksFCSFQWFiIevXqwc3NDXv37tWse/DgAZKTk9GhQwed9smeOhERkYHNmDEDPXv2hKenJ+7du4dNmzYhKSkJCQkJkCQJkydPxpw5c9CgQQM0aNAAc+bMgZ2dHYYMGaJTO0zqRERkviow/K6Lv/76C0OHDkVWVhZUKhVatGiBhIQEdO/eHQAwbdo03L9/HxMnTsStW7fQrl077NmzB46Ojjq1I8vr1Dn7ncwBZ7+TOTD47Pe2b+u97f2jCyoxksrBnjoREZmvKuqpVxUmdSIiMl+VMOHNlDCpExGR+ZJZT11eP1GIiIjMGHvqRERkvjj8TkREJBMyG35nUiciIvPFnjoREZFMsKdOREQkEzLrqcvraIiIiMwYe+pERGS+ZNZTZ1InIiLzZcFz6kRERPLAnjoREZFMcPY7ERGRTMispy6voyEiIjJj7KkTEZH54vA7ERGRTMhs+J1JnYiIzBd76kRERDLBnjoREZFMyKynLq+fKERERGaMPXUiIjJfMht+l9fREBER6UKS9F90EBsbCz8/Pzg6OsLV1RX9+/fHmTNntOrk5uYiLCwMHh4eUCqVaNy4MVauXKlTO0zqRERkviQL/RcdJCcnIzQ0FIcPH8bevXtRVFSEHj16IC8vT1NnypQpSEhIwFdffYX09HRMmTIF4eHh2L59e7nb4fA7ERGZryoafk9ISNB6HRcXB1dXVxw/fhwBAQEAgEOHDmH48OEIDAwEAIwdOxaffvopUlJS0K9fv3K1w546ERGZrwoMvxcWFuLu3btaS2FhYbmavXPnDgDA2dlZU9apUyfs2LEDV69ehRACiYmJOHv2LIKCgsp9OEzqREREeoiNjYVKpdJaYmNjn7qdEAIRERHo1KkTmjVrpilfunQpmjRpAg8PD9jY2ODll1/GihUr0KlTp3LHxOF3IiIyXxUYfo+KikJERIRWmUKheOp2YWFhOHnyJA4cOKBVvnTpUhw+fBg7duyAt7c39u/fj4kTJ6J27dro1q1buWJiUiciIvNVgZvPKBSKciXxfwoPD8eOHTuwf/9+eHh4aMrv37+PGTNmYNu2bejduzcAoEWLFkhLS8OCBQuY1ImIiJ6qiibKCSEQHh6Obdu2ISkpCfXq1dNar1aroVarYWGhHY+lpSVKSkrK3Q6TOhERma8quk1saGgoNm7ciO3bt8PR0RHZ2dkAAJVKBaVSCScnJ3Tp0gWRkZFQKpXw9vZGcnIy1q9fj4ULF5a7HSZ1IiIyW1IVJfVHN5F5dLnaI3FxcQgJCQEAbNq0CVFRUQgODsbNmzfh7e2Njz76COPHjy93O0zqREREBiaEeGodNzc3xMXFVagdJnUiIjJbVdVTrypM6kREZL7kldOZ1ImIyHyxp05ERCQTTOpEREQyIbekznu/ExERyQR76kREZLbk1lNnUiciIvMlr5zOpE5EROaLPXUDuX37NlavXo309HRIkoTGjRtj1KhRUKlUxg6NiIhkSm5J3SQmyqWkpMDHxweLFi3CzZs38ffff2PRokXw8fFBamqqscMjIiKZkiRJ78UUmURPfcqUKejbty8+//xzWFk9DKmoqAijR4/G5MmTsX//fiNHSEREZPpMIqmnpKRoJXQAsLKywrRp09CmTRsjRkZERHJmqj1ufZnE8LuTkxMuXbpUqvzy5ctwdHQ0QkRERGQWpAosJsgkkvrAgQMxatQobN68GZcvX8aVK1ewadMmjB49GoMHDzZ2eEREJFM8p24ACxYsgCRJGDZsGIqKigAA1tbWmDBhAubOnWvk6IiISK5MNTnryySSuo2NDZYsWYLY2FicP38eQgj4+vrCzs7O2KEREZGMyS2pm8Tw+7p165CXlwc7Ozs0b94cLVq0YEInIiLSkUkk9bfffhuurq4YNGgQdu3apRmCJyIiMihOlKt8WVlZ2Lx5MywtLTFo0CDUrl0bEydOxMGDB40dGhERyZjcJsqZRFK3srLCK6+8gg0bNiAnJweLFy/GxYsX0bVrV/j4+Bg7PCIikim5JXWTmCj3T3Z2dggKCsKtW7dw8eJFpKenGzskIiKSKVNNzvoyiZ46AOTn52PDhg3o1asX3N3dsWjRIvTv3x+//fabsUMjIiKZkltP3SSS+uDBg+Hq6oopU6agXr16SEpKwvnz5/Hhhx+icePGxg6PiIioQmJjY+Hn5wdHR0e4urqif//+OHPmTKl66enp6Nu3L1QqFRwdHdG+ffsy77j6OCYx/C5JEjZv3oygoCCt+78TEREZVBV1uJOTkxEaGgo/Pz8UFRXh3XffRY8ePfD777/D3t4eAHD+/Hl06tQJo0aNQkxMDFQqFdLT02Fra1vudiQhhDDUQRiL8vkwY4dAZHC2Tf2NHQKRwd36Ktig+68zYZve215d+are216/fh2urq5ITk5GQEAAAGDQoEGwtrbGl19+qfd+jdYtXrp0KcaOHQtbW1ssXbr0iXUnTZpURVEREZE5qci58cLCQhQWFmqVKRQKKBSKp257584dAICzszMAoKSkBLt378a0adMQFBSEEydOoF69eoiKikL//v3LHZPReur16tVDSkoKXFxcUK9evcfWkyQJFy5c0Gnf7KmTOWBPncyBoXvqnqHb9d52VM0TiImJ0SqLjo7GrFmznridEAL9+vXDrVu38PPPPwMAsrOzUbt2bdjZ2eHDDz9E165dkZCQgBkzZiAxMRFdunQpV0xG66lnZGSU+W8iIqJnQVRUFCIiIrTKytNLDwsLw8mTJ3HgwAFNWUlJCQCgX79+mDJlCgCgVatWOHjwIFatWlXupG4Ss99nz56N/Pz8UuX379/H7NmzjRARERGZhQrcJlahUMDJyUlreVpSDw8Px44dO5CYmAgPDw9NeY0aNWBlZYUmTZpo1W/cuPGzN/s9JiYG48ePL/UQl/z8fMTExGDmzJlGioweGfNGJ4wZ0Bne7g/P/6RfyMacz77Hnl9+19R5d1wvjHq9I6o5KnHst4uYHLsZ6ReyjRUykc6m9GmKV/w80aC2EwoeFOPon9cxa/MJnMu6p6nzuOHgmV+nYtlu3izrWVNV15sLIRAeHo5t27YhKSmp1GlnGxsb+Pn5lbrM7ezZs/D29i53OyaR1IUQZb6xv/76q2YSARnX1b9u4/1l23H+0t8AgDf7tMO3i8ai/aC5SL+Qjakh3TDpza4YG/0V/ryYg3fGvIzdq8LRov9s5OYXPmXvRKahQ2NXfLH3LE5cuAErSwnvvdEKW6e/hPbTdyK/sBgA0Ch0i9Y23Vq6Y9no9thx9LIxQqYKqqqkHhoaio0bN2L79u1wdHREdvbDDo9KpYJSqQQAREZGYuDAgQgICNCcU9+5cyeSkpLK3Y5RL2mrXr06JEnCnTt34OTkpPXmFhcXIzc3F+PHj8cnn3yi0345Ua5qXE2ahxmL47Eu/hAu7PkIn2xMxMdrfwQA2Fhb4eJPc/Deku1YveUXI0cqT5woZ3gujgqcWzkAvT/Yi4Nncsqs89XkADgordE/9qcqjs48GHqiXN23dum9beaSV8pd93E/HuLi4hASEqJ5vWbNGsTGxuLKlSto1KgRYmJi0K9fv3K3Y9Se+uLFiyGEwMiRIzUX2j9iY2ODunXrwt+ff7hMjYWFhNe7t4a90gZHTmagbh0X1K6pwo+H/tDUeaAuws/Hz6F9y/pM6vTMcrKzBgDcyit7tKmmky16tKqDiZ8eqsqwqBJV5fB7eYwcORIjR47Uux2jJvXhw4cDeHh5W4cOHWBtbW3McOgpmvq6I2ndVNjaWCH3fiEGTv0cf1zIRvuWD88N5dy8p1U/58Y9eNXm6RN6dn0U/AIOnclB+pU7Za4f3Lk+cgvU2JlS/olMRIZkEufU/zlV//79+1Cr1VrrnZycHrttWRf/i5JiSBaWlRsk4WzmX2g3KBbVHO3Q/6VW+Hz2UPQYvUSz/t+/RCWp/L9OiUzNf4f7oalnNfT8YM9j6wR3qY9vD2aiUF1ShZFRpTLN57LozSQuacvPz0dYWBhcXV3h4OCA6tWray1PEhsbC5VKpbUU/XW8iiI3L+qiYly4/DdSf7+Emct24NTZqwgdHIjsv+8CAGq5aP/4qunsWKr3TvQsmDesDXq2roM+c37EtZv3y6zj36gmGrqr8GXSuSqOjioTn9JmAJGRkdi3bx9WrFgBhUKBL774AjExMXB3d8f69eufuG1UVBTu3LmjtVjVeqGKIjdvEiQobKyQefUGsq7fwUvtn9Oss7ayROcXfHH4V93uBkhkbPOHtcErbTzRd85PuHQ977H13uzigxMXbuC3S7erLjiqdHJL6iYx/L5z506sX78egYGBGDlyJDp37gxfX194e3tjw4YNCA5+/OzHsu6zy6H3yhcT1gd7fvkdl7NvwdHeFm8EvYCANg3QN3QFAOCTjYmIHNUD5y7l4Nyl65g2Kgj3C9TY/H2KkSMnKr8FIX4Y4F8XQxYlI7dADVfVw6dj3c1Xo0BdrKnnqLRCv7beeH9jqrFCpUpiorlZbyaR1G/evKm5EN/JyQk3b94EAHTq1AkTJkwwZmj0/7m6OGL1h8PgVsMJd3IL8NufV9E3dAX2HXk44/3jtT/CVmGDxVEDUd3JDsd+y8QrE5bzGnV6pozq1hAAsPu97lrlEz89hK9//r9Rp9fa14UkAVsOZVZleGQAptrj1pdJJPX69esjMzMT3t7eaNKkCb755hu0bdsWO3fuRLVq1YwdHgGYELPxqXU++vQ7fPTpd1UQDZFhVH9zQ7nqrUs8h3WJPJdOpsckzqmPGDECv/76K4CH58gfnVufMmUKIiMjjRwdERHJlSTpv5gik+ipP3oiDQB07doVf/zxB1JSUuDj44OWLVsaMTIiIpIzDr9XAS8vL3h5eRk7DCIikjmZ5XTTSOpLly4ts1ySJNja2sLX1xcBAQGwtOSsdiIiqjwWFvLK6iaR1BctWoTr168jPz8f1atXhxACt2/fhp2dHRwcHJCTk4P69esjMTERnp6exg6XiIhkQm49dZOYKDdnzhz4+fnhzz//xI0bN3Dz5k2cPXsW7dq1w5IlS3Dp0iW4ublpnXsnIiIibSbRU3/vvfewZcsW+Pj4aMp8fX2xYMECvP7667hw4QLmz5+P119/3YhREhGR3HCinAFkZWWhqKioVHlRUZHmQfLu7u64d4/3ESciosojs5xuGsPvXbt2xbhx43DixAlN2YkTJzBhwgS8+OKLAIBTp05p7jpHRERUGeR273eTSOqrV6+Gs7MzXnjhBc293Nu0aQNnZ2esXr0aAODg4ICPP/7YyJESEZGcyC2pm8Twu5ubG/bu3Ys//vgDZ8+ehRACzz33HBo1aqSp07VrVyNGSEREcmSiuVlvJpHUH6lfvz4kSYKPjw+srEwqNCIiIpNnEsPv+fn5GDVqFOzs7NC0aVNcunQJADBp0iTMnTvXyNEREZFcyW343SSSelRUFH799VckJSXB1tZWU96tWzds3rzZiJEREZGc8YEuBhAfH4/Nmzejffv2Wr9+mjRpgvPnzxsxMiIikjNT7XHryySS+vXr1+Hq6lqqPC8vT3ZvOBERmQ65pRiTGH738/PD7t27Na8fJfLPP/8c/v7+xgqLiIhkjufUDSA2NhbvvvsuJkyYgKKiIixZsgTdu3fH2rVr8dFHHxk7PCIiogqJjY2Fn58fHB0d4erqiv79++PMmTOPrT9u3DhIkoTFixfr1I5JJPUOHTrgl19+QX5+Pnx8fLBnzx7UqlULhw4dwgsvvGDs8IiISKaqaqJccnIyQkNDcfjwYezduxdFRUXo0aMH8vLyStWNj4/HkSNH4O7urvPxmMQ5dQBo3rw51q1bZ+wwiIjIjFRkGL2wsBCFhYVaZY/uivpvCQkJWq/j4uLg6uqK48ePIyAgQFN+9epVhIWF4YcffkDv3r11jsmoPXULCwtYWlo+ceFNaIiIyFAq0lOPjY2FSqXSWmJjY8vV7p07dwAAzs7OmrKSkhIMHToUkZGRaNq0qV7HY9SMuW3btseuO3jwIJYtWwYhRBVGRERE5qQiPfWoqChERERolZXVS/83IQQiIiLQqVMnNGvWTFM+b948WFlZYdKkSXrHZNSk3q9fv1Jlf/zxB6KiorBz504EBwfjgw8+MEJkRERkDioyif1xQ+1PExYWhpMnT+LAgQOasuPHj2PJkiVITU2t0A8Nk5goBwDXrl3DmDFj0KJFCxQVFSEtLQ3r1q2Dl5eXsUMjIiKqFOHh4dixYwcSExPh4eGhKf/555+Rk5MDLy8vWFlZwcrKChcvXsTUqVNRt27dcu/f6Ces79y5gzlz5mDZsmVo1aoVfvrpJ3Tu3NnYYRERkRmoquvNhRAIDw/Htm3bkJSUhHr16mmtHzp0KLp166ZVFhQUhKFDh2LEiBHlbseoSX3+/PmYN28e3Nzc8PXXX5c5HE9ERGQoVXUPmdDQUGzcuBHbt2+Ho6MjsrOzAQAqlQpKpRIuLi5wcXHR2sba2hpubm5ajyF/GqMm9XfeeQdKpRK+vr5Yt27dYy9p27p1axVHRkRE5qCqeuorV64EAAQGBmqVx8XFISQkpNLaMWpSHzZsmMneao+IiOSvKoffdZWZmanzNkZN6mvXrjVm80REZObk1q80mdnvREREVDFGn/1ORERkLHI7BcykTkREZktmOZ1JnYiIzBd76kRERDIhs5zOpE5ERObLQmZZnbPfiYiIZII9dSIiMlsy66gzqRMRkfniRDkiIiKZsJBXTmdSJyIi88WeOhERkUzILKdz9jsREZFcsKdORERmS4K8uupM6kREZLY4UY6IiEgmOFGOiIhIJmSW05nUiYjIfPHe70RERGSS2FMnIiKzJbOOOpM6ERGZL06UIyIikgmZ5XSeUyciIvNlIUl6L7qIjY2Fn58fHB0d4erqiv79++PMmTOa9Wq1GtOnT0fz5s1hb28Pd3d3DBs2DNeuXdPteHSqTUREJCNSBRZdJCcnIzQ0FIcPH8bevXtRVFSEHj16IC8vDwCQn5+P1NRUvP/++0hNTcXWrVtx9uxZ9O3bV6d2OPxORERkYAkJCVqv4+Li4OrqiuPHjyMgIAAqlQp79+7VqrNs2TK0bdsWly5dgpeXV7naYVInIiKzVZGJcoWFhSgsLNQqUygUUCgUT932zp07AABnZ+cn1pEkCdWqVSt3TBx+JyIis2Uh6b/ExsZCpVJpLbGxsU9tUwiBiIgIdOrUCc2aNSuzTkFBAd555x0MGTIETk5O5T4e9tSJiMhsVaSnHhUVhYiICK2y8vTSw8LCcPLkSRw4cKDM9Wq1GoMGDUJJSQlWrFihU0xM6kREZLYqcklbeYfa/yk8PBw7duzA/v374eHhUWq9Wq3Gf/7zH2RkZGDfvn069dIBJnUiIjJjVXXzGSEEwsPDsW3bNiQlJaFevXql6jxK6H/++ScSExPh4uKicztM6kRERAYWGhqKjRs3Yvv27XB0dER2djYAQKVSQalUoqioCAMGDEBqaip27dqF4uJiTR1nZ2fY2NiUqx0mdSIiMlsWVXRHuZUrVwIAAgMDtcrj4uIQEhKCK1euYMeOHQCAVq1aadVJTEwstd3jlDupP//88+UepkhNTS3vbomIiIymKoffn6Ru3bpPrVMe5U7q/fv3r3BjREREpkRmt34vf1KPjo42ZBxERERVTtd7uJs63nyGiIhIJvSaKFdcXIxFixbhm2++waVLl/DgwQOt9Tdv3qyU4IiIiAxJZh11/XrqMTExWLhwIf7zn//gzp07iIiIwGuvvQYLCwvMmjWrkkMkIiIyDEmS9F5MkV5JfcOGDfj888/x9ttvw8rKCoMHD8YXX3yBmTNn4vDhw5UdIxERkUFIkv6LKdIrqWdnZ6N58+YAAAcHB83TZl555RXs3r278qIjIiIyIAtJ0nsxRXoldQ8PD2RlZQEAfH19sWfPHgDAsWPHdL4PLhERkbGwpw7g1VdfxU8//QQAeOutt/D++++jQYMGGDZsGEaOHFmpARIREVH56DX7fe7cuZp/DxgwAB4eHjh48CB8fX3Rt2/fSguOiIjIkEx1wpu+JFEZ96UzMTfyiowdApHB2Sv46AaSP1sDf83Dt6Xrve2yVxtXYiSVQ++bz3z55Zfo2LEj3N3dcfHiRQDA4sWLsX379koLjoiIyJB4SRsePm0mIiICvXr1wu3bt1FcXAwAqFatGhYvXlyZ8RERERmMhaT/Yor0SurLli3D559/jnfffReWlpaa8jZt2uDUqVOVFhwREZEhMakDyMjIwPPPP1+qXKFQIC8vr8JBERERke70Sur16tVDWlpaqfLvv/8ejRub3sQBIiKissjtnLpe8wojIyMRGhqKgoICCCFw9OhRfP3115gzZw5Wr15d2TESEREZhKkOo+tLr6Q+YsQIFBUVYdq0acjPz8eQIUNQp04dLFu2DJ07d67sGImIiAzCRDvcetP7krYxY8bg4sWLyMnJQXZ2No4ePYoTJ07A19e3MuMjIiIyGLO+9/vt27cRHByMmjVrwt3dHUuXLoWzszM++eQT+Pr64vDhw1izZo2hYiUiIqpUFhVYTJFOw+8zZszA/v37MXz4cCQkJGDKlClISEhAQUEBvvvuO3Tp0sVQcRIREdFT6JTUd+/ejbi4OHTr1g0TJ06Er68vGjZsyBvOEBHRM8lER9H1plNSv3btGpo0aQIAqF+/PmxtbTF69GiDBEZERGRopnpuXF86nRYoKSmBtbW15rWlpSXs7e0rPSgiIqKqUFXPU4+NjYWfnx8cHR3h6uqK/v3748yZM1p1hBCYNWsW3N3doVQqERgYiNOnT+vUjk49dSEEQkJCoFAoAAAFBQUYP358qcS+detWnYIgIiIyhqq6Tj05ORmhoaHw8/NDUVER3n33XfTo0QO///67JofOnz8fCxcuxNq1a9GwYUN8+OGH6N69O86cOQNHR8dytaPTo1dHjBhRrnpxcXHl3aVB8NGrZA746FUyB4Z+9Orsvef03nZmd/0v4b5+/TpcXV2RnJyMgIAACCHg7u6OyZMnY/r06QCAwsJC1KpVC/PmzcO4cePKtV+d3i5jJ2siIiJTUVhYiMLCQq0yhUKhGc1+kjt37gAAnJ2dATx8pkp2djZ69Oihta8uXbrg4MGD5U7qpnqpHRERkcFV5Jx6bGwsVCqV1hIbG/vUNoUQiIiIQKdOndCsWTMAQHZ2NgCgVq1aWnVr1aqlWVceHL8jIiKzVZFz6tOiohAREaFVVp5eelhYGE6ePIkDBw6UWvfvB8UIIXR6eAyTOhERmS0J+mf18g61/1N4eDh27NiB/fv3w8PDQ1Pu5uYG4GGPvXbt2prynJycUr33J+HwOxERmS0LSf9FF0IIhIWFYevWrdi3bx/q1auntb5evXpwc3PD3r17NWUPHjxAcnIyOnToUO522FMnIiKzVVWXtIWGhmLjxo3Yvn07HB0dNefJVSoVlEolJEnC5MmTMWfOHDRo0AANGjTAnDlzYGdnhyFDhpS7HSZ1IiIiA1u5ciUAIDAwUKs8Li4OISEhAIBp06bh/v37mDhxIm7duoV27dphz5495b5GHdDxOvVnBa9TJ3PA69TJHBj6OvX/Jl3Qe9vIwPqVGEnl4F8FIiIyW1U1/F5VmNSJiMhsyex5LkzqRERkvuT2lDYmdSIiMltyG37ndepEREQywZ46ERGZLZmNvjOpExGR+bKowG1iTRGTOhERmS321ImIiGRCbhPlmNSJiMhsye2SNs5+JyIikgn21ImIyGzJrKPOpE5EROZLbsPvTOpERGS2ZJbTmdSJiMh8yW1iGZM6ERGZLUlmXXW5/UghIiIyW+ypExGR2ZJXP51JnYiIzBhnvxMREcmEvFI6kzoREZkxmXXUmdSJiMh8cfY7ERERmSQmdSIiMlsWFVh0sX//fvTp0wfu7u6QJAnx8fFa63NzcxEWFgYPDw8olUo0btwYK1eu1Ot4iIiIzJIkSXovusjLy0PLli2xfPnyMtdPmTIFCQkJ+Oqrr5Ceno4pU6YgPDwc27dv16kdnlMnIiKzVVVn1Hv27ImePXs+dv2hQ4cwfPhwBAYGAgDGjh2LTz/9FCkpKejXr1+522FPnYiIzFZFeuqFhYW4e/eu1lJYWKhXHJ06dcKOHTtw9epVCCGQmJiIs2fPIigoSKf9MKkTEZHZqsg59djYWKhUKq0lNjZWrziWLl2KJk2awMPDAzY2Nnj55ZexYsUKdOrUSaf9cPidiIhID1FRUYiIiNAqUygUeu1r6dKlOHz4MHbs2AFvb2/s378fEydORO3atdGtW7dy74dJnYiIzFZFrlNXKBR6J/F/un//PmbMmIFt27ahd+/eAIAWLVogLS0NCxYseDaT+vnz57F48WKkp6dDkiQ0btwYb731Fnx8fIwdGhERyZQp3HpGrVZDrVbDwkL7jLilpSVKSkp02pdJJPUffvgBffv2RatWrdCxY0cIIXDw4EE0bdoUO3fuRPfu3Y0dIhERyVBV3VAuNzcX586d07zOyMhAWloanJ2d4eXlhS5duiAyMhJKpRLe3t5ITk7G+vXrsXDhQp3akYQQorKD19Xzzz+PoKAgzJ07V6v8nXfewZ49e5CamqrT/m7kFVVmeEQmyV5hEr/JiQzK1sBf852n/tJ72z7Na5W7blJSErp27VqqfPjw4Vi7di2ys7MRFRWFPXv24ObNm/D29sbYsWMxZcoUnU4RmERSt7W1xalTp9CgQQOt8rNnz6JFixYoKCjQaX9M6mQOmNTJHBg6qe/6Tf+k/kqz8if1qmISl7TVrFkTaWlppcrT0tLg6upa9QERERE9g0zip/6YMWMwduxYXLhwAR06dIAkSThw4ADmzZuHqVOnGjs8IiKSKckkpspVHpMYfhdCYPHixfj4449x7do1AIC7uzsiIyMxadIknS854PA7mQMOv5M5MPTw+3enc/TetldT0xtJNomk/k/37t0DADg6Ouq9DyZ1MgdM6mQODJ3UE05f13vbl5vWrMRIKodJnFOPiYnB+fPnATxM5hVJ6EREROUlSfovpsgkkvqWLVvQsGFDtG/fHsuXL8f16/r/ciIiIiovJnUDOHnyJE6ePIkXX3wRCxcuRJ06ddCrVy9s3LgR+fn5xg6PiIjomWBy59QB4JdffsHGjRvx7bffoqCgAHfv3tVpe55TJ3PAc+pkDgx9Tn1v+t96b9u9cY1KjKRymORfBXt7eyiVStjY2GgmzhEREVU2CxMdRteXSQy/Aw/vg/vRRx+hSZMmaNOmDVJTUzFr1ixkZ2cbOzQiIpIpqQL/mSKT6Kn7+/vj6NGjaN68OUaMGIEhQ4agTp06xg6LiIhkzlQnvOnLJJJ6165d8cUXX6Bp06bGDoWIiOiZZZIT5SqKE+XIHHCiHJkDQ0+USzpzU+9tAxs5V2IklcNofxUiIiLwwQcfwN7eHhEREU+sq+vzZMkwThxPwcb1a3Am/Xf8/fd1xH68FF26vqRZ/8WqT/Djnu+Rk50Na2trNGrcBONC30LT5i2MGDWRbo6nHMPaNauR/vtvuH79OhYt/QQvvtQNAKBWq7F86WIc+Hk/rly5DEcHB7Tz74C3pkyFq6vpPbGLnk5uE+WMltRPnDgBtVqt+TeZvoKC+/Bt2Ai9+76KGZGTS6338vbG1Onvwr2OBwoLC7F5w3pMDh2Db7Z/j+rVTe8XLVFZ7t/PR6NGjdDv1dcwdXK41rqCggL8kf47xo6fgEaNnsPdu3cxf+4cvBU2AV9/s9VIEVNFmOqEN31x+J300qF101I99X/Ly81F94B2WLpyNdq0a1+F0ZkHDr8bXsumjbR66mX57dRJBA96Awl7E1Hb3b0KozMPhh5+P/DnLb237dSgeiVGUjlM4pK2kSNHlnk9el5eHkaOHGmEiKii1OoH2L71Wzg4OMK3YSNjh0NkMLm5uZAkCY5OTsYOhfQgVWAxRSaR1NetW4f79++XKr9//z7Wr19vhIhIX7/sT8JLHdsgsH1rbNqwHotXfo5q1U3v1yxRZSgsLMSSRQvQs/crcHBwMHY4RMa9pO3u3bsQQkAIgXv37sHW1lazrri4GN999x1cXZ/8vNrCwkIUFhZqlxVZQqFQGCRmerLWfm2x7ustuH37NnZs+x/enz4Vn6//Gs7OLsYOjahSqdVqTH97CkpKBN59f5axwyE9WcjsQnWj9tSrVasGZ2dnSJKEhg0bonr16pqlRo0aGDlyJEJDQ5+4j9jYWKhUKq1l8YJ5VXQE9G9KpR08vLzRrEVLzIj+AJaWltgVzwlEJC9qtRqRUyfj6pUr+PSLNeylP8PkNvxu1J56YmIihBB48cUXsWXLFjg7/98MaRsbG3h7e8P9KRNPoqKiSl0Sl1tkaZB4SXdCCDx48MDYYRBVmkcJ/dLFi/gibj2qVePppWeaqWZnPRk1qXfp0gXAw/u+e3l5QdJjGEShUJQaaldz9rtB5Ofn4crlS5rXWVev4OyZdDg5qaCqVg3rvvgMnbp0hUuNmrh75za2frsJ13P+wovdg4wYNZFu8vPycOnS/33Pr165gj/S06FSqVDT1RVvT5mE9PTfseyTT1FSXIy/r18HAKhUKljb2BgrbNITL2mrJCdPnkSzZs1gYWGBkydPPrFuixa63byEl7QZRmrKUYSNHVGqvFeffoicEY1ZM6bh9G8ncef2LahU1fBc02YIGT0OTZo2N0K08sdL2gzj2NEjGD1iWKnyvv1exfjQMPTqUfZlnF/ErYdf23aGDs/sGPqStqMX7ui9bdv6qkqMpHIYLalbWFggOzsbrq6usLCwgCRJKCsUSZJQXFys076Z1MkcMKmTOZBLUt+/fz/++9//4vjx48jKysK2bdvQv39/rTrp6emYPn06kpOTUVJSgqZNm+Kbb76Bl5dXudsx2l+FjIwM1KxZU/NvIiKiqlZVg+95eXlo2bIlRowYgddff73U+vPnz6NTp04YNWoUYmJioFKpkJ6ernVVWHnwjnJEzyj21MkcGLqnfixD/566Xz39ht8lSSrVUx80aBCsra3x5Zdf6h0PYEI3n9m9e7fm9bRp01CtWjV06NABFy9eNGJkREQkZ1IF/issLMTdu3e1ln/fN6U8SkpKsHv3bjRs2BBBQUFwdXVFu3btEB8fr/O+TCKpz5kzB0qlEgBw6NAhLF++HPPnz0eNGjUwZcoUI0dHRERyJUn6L2XdJyU2NlbnGHJycpCbm4u5c+fi5Zdfxp49e/Dqq6/itddeQ3Jysm7HYwrD73Z2dvjjjz/g5eWF6dOnIysrC+vXr8fp06cRGBiI6///kpHy4vA7mQMOv5M5MPTwe2rmXb23bVpbUapnXtZl1v/27+H3a9euoU6dOhg8eDA2btyoqde3b1/Y29vj66+/LndMJtFTd3BwwI0bNwAAe/bsQbduD5+IZGtrW+Y94YmIiIxNoVDAyclJa9HnFuU1atSAlZUVmjRpolXeuHFjrXsmlIdJ/NTv3r07Ro8ejeeffx5nz55F7969AQCnT59G3bp1jRscERHJlwnce8bGxgZ+fn44c+aMVvnZs2fh7e2t075MIql/8skneO+993D58mVs2bIFLi4PH/5x/PhxDB482MjRERGRXFXVHeVyc3Nx7tw5zeuMjAykpaXB2dkZXl5eiIyMxMCBAxEQEICuXbsiISEBO3fuRFJSkk7tmMQ59crGc+pkDnhOncyBoc+pp126p/e2rbwcy103KSkJXbt2LVU+fPhwrF27FgCwZs0axMbG4sqVK2jUqBFiYmLQr18/nWIymaR++/ZtrF69Gunp6ZAkCY0bN8aoUaOgUul+HSCTOpkDJnUyB4ZO6r9WIKm31CGpVxWTmCiXkpICHx8fLFq0CDdv3sTff/+NRYsWwcfHB6mpqcYOj4iI5Epmz141iZ56586d4evri88//xxWVg9/lhUVFWH06NG4cOEC9u/fr9P+2FMnc8CeOpkDg/fUL1egp+5pej11k0jqSqUSJ06cwHPPPadV/vvvv6NNmzbIz8/XaX9M6mQOmNTJHBg6qZ+8nKv3ti08HSoxksphEsPvTk5OZV6Ld/nyZTg6mt4vISIikoeK3FHOFJlEUh84cCBGjRqFzZs34/Lly7hy5Qo2bdqE0aNH85I2IiIyGJmdUjeN69QXLFgACwsLDBs2DEVFD4fOra2tMWHCBMydO9fI0RERkWyZanbWk1GTen5+PiIjIxEfHw+1Wo3+/fsjLCwMKpUKvr6+sLOzM2Z4REQkc1V185mqYtSkHh0djbVr1yI4OBhKpRIbN25ESUkJvv32W2OGRURE9EwyalLfunUrVq9ejUGDBgEAgoOD0bFjRxQXF8PS0tKYoRERkRkw1Qlv+jLqRLnLly+jc+fOmtdt27aFlZUVrl27ZsSoiIjIXHCiXCUqLi6GjY2NVpmVlZVmshwREZFBmWp21pNRk7oQAiEhIVrPny0oKMD48eNhb2+vKdu6dasxwiMiIpnjRLlKNHz48FJlb775phEiISIicyS3c+omcZvYysbbxJI54G1iyRwY+jaxZ7J1uw35PzVyM73LrvlXgYiIzJbMOupM6kREZMZkltWZ1ImIyGxxohwREZFMyG2iHJM6ERGZLZnldNN49CoRERFVHHvqRERkvmTWVWdSJyIis8WJckRERDLBiXJEREQyIbOczolyRERkxqro2av79+9Hnz594O7uDkmSEB8f/9i648aNgyRJWLx4sY4Hw6RORERkcHl5eWjZsiWWL1/+xHrx8fE4cuQI3N3d9WqHw+9ERGS2qmqiXM+ePdGzZ88n1rl69SrCwsLwww8/oHfv3nq1w6RORERmqyIT5QoLC1FYWKhVplAooFAodN5XSUkJhg4disjISDRt2lTvmDj8TkREZqsip9RjY2OhUqm0ltjYWL3imDdvHqysrDBp0qQKHQ976kREZLYq0lOPiopCRESEVpk+vfTjx49jyZIlSE1NhVTBa+zYUyciIjOmf19doVDAyclJa9Enqf/888/IycmBl5cXrKysYGVlhYsXL2Lq1KmoW7euTvtiT52IiMiIhg4dim7dummVBQUFYejQoRgxYoRO+2JSJyIis1VVd5TLzc3FuXPnNK8zMjKQlpYGZ2dneHl5wcXFRau+tbU13Nzc0KhRI53aYVInIiKzVVV3lEtJSUHXrl01rx+dix8+fDjWrl1bae1IQghRaXszETfyiowdApHB2Sv4m5zkz9bAX/OsOw/03ra2yqYSI6kc/KtARERmi09pIyIikgt55XRe0kZERCQX7KkTEZHZkllHnUmdiIjMV1Vd0lZVmNSJiMhscaIcERGRXMgrpzOpExGR+ZJZTufsdyIiIrlgT52IiMwWJ8oRERHJBCfKERERyYTceuo8p05ERCQT7KkTEZHZYk+diIiITBJ76kREZLY4UY6IiEgm5Db8zqRORERmS2Y5nUmdiIjMmMyyOifKERERyQR76kREZLY4UY6IiEgmOFGOiIhIJmSW03lOnYiIzJhUgUUH+/fvR58+feDu7g5JkhAfH69Zp1arMX36dDRv3hz29vZwd3fHsGHDcO3aNZ0Ph0mdiIjMllSB/3SRl5eHli1bYvny5aXW5efnIzU1Fe+//z5SU1OxdetWnD17Fn379tX9eIQQQuetTNyNvCJjh0BkcPYKnj0j+bM18Nf8vlr/bZXW+m0nSRK2bduG/v37P7bOsWPH0LZtW1y8eBFeXl7l3jf/KhARkdmqyES5wsJCFBYWapUpFAooFIoKRgXcuXMHkiShWrVqOm0ny6TuYi/LwzJZhYWFiI2NRVRUVKV8mYlMEb/n8lSRkYBZH8YiJiZGqyw6OhqzZs2qUEwFBQV45513MGTIEDg5Oem0rSyH36lq3b17FyqVCnfu3NH5C0j0rOD3nP5N3576k4bf1Wo13njjDVy6dAlJSUk6f9fYpSUiItJDZQ21P6JWq/Gf//wHGRkZ2Ldvn14/HpnUiYiIjOxRQv/zzz+RmJgIFxcXvfbDpE5ERGRgubm5OHfunOZ1RkYG0tLS4OzsDHd3dwwYMACpqanYtWsXiouLkZ2dDQBwdnaGjY1NudthUqcKUygUiI6O5uQhkjV+z6kiUlJS0LVrV83riIgIAMDw4cMxa9Ys7NixAwDQqlUrre0SExMRGBhY7nY4UY6IiEgmeEc5IiIimWBSJyIikgkmdSIiIplgUqcqV7duXSxevNjYYRCVS2ZmJiRJQlpa2hPrBQYGYvLkyVUSE9HjMKnLTEhICCRJwty5c7XK4+PjIVXkJsd6WLt2bZn3LT527BjGjh1bpbGQ/D367kuSBGtra9SvXx9vv/028vLyKrRfT09PZGVloVmzZgCApKQkSJKE27dva9XbunUrPvjggwq1RVRRTOoyZGtri3nz5uHWrVvGDqVMNWvWhJ2dnbHDIBl6+eWXkZWVhQsXLuDDDz/EihUr8Pbbb1don5aWlnBzc4OV1ZOvAHZ2doajo2OF2iKqKCZ1GerWrRvc3NwQGxv72DoHDx5EQEAAlEolPD09MWnSJK0eTVZWFnr37g2lUol69eph48aNpYbNFy5ciObNm8Pe3h6enp6YOHEicnNzATzszYwYMULzpCFJkjQPOfjnfgYPHoxBgwZpxaZWq1GjRg3ExcUBeHh/5UmTJsHV1RW2trbo1KkTjh07VgnvFMmNQqGAm5sbPD09MWTIEAQHByM+Pv6p36Fbt24hODgYNWvWhFKpRIMGDTTfv38Ov2dmZmquNa5evTokSUJISAgA7eH3qKgotG/fvlR8LVq0QHR0NACgpKQEs2fPhoeHBxQKBVq1aoWEhAQDvjtkDpjUZcjS0hJz5szBsmXLcOXKlVLrT506haCgILz22ms4efIkNm/ejAMHDiAsLExTZ9iwYbh27RqSkpKwZcsWfPbZZ8jJydHaj4WFBZYuXYrffvsN69atw759+zBt2jQAQIcOHbB48WI4OTkhKysLWVlZZfaYgoODsWPHDs2PAQD44YcfkJeXh9dffx0AMG3aNGzZsgXr1q1DamoqfH19ERQUhJs3b1bK+0XypVQqoVarn/odev/99/H777/j+++/R3p6OlauXIkaNWqU2p+npye2bNkCADhz5gyysrKwZMmSUvWCg4Nx5MgRnD9/XlN2+vRpnDp1CsHBwQCAJUuW4OOPP8aCBQtw8uRJBAUFoW/fvvjzzz8N8VaQuRAkK8OHDxf9+vUTQgjRvn17MXLkSCGEENu2bROPPu6hQ4eKsWPHam33888/CwsLC3H//n2Rnp4uAIhjx45p1v/5558CgFi0aNFj2/7mm2+Ei4uL5nVcXJxQqVSl6nl7e2v28+DBA1GjRg2xfv16zfrBgweLN954QwghRG5urrC2thYbNmzQrH/w4IFwd3cX8+fPf/obQmbjn999IYQ4cuSIcHFxEQMGDHjqd6hPnz5ixIgRZe43IyNDABAnTpwQQgiRmJgoAIhbt25p1evSpYt46623NK9btGghZs+erXkdFRUl/Pz8NK/d3d3FRx99pLUPPz8/MXHiRF0Om0gLe+oyNm/ePKxbtw6///67Vvnx48exdu1aODg4aJagoCCUlJQgIyMDZ86cgZWVFVq3bq3ZxtfXF9WrV9faT2JiIrp37446derA0dERw4YNw40bN3SamGRtbY033ngDGzZsAADk5eVh+/btmt7M+fPnoVar0bFjR61t2rZti/T0dJ3fE5K3Xbt2wcHBAba2tvD390dAQADCw8Of+h2aMGECNm3ahFatWmHatGk4ePBghWMJDg7WfK+FEPj666813+u7d+/i2rVrWjEBQMeOHfm9pgphUpexgIAABAUFYcaMGVrlJSUlGDduHNLS0jTLr7/+ij///BM+Pj4Qj7lz8D/LL168iF69eqFZs2bYsmULjh8/jk8++QTAw3PiuggODsaPP/6InJwcxMfHw9bWFj179tRq898z94UQVT6bn0xf165dkZaWhjNnzqCgoABbt26FSqUC8OTvUM+ePXHx4kVMnjwZ165dw0svvVThCXZDhgzB2bNnkZqaioMHD+Ly5cul5o/we02VjUld5ubOnYudO3dq9Txat26N06dPw9fXt9RiY2OD5557DkVFRThx4oRmm3PnzmldwpOSkoKioiJ8/PHHaN++PRo2bIhr165ptW1jY4Pi4uKnxtihQwd4enpi8+bN2LBhA9544w3NU4kexXTgwAFNfbVajZSUFDRu3Fjft4Vkyt7eHr6+vvD29oa1tTWA8n+HatasiZCQEHz11VdYvHgxPvvsszLbePTdfNp328PDAwEBAdiwYQM2bNiAbt26oVatWgAAJycnuLu7a8UEPJzAyu81VQSf0iZzzZs3R3BwMJYtW6Ypmz59Otq3b4/Q0FCMGTMG9vb2SE9Px969e7Fs2TI899xz6NatG8aOHYuVK1fC2toaU6dOhVKp1PQifHx8UFRUhGXLlqFPnz745ZdfsGrVKq2269ati9zcXPz0009o2bIl7OzsyryUTZIkDBkyBKtWrcLZs2eRmJioWWdvb48JEyYgMjISzs7O8PLywvz585Gfn49Ro0YZ6F0jOSnPd2jmzJl44YUX0LRpUxQWFmLXrl2PTa7e3t6QJAm7du1Cr169oFQq4eDgUGbd4OBgzJo1Cw8ePMCiRYu01kVGRiI6Oho+Pj5o1aoV4uLikJaWphmyJ9KLEc/nkwH8e7KQEEJkZmYKhUIh/vlxHz16VHTv3l04ODgIe3t70aJFC61JO9euXRM9e/YUCoVCeHt7i40bNwpXV1exatUqTZ2FCxeK2rVrC6VSKYKCgsT69etLTSAaP368cHFxEQBEdHS0EEJ7otwjp0+fFgCEt7e3KCkp0Vp3//59ER4eLmrUqCEUCoXo2LGjOHr0aMXeKJKdsr77jzztO/TBBx+Ixo0bC6VSKZydnUW/fv3EhQsXhBClJ8oJIcTs2bOFm5ubkCRJDB8+XAhReqKcEELcunVLKBQKYWdnJ+7du6e1rri4WMTExIg6deoIa2tr0bJlS/H9999X+H0g88ZHr1K5XLlyBZ6envjxxx/x0ksvGTscIiIqA5M6lWnfvn3Izc1F8+bNkZWVhWnTpuHq1as4e/as5lwlERGZFp5TpzKp1WrMmDEDFy5cgKOjIzp06IANGzYwoRMRmTD21ImIiGSCl7QRERHJBJM6ERGRTDCpExERyQSTOhERkUwwqRMREckEkzqRDMyaNQutWrXSvA4JCUH//v2NFg8RGQeTOpEBhYSEQJIkSJIEa2tr1K9fH2+//bZOj6fVx5IlS7B27VrN68DAQEyePNmgbRKR8fHmM0QG9vLLLyMuLg5qtRo///wzRo8ejby8PKxcuVKrnlqtrrSb+zx63CgRmRf21IkMTKFQwM3NDZ6enhgyZAiCg4MRHx+vGTJfs2YN6tevD4VCASEE7ty5g7Fjx8LV1RVOTk548cUX8euvv2rtc+7cuahVqxYcHR0xatQoFBQUaK3/5/B7SEgIkpOTsWTJEs2oQWZmJgAgOTkZbdu2hUKhQO3atfHOO++gqKioKt4WIjIAJnWiKqZUKqFWqwE8fE79N998gy1btiAtLQ0A0Lt3b2RnZ+O7777D8ePH0bp1a7z00ku4efMmAOCbb75BdHQ0PvroI6SkpKB27dpYsWLFY9tbsmQJ/P39MWbMGGRlZSErKwuenp64evUqevXqBT8/P/z6669YuXIlVq9ejQ8//NDg7wERGQaH34mq0NGjR7Fx40bNk+4ePHiAL7/8EjVr1gTw8EE6p06dQk5ODhQKBQBgwYIFiI+Px//+9z+MHTsWixcvxsiRIzF69GgAwIcffogff/yxVG/9EZVKBRsbG9jZ2cHNzU1TvmLFCnh6emL58uWQJAnPPfccrl27hunTp2PmzJmwsOBvfqJnDf+vJTKwXbt2wcHBAba2tvD390dAQACWLVsGAPD29tYkdAA4fvw4cnNz4eLiAgcHB82SkZGB8+fPAwDS09Ph7++v1ca/X5fHo/1IkqQp69ixI3Jzc3HlyhV9DpWIjIw9dSID69q1K1auXAlra2u4u7trTYazt7fXqltSUoLatWsjKSmp1H6qVatWqXEJIbQS+qMyAKXKiejZwKROZGD29vbw9fUtV93WrVsjOzsbVlZWqFu3bpl1GjdujMOHD2PYsGGassOHDz9xvzY2NiguLtYqa9KkCbZs2aKV3A8ePAhHR0fUqVOnXPESkWnh8DuRCenWrRv8/f3Rv39//PDDD8jMzMTBgwfx3nvvISUlBQDw1ltvYc2aNVizZg3Onj2L6OhonD59+on7rVu3Lo4cOYLMzEz8/fffKCkpwcSJE3H58mWEh4fjjz/+wPbt2xEdHY2IiAieTyd6RvH/XCITIkkSvvvuOwQEBGDkyJFo2LAhBg0ahMzMTNSqVQsAMHDgQMycORPTp0/HCy+8gIsXL2LChAlP3O/bb78NS0tLNGnSBDVr1sSlS5dQp04dfPfddzh69ChatmyJ8ePHY9SoUXjvvfeq4lCJyAAk8egkGhERET3T2FMnIiKSCSZ1IiIimWBSJyIikgkmdSIiIplgUiciIpIJJnUiIiKZYFInIiKSCSZ1IiIimWBSJyIikgkmdSIiIplgUiciIpKJ/wc/BDPfL+4HMgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gerar matriz de confusão\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Plotar matriz de confusão\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GPU Enabled Condensed Version of  multiqubit and multioutput QML-Hybrid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "quantumEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1eb8817a50524ce1af23052011be56f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24f07891b0324ca78c4c7f0beee98566": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f56767fae03484688536b828846b56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "505d1bdc25414cee9dfbc3204dfc0c93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "552e8d190a1d437b920bc7d3f1e1af61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58adc826bab3458ca9cb8e325ce05f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59f8519d3d2144d683558aca466da131": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f1bb84efe844ee2b4fc27afe2a212c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64575c54d09d455281be57a8a0260346": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6611d138ef6e432f8ce0cf52cb1a07c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e827e8d2e88f4c71ae86f3c8538c84c0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ca965b900b1461eaa28f2a6b5398c73",
      "value": 1
     }
    },
    "69d560892ba440f89b50641014d1fd06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ca965b900b1461eaa28f2a6b5398c73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "90586e7287474ecfae458ff3b0a74efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae991db157b34830a4824661dc2ea07d",
       "IPY_MODEL_d9afc24be121433da98462d5ca8d8690"
      ],
      "layout": "IPY_MODEL_f2cd8d5132c444f0b25b353bdcd9d7ab"
     }
    },
    "9255a79718b040bbb8ec080d440304c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eb8817a50524ce1af23052011be56f4",
      "placeholder": "​",
      "style": "IPY_MODEL_24f07891b0324ca78c4c7f0beee98566",
      "value": " 32768/? [00:00&lt;00:00, 369344.38it/s]"
     }
    },
    "9276c41a3c6d41d3b60d31b30be07113": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a29264a8b5e6411eac0d3dae64693251": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe01b032a0c84aa695c9640550aab9fb",
       "IPY_MODEL_9255a79718b040bbb8ec080d440304c5"
      ],
      "layout": "IPY_MODEL_9276c41a3c6d41d3b60d31b30be07113"
     }
    },
    "a530b88ca002433e86872d16c37e551d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505d1bdc25414cee9dfbc3204dfc0c93",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f56767fae03484688536b828846b56a",
      "value": 1
     }
    },
    "ae991db157b34830a4824661dc2ea07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f1bb84efe844ee2b4fc27afe2a212c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef091b36eb3c48dcb0aaf09eec350971",
      "value": 1
     }
    },
    "af12e2a48e7940d0bff7731249e433f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a530b88ca002433e86872d16c37e551d",
       "IPY_MODEL_c30500854da54f07b2345d5cc55deee3"
      ],
      "layout": "IPY_MODEL_59f8519d3d2144d683558aca466da131"
     }
    },
    "b674dba95756437fb8eb209b726e7dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbfbdbd1d45e4de0b32e19125b29f71d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6611d138ef6e432f8ce0cf52cb1a07c4",
       "IPY_MODEL_ff58db68cca442cea4055e678574b2c2"
      ],
      "layout": "IPY_MODEL_552e8d190a1d437b920bc7d3f1e1af61"
     }
    },
    "c30500854da54f07b2345d5cc55deee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d560892ba440f89b50641014d1fd06",
      "placeholder": "​",
      "style": "IPY_MODEL_b674dba95756437fb8eb209b726e7dd8",
      "value": " 9920512/? [00:20&lt;00:00, 42152945.94it/s]"
     }
    },
    "d9afc24be121433da98462d5ca8d8690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de7bb8d497e14b09b1921f670bb59efb",
      "placeholder": "​",
      "style": "IPY_MODEL_f1a712b491b546029d157a17a0d6337e",
      "value": " 8192/? [00:00&lt;00:00, 18970.79it/s]"
     }
    },
    "de7bb8d497e14b09b1921f670bb59efb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e827e8d2e88f4c71ae86f3c8538c84c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea70115f0ada4a769c55113327333393": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef091b36eb3c48dcb0aaf09eec350971": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1a712b491b546029d157a17a0d6337e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2cd8d5132c444f0b25b353bdcd9d7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9cd8031e436418595d28cf344fe2e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe01b032a0c84aa695c9640550aab9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64575c54d09d455281be57a8a0260346",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9cd8031e436418595d28cf344fe2e4f",
      "value": 1
     }
    },
    "ff58db68cca442cea4055e678574b2c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58adc826bab3458ca9cb8e325ce05f2c",
      "placeholder": "​",
      "style": "IPY_MODEL_ea70115f0ada4a769c55113327333393",
      "value": " 1654784/? [00:19&lt;00:00, 138150.43it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
