{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.017426Z",
     "start_time": "2024-08-29T20:17:54.207404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eflammere/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torchxrayvision/utils.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "import torch.autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "\n",
    "import qiskit\n",
    "from qiskit import transpile\n",
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** Display current device and versions of Qiskit, PyTorch and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "CUDA: 12.4\n",
      "Qiskit: 1.2.4\n",
      "Torch: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "print(f\"Qiskit: {qiskit.__version__}\")\n",
    "torch_version = torch.__version__.split('+')[0]\n",
    "print(f\"Torch: {torch_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2** Mammography dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.025396Z",
     "start_time": "2024-08-29T20:17:57.020898Z"
    }
   },
   "outputs": [],
   "source": [
    "class MammoDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True, data_augmentation=True):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Base transformation: resizing, tensor conversion, and normalization\n",
    "        base_transform = [transforms.Resize((250, 250)),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "\n",
    "        # Apply data augmentation if in training mode\n",
    "        if train and data_augmentation:\n",
    "            augmentation_transform = [transforms.RandomVerticalFlip(),\n",
    "                                      v2.GaussianNoise(0.3),\n",
    "                                      transforms.RandomRotation(45)]\n",
    "            self.transform = transforms.Compose(base_transform + augmentation_transform)\n",
    "        else:\n",
    "            self.transform = transforms.Compose(base_transform)\n",
    "\n",
    "        # Load image paths and corresponding labels\n",
    "        for label in ['0', '1']:\n",
    "            folder_path = os.path.join(root_dir, label)\n",
    "            self.image_paths.extend([os.path.join(folder_path, img_name) for img_name in os.listdir(folder_path)])\n",
    "            self.labels.extend([int(label)] * len(os.listdir(folder_path)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    # Fetch an image and its corresponding label\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3** Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # Initialize the quantum circuit with the specified number of qubits (number of outputs of the model)\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta_0 = qiskit.circuit.Parameter('theta0')\n",
    "        \n",
    "        # Apply Hadamard gate to all qubits to create superposition\n",
    "        self._circuit.h(all_qubits)\n",
    "\n",
    "        self._circuit.barrier()\n",
    "        \n",
    "        # Apply parameterized Ry rotation to all qubits\n",
    "        self._circuit.ry(self.theta_0, all_qubits)\n",
    "        \n",
    "        # Add a CNOT gate to create entanglement\n",
    "        if n_qubits > 1:\n",
    "            self._circuit.cx(0, 1)\n",
    "\n",
    "        self._circuit.barrier()\n",
    "        \n",
    "        # Measure all qubits to retrieve their states\n",
    "        self._circuit.measure_all()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def run(self, thetas):\n",
    "        # Assign parameter values for the circuit\n",
    "        param_values = {\n",
    "            self.theta_0: thetas[0],\n",
    "        }\n",
    "        \n",
    "        # Bind the parameters to the circuit\n",
    "        bound_circuit = self._circuit.assign_parameters(param_values)\n",
    "        \n",
    "        # Transpile the circuit for the specified backend\n",
    "        transpiled_circuit = transpile(bound_circuit, self.backend)\n",
    "        \n",
    "        # Execute the circuit and obtain results\n",
    "        job = self.backend.run(transpiled_circuit, shots=self.shots)\n",
    "        \n",
    "        # Get the result counts from the job\n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        expectations = []\n",
    "\n",
    "        # Check if the result is a list (multiple circuits)\n",
    "        if isinstance(result, list):\n",
    "            for i in result:\n",
    "                counts = np.array(list(i.values()))\n",
    "                states = np.array(list(i.keys())).astype(float)\n",
    "                \n",
    "                # Calculate probabilities for each state\n",
    "                probabilities = counts / self.shots\n",
    "                \n",
    "                # Compute the expectation value for the current result\n",
    "                expectation = np.sum(states * probabilities)\n",
    "                expectations.append(expectation)\n",
    "        else:\n",
    "            # Handle single result scenario\n",
    "            counts = np.array(list(result.values()))\n",
    "            states = np.array(list(result.keys())).astype(float)\n",
    "            \n",
    "            probabilities = counts / self.shots\n",
    "            \n",
    "            # Compute the expectation value for the single result\n",
    "            expectation = np.sum(states * probabilities)\n",
    "            expectations.append(expectation)\n",
    "        \n",
    "        # Return the computed expectation values as a numpy array\n",
    "        return np.array(expectations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Hybrid quantum-classical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        ctx.shift = shift  # Save the shift value\n",
    "        ctx.quantum_circuit = quantum_circuit  # Save the quantum circuit\n",
    "\n",
    "        # Run the quantum circuit and get the expectation value\n",
    "        expectation_z = ctx.quantum_circuit.run(input.tolist()[0])\n",
    "        \n",
    "        # Create a result tensor on the same device as the input\n",
    "        result = torch.tensor([expectation_z], device=input.device)\n",
    "        \n",
    "        ctx.save_for_backward(input, result)  # Save tensors for backward pass\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        \n",
    "        device = grad_output.device \n",
    "        input = input.to(device)\n",
    "\n",
    "        input_list = input.tolist()[0]\n",
    "        input_tensor = torch.tensor(input_list, device=device) \n",
    "\n",
    "        shift_value = torch.tensor(ctx.shift, device=device) * torch.ones_like(input_tensor) \n",
    "\n",
    "        # Calculate shifted values\n",
    "        shift_right = input_tensor + shift_value\n",
    "        shift_left = input_tensor - shift_value\n",
    "\n",
    "        gradients = [] \n",
    "        for i in range(len(input_tensor)):\n",
    "            # Run the quantum circuit for shifted values\n",
    "            expectation_right = ctx.quantum_circuit.run([shift_right[i].item()])\n",
    "            expectation_left = ctx.quantum_circuit.run([shift_left[i].item()])\n",
    "\n",
    "            # Create tensors for results\n",
    "            expectation_right = torch.tensor([expectation_right], device=device)\n",
    "            expectation_left = torch.tensor([expectation_left], device=device)\n",
    "\n",
    "            # Calculate the gradient\n",
    "            gradient = expectation_right - expectation_left\n",
    "            gradients.append(gradient) \n",
    "\n",
    "        # Convert gradients list to tensor\n",
    "        gradients = torch.cat(gradients).to(device).float()\n",
    "\n",
    "        return gradients * grad_output.float(), None, None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Hybrid quantum-classical layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(nn.Module):\n",
    "    def __init__(self, n_qubits, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(n_qubits, backend, shots) \n",
    "        self.shift = shift  \n",
    "        \n",
    "    def forward(self, input):\n",
    "        batch_results = []\n",
    "        for i in range(input.shape[0]):\n",
    "            # Apply the hybrid function for each input\n",
    "            result = HybridFunction.apply(input[i].unsqueeze(0), self.quantum_circuit, self.shift)\n",
    "            batch_results.append(result)\n",
    "        return torch.cat(batch_results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4** Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(torch.nn.Module):\n",
    "    def __init__(self, out_features = 2):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, out_features)\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qcNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(qcNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 15, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.drop1 = nn.Dropout2d(p=0.2)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(55815, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        sim = Aer.get_backend('aer_simulator_statevector')\n",
    "        self.theta_qubit = nn.Parameter(torch.FloatTensor(np.random.uniform(0, 2 * np.pi, size=(self.fc1.out_features,))))\n",
    "        theta_qubit = torch.clamp(theta_qubit, min=0, max=2 * np.pi)\n",
    "        self.hybrid = Hybrid(self.fc1.out_features, sim, 1000, self.theta_qubit)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.hybrid(x)\n",
    "        x = torch.cat((x, 1 - x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, theta_min = 0, theta_max = 2 * np.pi):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained ResNet50 model\n",
    "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Modify the fully connected layer to have 84 outputs\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 84)\n",
    "    \n",
    "        self.drop1 = nn.Dropout(p=0.2)  # Dropout layer to prevent overfitting\n",
    "        self.fc1 = nn.Linear(84, 1)  # Output layer for one output\n",
    "        \n",
    "        # Initialize the quantum simulator backend\n",
    "        sim = Aer.get_backend('qasm_simulator')\n",
    "        self.theta_qubit = nn.Parameter(torch.FloatTensor(np.random.uniform(theta_min, theta_max, size=(self.fc1.out_features,))))\n",
    "\n",
    "        self.hybrid = Hybrid(self.fc1.out_features, sim, 10000, self.theta_qubit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.drop1(x) \n",
    "        #x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.hybrid(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5** Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.054984Z",
     "start_time": "2024-08-29T20:17:57.050739Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/mnt/c/Users/Win10/Desktop/researchData/data/png/train'\n",
    "test_dir = '/mnt/c/Users/Win10/Desktop/researchData/data/png/test'\n",
    "\n",
    "train_dataset = MammoDataset(root_dir=train_dir, data_augmentation=True)\n",
    "test_dataset = MammoDataset(root_dir=test_dir, train=False)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6** Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: checkpoints/2024-12-04_22-34\n"
     ]
    }
   ],
   "source": [
    "def create_output_directory():\n",
    "    now = datetime.now()\n",
    "    folder_name = now.strftime(\"%Y-%m-%d_%H-%M\") \n",
    "    output_dir = os.path.join(\"checkpoints\", folder_name)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Created: {output_dir}\")\n",
    "    return output_dir\n",
    "\n",
    "output_dir = create_output_directory()\n",
    "\n",
    "def save_model(model, epoch, output_dir):\n",
    "    model_path = os.path.join(output_dir, f\"model_epoch_{epoch}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "class_weights = torch.tensor([1, 2])\n",
    "quantum_loss_func = nn.BCELoss(reduction='none').to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-6) \n",
    "optimizer_quantum = optim.Adam([model.theta_qubit], lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2617993877991494\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer_quantum\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate quantum loss\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss_per_sample \u001b[38;5;241m=\u001b[39m quantum_loss_func(prediction, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#x = F.leaky_relu(self.fc1(x))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mHybrid.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Apply the hybrid function for each input\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mHybridFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     batch_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(batch_results)\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mHybridFunction.forward\u001b[0;34m(ctx, input, quantum_circuit, shift)\u001b[0m\n\u001b[1;32m      5\u001b[0m ctx\u001b[38;5;241m.\u001b[39mquantum_circuit \u001b[38;5;241m=\u001b[39m quantum_circuit  \u001b[38;5;66;03m# Save the quantum circuit\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run the quantum circuit and get the expectation value\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m expectation_z \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_circuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a result tensor on the same device as the input\u001b[39;00m\n\u001b[1;32m     11\u001b[0m result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([expectation_z], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mQuantumCircuit.run\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     38\u001b[0m bound_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circuit\u001b[38;5;241m.\u001b[39massign_parameters(param_values)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Transpile the circuit for the specified backend\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m transpiled_circuit \u001b[38;5;241m=\u001b[39m \u001b[43mtranspile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Execute the circuit and obtain results\u001b[39;00m\n\u001b[1;32m     44\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mrun(transpiled_circuit, shots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshots)\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/qiskit/compiler/transpiler.py:366\u001b[0m, in \u001b[0;36mtranspile\u001b[0;34m(circuits, backend, basis_gates, inst_map, coupling_map, backend_properties, initial_layout, layout_method, routing_method, translation_method, scheduling_method, instruction_durations, dt, approximation_degree, timing_constraints, seed_transpiler, optimization_level, callback, output_name, unitary_synthesis_method, unitary_synthesis_plugin_config, target, hls_config, init_method, optimization_method, ignore_backend_supplied_default_methods, num_processes)\u001b[0m\n\u001b[1;32m    361\u001b[0m _check_circuits_coupling_map(circuits, coupling_map, backend)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Edge cases require using the old model (loose constraints) instead of building a target,\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# but we don't populate the passmanager config with loose constraints unless it's one of\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# the known edge cases to control the execution path.\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m pm \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_preset_pass_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasis_gates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasis_gates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoupling_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoupling_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstruction_durations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstruction_durations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtiming_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtiming_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43minst_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minst_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_layout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayout_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouting_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouting_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtranslation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranslation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduling_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapproximation_degree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapproximation_degree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed_transpiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_transpiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43munitary_synthesis_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munitary_synthesis_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43munitary_synthesis_plugin_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munitary_synthesis_plugin_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhls_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimization_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m out_circuits \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mrun(circuits, callback\u001b[38;5;241m=\u001b[39mcallback, num_processes\u001b[38;5;241m=\u001b[39mnum_processes)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, circ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output_name, out_circuits):\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/qiskit/transpiler/preset_passmanagers/generate_preset_pass_manager.py:282\u001b[0m, in \u001b[0;36mgenerate_preset_pass_manager\u001b[0;34m(optimization_level, backend, target, basis_gates, inst_map, coupling_map, instruction_durations, backend_properties, timing_constraints, initial_layout, layout_method, routing_method, translation_method, scheduling_method, approximation_degree, seed_transpiler, unitary_synthesis_method, unitary_synthesis_plugin_config, hls_config, init_method, optimization_method, dt, _skip_target)\u001b[0m\n\u001b[1;32m    279\u001b[0m inst_map \u001b[38;5;241m=\u001b[39m _parse_inst_map(inst_map, backend)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# The basis gates parser will set _skip_target to True if a custom basis gate is found\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# (known edge case).\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m basis_gates, name_mapping, _skip_target \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_basis_gates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasis_gates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_skip_target\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m coupling_map \u001b[38;5;241m=\u001b[39m _parse_coupling_map(coupling_map, backend)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/qiskit/transpiler/preset_passmanagers/generate_preset_pass_manager.py:416\u001b[0m, in \u001b[0;36m_parse_basis_gates\u001b[0;34m(basis_gates, backend, inst_map, skip_target)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(instructions), name_mapping, skip_target\n\u001b[1;32m    414\u001b[0m instructions \u001b[38;5;241m=\u001b[39m instructions \u001b[38;5;129;01mor\u001b[39;00m backend\u001b[38;5;241m.\u001b[39moperation_names\n\u001b[1;32m    415\u001b[0m name_mapping\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 416\u001b[0m     {name: \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241m.\u001b[39moperation_from_name(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m backend\u001b[38;5;241m.\u001b[39moperation_names}\n\u001b[1;32m    417\u001b[0m )\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Check for custom instructions before removing calibrations\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inst \u001b[38;5;129;01min\u001b[39;00m instructions:\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/qiskit_aer/backends/aerbackend.py:262\u001b[0m, in \u001b[0;36mAerBackend.target\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Load Qiskit object representation\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m qiskit_inst_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mget_standard_gate_name_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m qiskit_inst_mapping\u001b[38;5;241m.\u001b[39mupdate(NAME_MAPPING)\n\u001b[1;32m    265\u001b[0m qiskit_control_flow_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif_else\u001b[39m\u001b[38;5;124m\"\u001b[39m: IfElseOp,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m: WhileLoopOp,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m: ForLoopOp,\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswitch_case\u001b[39m\u001b[38;5;124m\"\u001b[39m: SwitchCaseOp,\n\u001b[1;32m    270\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/qiskit/circuit/library/standard_gates/__init__.py:61\u001b[0m, in \u001b[0;36mget_standard_gate_name_mapping\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m phi \u001b[38;5;241m=\u001b[39m Parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mφ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m gamma \u001b[38;5;241m=\u001b[39m Parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mγ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mβ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m time \u001b[38;5;241m=\u001b[39m Parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Standard gates library mapping, multicontrolled gates not included since they're\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# variable width\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/qiskit/circuit/parameter.py:88\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[0;34m(self, name, uuid)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hash_key(),))\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hash \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_expr))\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_symbols \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m: symbol}\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/qiskit/circuit/parameter.py:159\u001b[0m, in \u001b[0;36mParameter.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_hash_key\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# `ParameterExpression` needs to be able to hash all its contained `Parameter` instances in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# its hash as part of the equality comparison but has its own more complete symbolic\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# expression, so its full hash key is split into `(parameter_keys, symbolic_expression)`.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# This method lets containing expressions get only the bits they need for equality checks in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# the first value, without wasting time re-hashing individual Sympy/Symengine symbols.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_expr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uuid)\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# This is precached for performance, since it's used a lot and we are immutable.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hash\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# We have to manually control the pickling so that the hash is computable before the unpickling\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# operation attempts to put this parameter into a hashmap.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_losses = {}\n",
    "for theta in np.arange(np.pi / 12, 2 * np.pi, np.pi / 12):\n",
    "    print(theta)\n",
    "    \n",
    "    model = Net(theta - np.pi /12, theta).to(device)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(1):\n",
    "        total_loss = []\n",
    "\n",
    "        for batch_idx, (image, label) in enumerate(train_loader):\n",
    "            \n",
    "            image = image.to(device)\n",
    "            label = label.double().unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_quantum.zero_grad()\n",
    "\n",
    "            # Forward pass through the model\n",
    "            prediction = model(image)\n",
    "\n",
    "            # Calculate quantum loss\n",
    "            loss_per_sample = quantum_loss_func(prediction, label)\n",
    "\n",
    "            sample_weights = torch.where(label == 1, class_weights[1], class_weights[0])\n",
    "\n",
    "            quantum_loss = (loss_per_sample * sample_weights).mean()\n",
    "        \n",
    "            # Backward pass and compute gradients\n",
    "            quantum_loss.backward()\n",
    "\n",
    "            # Clipping gradients\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            nn.utils.clip_grad_norm_([model.theta_qubit], max_norm=1.0)\n",
    "\n",
    "            # Update classical weights\n",
    "            optimizer.step()\n",
    "            # Update quantum parameters\n",
    "            optimizer_quantum.step()\n",
    "\n",
    "            total_loss.append(quantum_loss.item())\n",
    "            print(f\"Batch {batch_idx + 1} completed with total loss: {quantum_loss.item():.4f}\")\n",
    "\n",
    "    # Average loss per epoch\n",
    "    avg_loss = np.mean(total_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{1}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    total_losses[str(theta)] = avg_loss\n",
    "\n",
    "print(total_losses)\n",
    "\n",
    "min_theta = min(total_losses, key=total_losses.get)\n",
    "min_result = total_losses[min_theta]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimal_theta \u001b[38;5;241m=\u001b[39m min_theta  \n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimal_theta\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[87], line 16\u001b[0m, in \u001b[0;36mNet.__init__\u001b[0;34m(self, theta_min, theta_max)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize the quantum simulator backend\u001b[39;00m\n\u001b[1;32m     15\u001b[0m sim \u001b[38;5;241m=\u001b[39m Aer\u001b[38;5;241m.\u001b[39mget_backend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqasm_simulator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta_qubit \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhybrid \u001b[38;5;241m=\u001b[39m Hybrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mout_features, sim, \u001b[38;5;241m10000\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta_qubit)\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:1175\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.uniform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "optimal_theta = min_theta  \n",
    "model = Net(optimal_theta).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7** Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.845117Z",
     "start_time": "2024-08-29T20:17:57.845117Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.double().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_quantum.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        prediction = model(image)\n",
    "\n",
    "        # Calculate quantum loss\n",
    "        loss_per_sample = quantum_loss_func(prediction, label)\n",
    "\n",
    "        sample_weights = torch.where(label == 1, class_weights[1], class_weights[0])\n",
    "\n",
    "        quantum_loss = (loss_per_sample * sample_weights).mean()\n",
    "    \n",
    "        # Backward pass and compute gradients\n",
    "        quantum_loss.backward()\n",
    "\n",
    "        # Clipping gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        nn.utils.clip_grad_norm_([model.theta_qubit], max_norm=1.0)\n",
    "\n",
    "        # Update classical weights\n",
    "        optimizer.step()\n",
    "        # Update quantum parameters\n",
    "        optimizer_quantum.step()\n",
    "\n",
    "        total_loss.append(quantum_loss.item())\n",
    "        print(f\"Batch {batch_idx + 1} completed with total loss: {quantum_loss.item():.4f}\")\n",
    "\n",
    "    # Average loss per epoch\n",
    "    avg_loss = np.mean(total_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    save_model(model, epoch + 1, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8** Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oy111XeE_cm-"
   },
   "outputs": [],
   "source": [
    "#model_path = ''\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "all_labels = [] \n",
    "all_predictions = []  \n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        label = label.unsqueeze(1) \n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        try:\n",
    "            prediction = model(image)\n",
    "            predicted_class = prediction.argmax(dim=1)\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(predicted_class.cpu().numpy())\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9** Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10** Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GPU Enabled Condensed Version of  multiqubit and multioutput QML-Hybrid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "quantumEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1eb8817a50524ce1af23052011be56f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24f07891b0324ca78c4c7f0beee98566": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f56767fae03484688536b828846b56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "505d1bdc25414cee9dfbc3204dfc0c93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "552e8d190a1d437b920bc7d3f1e1af61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58adc826bab3458ca9cb8e325ce05f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59f8519d3d2144d683558aca466da131": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f1bb84efe844ee2b4fc27afe2a212c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64575c54d09d455281be57a8a0260346": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6611d138ef6e432f8ce0cf52cb1a07c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e827e8d2e88f4c71ae86f3c8538c84c0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ca965b900b1461eaa28f2a6b5398c73",
      "value": 1
     }
    },
    "69d560892ba440f89b50641014d1fd06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ca965b900b1461eaa28f2a6b5398c73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "90586e7287474ecfae458ff3b0a74efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae991db157b34830a4824661dc2ea07d",
       "IPY_MODEL_d9afc24be121433da98462d5ca8d8690"
      ],
      "layout": "IPY_MODEL_f2cd8d5132c444f0b25b353bdcd9d7ab"
     }
    },
    "9255a79718b040bbb8ec080d440304c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eb8817a50524ce1af23052011be56f4",
      "placeholder": "​",
      "style": "IPY_MODEL_24f07891b0324ca78c4c7f0beee98566",
      "value": " 32768/? [00:00&lt;00:00, 369344.38it/s]"
     }
    },
    "9276c41a3c6d41d3b60d31b30be07113": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a29264a8b5e6411eac0d3dae64693251": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe01b032a0c84aa695c9640550aab9fb",
       "IPY_MODEL_9255a79718b040bbb8ec080d440304c5"
      ],
      "layout": "IPY_MODEL_9276c41a3c6d41d3b60d31b30be07113"
     }
    },
    "a530b88ca002433e86872d16c37e551d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505d1bdc25414cee9dfbc3204dfc0c93",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f56767fae03484688536b828846b56a",
      "value": 1
     }
    },
    "ae991db157b34830a4824661dc2ea07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f1bb84efe844ee2b4fc27afe2a212c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef091b36eb3c48dcb0aaf09eec350971",
      "value": 1
     }
    },
    "af12e2a48e7940d0bff7731249e433f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a530b88ca002433e86872d16c37e551d",
       "IPY_MODEL_c30500854da54f07b2345d5cc55deee3"
      ],
      "layout": "IPY_MODEL_59f8519d3d2144d683558aca466da131"
     }
    },
    "b674dba95756437fb8eb209b726e7dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbfbdbd1d45e4de0b32e19125b29f71d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6611d138ef6e432f8ce0cf52cb1a07c4",
       "IPY_MODEL_ff58db68cca442cea4055e678574b2c2"
      ],
      "layout": "IPY_MODEL_552e8d190a1d437b920bc7d3f1e1af61"
     }
    },
    "c30500854da54f07b2345d5cc55deee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d560892ba440f89b50641014d1fd06",
      "placeholder": "​",
      "style": "IPY_MODEL_b674dba95756437fb8eb209b726e7dd8",
      "value": " 9920512/? [00:20&lt;00:00, 42152945.94it/s]"
     }
    },
    "d9afc24be121433da98462d5ca8d8690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de7bb8d497e14b09b1921f670bb59efb",
      "placeholder": "​",
      "style": "IPY_MODEL_f1a712b491b546029d157a17a0d6337e",
      "value": " 8192/? [00:00&lt;00:00, 18970.79it/s]"
     }
    },
    "de7bb8d497e14b09b1921f670bb59efb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e827e8d2e88f4c71ae86f3c8538c84c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea70115f0ada4a769c55113327333393": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef091b36eb3c48dcb0aaf09eec350971": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1a712b491b546029d157a17a0d6337e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2cd8d5132c444f0b25b353bdcd9d7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9cd8031e436418595d28cf344fe2e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe01b032a0c84aa695c9640550aab9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64575c54d09d455281be57a8a0260346",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9cd8031e436418595d28cf344fe2e4f",
      "value": 1
     }
    },
    "ff58db68cca442cea4055e678574b2c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58adc826bab3458ca9cb8e325ce05f2c",
      "placeholder": "​",
      "style": "IPY_MODEL_ea70115f0ada4a769c55113327333393",
      "value": " 1654784/? [00:19&lt;00:00, 138150.43it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
