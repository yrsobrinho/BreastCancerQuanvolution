{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.017426Z",
     "start_time": "2024-08-29T20:17:54.207404Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "import torch.autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "\n",
    "import qiskit\n",
    "from qiskit import transpile\n",
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** Display current device and versions of Qiskit, PyTorch and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "CUDA: 12.4\n",
      "Qiskit: 1.2.4\n",
      "Torch: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "print(f\"Qiskit: {qiskit.__version__}\")\n",
    "torch_version = torch.__version__.split('+')[0]\n",
    "print(f\"Torch: {torch_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2** Mammography dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.025396Z",
     "start_time": "2024-08-29T20:17:57.020898Z"
    }
   },
   "outputs": [],
   "source": [
    "class MammoDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True, data_augmentation=True):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Base transformation: resizing, tensor conversion, and normalization\n",
    "        base_transform = [transforms.Resize((250, 250)),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize(mean=[0.3577, 0.3577, 0.3577], std=[0.2662, 0.2662, 0.2662])]\n",
    "\n",
    "        # Apply data augmentation if in training mode\n",
    "        if train and data_augmentation:\n",
    "            augmentation_transform = [transforms.RandomVerticalFlip(),\n",
    "                                      transforms.GaussianBlur(kernel_size=(3, 3))]\n",
    "            self.transform = transforms.Compose(augmentation_transform + base_transform)\n",
    "        else:\n",
    "            self.transform = transforms.Compose(base_transform)\n",
    "\n",
    "        # Load image paths and corresponding labels\n",
    "        for label in ['0', '1']:\n",
    "            folder_path = os.path.join(root_dir, label)\n",
    "            self.image_paths.extend([os.path.join(folder_path, img_name) for img_name in os.listdir(folder_path)])\n",
    "            self.labels.extend([int(label)] * len(os.listdir(folder_path)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    # Fetch an image and its corresponding label\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3** Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # Initialize the quantum circuit with the specified number of qubits (number of outputs of the model)\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta_0 = qiskit.circuit.Parameter('theta0')\n",
    "        \n",
    "        # Apply Hadamard gate to all qubits to create superposition\n",
    "        self._circuit.h(all_qubits)\n",
    "\n",
    "        self._circuit.barrier()\n",
    "        \n",
    "        # Apply parameterized Ry rotation to all qubits\n",
    "        self._circuit.ry(self.theta_0, all_qubits)\n",
    "        \n",
    "        # Add a CNOT gate to create entanglement\n",
    "        if n_qubits > 1:\n",
    "            self._circuit.cx(0, 1)\n",
    "\n",
    "        self._circuit.barrier()\n",
    "        \n",
    "        # Measure all qubits to retrieve their states\n",
    "        self._circuit.measure_all()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def run(self, thetas):\n",
    "        # Assign parameter values for the circuit\n",
    "        param_values = {\n",
    "            self.theta_0: thetas[0],\n",
    "        }\n",
    "        \n",
    "        # Bind the parameters to the circuit\n",
    "        bound_circuit = self._circuit.assign_parameters(param_values)\n",
    "        \n",
    "        # Transpile the circuit for the specified backend\n",
    "        transpiled_circuit = transpile(bound_circuit, self.backend)\n",
    "        \n",
    "        # Execute the circuit and obtain results\n",
    "        job = self.backend.run(transpiled_circuit, shots=self.shots)\n",
    "        \n",
    "        # Get the result counts from the job\n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        expectations = []\n",
    "\n",
    "        # Check if the result is a list (multiple circuits)\n",
    "        if isinstance(result, list):\n",
    "            for i in result:\n",
    "                counts = np.array(list(i.values()))\n",
    "                states = np.array(list(i.keys())).astype(float)\n",
    "                \n",
    "                # Calculate probabilities for each state\n",
    "                probabilities = counts / self.shots\n",
    "                \n",
    "                # Compute the expectation value for the current result\n",
    "                expectation = np.sum(states * probabilities)\n",
    "                expectations.append(expectation)\n",
    "        else:\n",
    "            # Handle single result scenario\n",
    "            counts = np.array(list(result.values()))\n",
    "            states = np.array(list(result.keys())).astype(float)\n",
    "            \n",
    "            probabilities = counts / self.shots\n",
    "            \n",
    "            # Compute the expectation value for the single result\n",
    "            expectation = np.sum(states * probabilities)\n",
    "            expectations.append(expectation)\n",
    "        \n",
    "        # Return the computed expectation values as a numpy array\n",
    "        return np.array(expectations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Hybrid quantum-classical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        ctx.shift = shift  # Save the shift value\n",
    "        ctx.quantum_circuit = quantum_circuit  # Save the quantum circuit\n",
    "\n",
    "        # Run the quantum circuit and get the expectation value\n",
    "        expectation_z = ctx.quantum_circuit.run(input.tolist()[0])\n",
    "        \n",
    "        # Create a result tensor on the same device as the input\n",
    "        result = torch.tensor([expectation_z], device=input.device)\n",
    "        \n",
    "        ctx.save_for_backward(input, result)  # Save tensors for backward pass\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        \n",
    "        device = grad_output.device \n",
    "        input = input.to(device)\n",
    "\n",
    "        input_list = input.tolist()[0]\n",
    "        input_tensor = torch.tensor(input_list, device=device) \n",
    "\n",
    "        shift_value = torch.tensor(ctx.shift, device=device) * torch.ones_like(input_tensor) \n",
    "\n",
    "        # Calculate shifted values\n",
    "        shift_right = input_tensor + shift_value\n",
    "        shift_left = input_tensor - shift_value\n",
    "\n",
    "        gradients = [] \n",
    "        for i in range(len(input_tensor)):\n",
    "            # Run the quantum circuit for shifted values\n",
    "            expectation_right = ctx.quantum_circuit.run([shift_right[i].item()])\n",
    "            expectation_left = ctx.quantum_circuit.run([shift_left[i].item()])\n",
    "\n",
    "            # Create tensors for results\n",
    "            expectation_right = torch.tensor([expectation_right], device=device)\n",
    "            expectation_left = torch.tensor([expectation_left], device=device)\n",
    "\n",
    "            # Calculate the gradient\n",
    "            gradient = expectation_right - expectation_left\n",
    "            gradients.append(gradient) \n",
    "\n",
    "        # Convert gradients list to tensor\n",
    "        gradients = torch.cat(gradients).to(device).float()\n",
    "\n",
    "        return gradients * grad_output.float(), None, None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Hybrid quantum-classical layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(nn.Module):\n",
    "    def __init__(self, n_qubits, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(n_qubits, backend, shots) \n",
    "        self.shift = shift  \n",
    "        \n",
    "    def forward(self, input):\n",
    "        batch_results = []\n",
    "        for i in range(input.shape[0]):\n",
    "            # Apply the hybrid function for each input\n",
    "            result = HybridFunction.apply(input[i].unsqueeze(0), self.quantum_circuit, self.shift)\n",
    "            batch_results.append(result)\n",
    "        return torch.cat(batch_results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4** Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(torch.nn.Module):\n",
    "    def __init__(self, out_features = 2):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, out_features)\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qcNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(qcNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 15, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.drop1 = nn.Dropout2d(p=0.2)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(55815, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        sim = Aer.get_backend('aer_simulator_statevector')\n",
    "        self.theta_qubit = nn.Parameter(torch.FloatTensor(np.random.uniform(0, 2 * np.pi, size=(self.fc1.out_features,))))\n",
    "        theta_qubit = torch.clamp(theta_qubit, min=0, max=2 * np.pi)\n",
    "        self.hybrid = Hybrid(self.fc1.out_features, sim, 1000, self.theta_qubit)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.hybrid(x)\n",
    "        x = torch.cat((x, 1 - x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained ResNet50 model\n",
    "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Modify the fully connected layer to have 84 outputs\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 84)\n",
    "    \n",
    "        self.drop1 = nn.Dropout(p=0.2)  # Dropout layer to prevent overfitting\n",
    "        self.fc1 = nn.Linear(84, 1)  # Output layer for one output\n",
    "        \n",
    "        # Initialize the quantum simulator backend\n",
    "        sim = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "        self.theta_qubit = nn.Parameter(torch.FloatTensor(np.random.uniform(0, 2 * np.pi, size=(self.fc1.out_features,))))\n",
    "        self.hybrid = Hybrid(self.fc1.out_features, sim, 1000, self.theta_qubit)\n",
    "\n",
    "        print(f\"Initial theta: {self.theta_qubit.tolist()}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.drop1(x) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.hybrid(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.054984Z",
     "start_time": "2024-08-29T20:17:57.050739Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/mnt/c/Users/Win10/Desktop/researchData/data/png/train'\n",
    "test_dir = '/mnt/c/Users/Win10/Desktop/researchData/data/png/test'\n",
    "\n",
    "# Instancia os datasets\n",
    "\n",
    "train_dataset = MammoDataset(root_dir=train_dir, data_augmentation=True)\n",
    "test_dataset = MammoDataset(root_dir=test_dir, train=False)\n",
    "\n",
    "# Cria os DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.844112Z",
     "start_time": "2024-08-29T20:17:57.054984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial theta: [5.08659029006958]\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "class_weight = torch.tensor([1.4261, 3.3469], dtype=torch.float64)\n",
    "loss_func = nn.BCEWithLogitsLoss(pos_weight=class_weight).to(device)\n",
    "quantum_loss_func = nn.BCEWithLogitsLoss(pos_weight=class_weight).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # Clip grad norm depois do backwards = passo os parametros do modelo quantico e classico \n",
    "optimizer_quantum = optim.SGD([model.theta_qubit], lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96)\n",
    "epochs = 10\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T20:17:57.845117Z",
     "start_time": "2024-08-29T20:17:57.845117Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [64, 1] doesn't match the broadcast shape [64, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate classical loss \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m classical_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate quantum loss\u001b[39;00m\n\u001b[1;32m     21\u001b[0m quantum_loss \u001b[38;5;241m=\u001b[39m quantum_loss_func(prediction, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/modules/loss.py:734\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quantumEnvironment/lib/python3.12/site-packages/torch/nn/functional.py:3244\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [64, 1] doesn't match the broadcast shape [64, 2]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.float().unsqueeze(1).to(device) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_quantum.zero_grad() \n",
    "\n",
    "        # Forward pass through the model\n",
    "        prediction = model(image)\n",
    "\n",
    "        # Calculate classical loss \n",
    "        classical_loss = loss_func(prediction, label)\n",
    "\n",
    "        # Calculate quantum loss\n",
    "        quantum_loss = quantum_loss_func(prediction, label)\n",
    "\n",
    "        combined_loss = quantum_loss + classical_loss\n",
    "\n",
    "        # Backward pass and weight updates\n",
    "        combined_loss.backward()  # Backpropagate the combined loss\n",
    "\n",
    "        # Clipping gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        nn.utils.clip_grad_norm_([model.theta_qubit], max_norm=1.0)\n",
    "\n",
    "        # Update classical weights\n",
    "        optimizer.step()\n",
    "        # Update quantum parameters\n",
    "        optimizer_quantum.step()\n",
    "\n",
    "        total_loss.append(combined_loss.item())\n",
    "        print(f\"Batch {batch_idx + 1} completed with total loss: {combined_loss.item():.4f}\")\n",
    "\n",
    "    # Average loss per epoch\n",
    "    avg_loss = np.mean(total_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oy111XeE_cm-"
   },
   "outputs": [],
   "source": [
    "#model_path = '/home/eflammere/QuantumIC/Quantum/models/saved_models/model_epoch_9_2024-10-18_09-08-44.pth'\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "all_labels = [] \n",
    "all_predictions = []  \n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        label = label.unsqueeze(1) \n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        try:\n",
    "            prediction = model(image)\n",
    "            predicted_class = prediction.argmax(dim=1)\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(predicted_class.cpu().numpy())\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GPU Enabled Condensed Version of  multiqubit and multioutput QML-Hybrid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "quantumEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1eb8817a50524ce1af23052011be56f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24f07891b0324ca78c4c7f0beee98566": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f56767fae03484688536b828846b56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "505d1bdc25414cee9dfbc3204dfc0c93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "552e8d190a1d437b920bc7d3f1e1af61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58adc826bab3458ca9cb8e325ce05f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59f8519d3d2144d683558aca466da131": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f1bb84efe844ee2b4fc27afe2a212c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64575c54d09d455281be57a8a0260346": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6611d138ef6e432f8ce0cf52cb1a07c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e827e8d2e88f4c71ae86f3c8538c84c0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ca965b900b1461eaa28f2a6b5398c73",
      "value": 1
     }
    },
    "69d560892ba440f89b50641014d1fd06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ca965b900b1461eaa28f2a6b5398c73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "90586e7287474ecfae458ff3b0a74efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae991db157b34830a4824661dc2ea07d",
       "IPY_MODEL_d9afc24be121433da98462d5ca8d8690"
      ],
      "layout": "IPY_MODEL_f2cd8d5132c444f0b25b353bdcd9d7ab"
     }
    },
    "9255a79718b040bbb8ec080d440304c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eb8817a50524ce1af23052011be56f4",
      "placeholder": "​",
      "style": "IPY_MODEL_24f07891b0324ca78c4c7f0beee98566",
      "value": " 32768/? [00:00&lt;00:00, 369344.38it/s]"
     }
    },
    "9276c41a3c6d41d3b60d31b30be07113": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a29264a8b5e6411eac0d3dae64693251": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe01b032a0c84aa695c9640550aab9fb",
       "IPY_MODEL_9255a79718b040bbb8ec080d440304c5"
      ],
      "layout": "IPY_MODEL_9276c41a3c6d41d3b60d31b30be07113"
     }
    },
    "a530b88ca002433e86872d16c37e551d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505d1bdc25414cee9dfbc3204dfc0c93",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f56767fae03484688536b828846b56a",
      "value": 1
     }
    },
    "ae991db157b34830a4824661dc2ea07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f1bb84efe844ee2b4fc27afe2a212c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef091b36eb3c48dcb0aaf09eec350971",
      "value": 1
     }
    },
    "af12e2a48e7940d0bff7731249e433f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a530b88ca002433e86872d16c37e551d",
       "IPY_MODEL_c30500854da54f07b2345d5cc55deee3"
      ],
      "layout": "IPY_MODEL_59f8519d3d2144d683558aca466da131"
     }
    },
    "b674dba95756437fb8eb209b726e7dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbfbdbd1d45e4de0b32e19125b29f71d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6611d138ef6e432f8ce0cf52cb1a07c4",
       "IPY_MODEL_ff58db68cca442cea4055e678574b2c2"
      ],
      "layout": "IPY_MODEL_552e8d190a1d437b920bc7d3f1e1af61"
     }
    },
    "c30500854da54f07b2345d5cc55deee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d560892ba440f89b50641014d1fd06",
      "placeholder": "​",
      "style": "IPY_MODEL_b674dba95756437fb8eb209b726e7dd8",
      "value": " 9920512/? [00:20&lt;00:00, 42152945.94it/s]"
     }
    },
    "d9afc24be121433da98462d5ca8d8690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de7bb8d497e14b09b1921f670bb59efb",
      "placeholder": "​",
      "style": "IPY_MODEL_f1a712b491b546029d157a17a0d6337e",
      "value": " 8192/? [00:00&lt;00:00, 18970.79it/s]"
     }
    },
    "de7bb8d497e14b09b1921f670bb59efb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e827e8d2e88f4c71ae86f3c8538c84c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea70115f0ada4a769c55113327333393": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef091b36eb3c48dcb0aaf09eec350971": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1a712b491b546029d157a17a0d6337e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2cd8d5132c444f0b25b353bdcd9d7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9cd8031e436418595d28cf344fe2e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe01b032a0c84aa695c9640550aab9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64575c54d09d455281be57a8a0260346",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9cd8031e436418595d28cf344fe2e4f",
      "value": 1
     }
    },
    "ff58db68cca442cea4055e678574b2c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58adc826bab3458ca9cb8e325ce05f2c",
      "placeholder": "​",
      "style": "IPY_MODEL_ea70115f0ada4a769c55113327333393",
      "value": " 1654784/? [00:19&lt;00:00, 138150.43it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
