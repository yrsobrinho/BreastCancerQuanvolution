{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from medmnist import BreastMNIST\n",
    "from medmnist import INFO\n",
    "\n",
    "import pennylane as qml\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "CUDA: 12.4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "info = INFO['breastmnist']\n",
    "data_flag = 'breastmnist'\n",
    "DataClass = BreastMNIST\n",
    "\n",
    "task = info['task']  \n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "print(f\"Number of classes:\", n_classes)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]),\n",
    "    lambda x: x.unsqueeze(0) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset Configuration for 28x28 and 64x64 Images**\n",
    "\n",
    "In the following code, the dataset is configured to use images of size 28x28, which is the default setting for the BreastMNIST dataset (and other similar datasets like MedMNIST). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist.npz\n"
     ]
    }
   ],
   "source": [
    "data_train28 = DataClass(split='train', transform=transform, download=True)\n",
    "data_test28 = DataClass(split='test', transform=transform, download=True)\n",
    "data_eval28 = DataClass(split='val', transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the case you want to use images of size 64x64, the code can be adjusted to load the dataset with this specific size by setting the `size` parameter to 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist_64.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist_64.npz\n",
      "Using downloaded and verified file: /home/eflammere/.medmnist/breastmnist_64.npz\n"
     ]
    }
   ],
   "source": [
    "data_train64 = DataClass(split='train', transform=transform, download=True, size=64)\n",
    "data_test64 = DataClass(split='test', transform=transform, download=True, size=64)\n",
    "data_eval64 = DataClass(split='val', transform=transform, download=True, size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataloader: Train, Test and Validation**\n",
    "\n",
    "The following code snippet demonstrates how to load the training, test, and validation splits of the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of images in training dataset: 546\n",
      "Number of images in test dataset: 156\n",
      "Number of images in validation dataset: 78\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64  \n",
    "dataloader_train = data.DataLoader(dataset=data_train28, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = data.DataLoader(dataset=data_test28, batch_size=batch_size, shuffle=False)\n",
    "dataloader_eval = data.DataLoader(dataset=data_eval28, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nNumber of images in training dataset: {len(data_train28)}\")\n",
    "print(f\"Number of images in test dataset: {len(data_test28)}\")\n",
    "print(f\"Number of images in validation dataset: {len(data_eval28)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Quanvolution**\n",
    "\n",
    "Designed to process an image by applying a quantum circuit to extract features from it. It works similarly to a convolutional layer in a neural network, but instead of using traditional mathematical filters, it leverages a quantum circuit to process small patches of the image and generate new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanvolution(image, circuit, patch_size, n_qubits):\n",
    "    \"\"\"\n",
    "    Perform quanvolution on the input image using the given quantum circuit.\n",
    "    \n",
    "    Args:\n",
    "    - image (ndarray): The input image (2D or 3D with channels).\n",
    "    - circuit (function): The quantum circuit function to extract features.\n",
    "    - patch_size (int): The size of the patches to divide the image into.\n",
    "    - n_qubits (int): Number of qubits in the quantum circuit.\n",
    "    \n",
    "    Returns:\n",
    "    - out (ndarray): The output tensor after quanvolution.\n",
    "    \"\"\"\n",
    "    if image.ndim == 2:\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "    \n",
    "    height_patches = image.shape[0] // patch_size\n",
    "    width_patches = image.shape[1] // patch_size\n",
    "    \n",
    "    out = np.zeros((height_patches, width_patches, n_qubits))\n",
    "    \n",
    "    for j in range(height_patches):\n",
    "        for k in range(width_patches):\n",
    "            patch = []\n",
    "            for i in range(patch_size):\n",
    "                for l in range(patch_size):\n",
    "                    if (j * patch_size + i < image.shape[0]) and (k * patch_size + l < image.shape[1]):\n",
    "                        patch.append(image[j * patch_size + i, k * patch_size + l, 0])\n",
    "                    else:\n",
    "                        patch.append(0)\n",
    "            \n",
    "            q_results = circuit(patch)\n",
    "            \n",
    "            for c in range(n_qubits):\n",
    "                out[j, k, c] = q_results[c]\n",
    "    \n",
    "    return out\n",
    "\n",
    "def quanvolution_batch(images, circuit, patch_size, n_qubits):\n",
    "    \"\"\"\n",
    "    Applies quanvolution to a batch of images.\n",
    "\n",
    "    Args:\n",
    "    - images: Input tensor (batch_size, H, W, C).\n",
    "    - circuit: Quantum circuit used for the quanvolution.\n",
    "    - patch_size: Size of the patches used in the quanvolution.\n",
    "    - n_qubits: Number of qubits in the quantum circuit.\n",
    "\n",
    "    Returns:\n",
    "    - Processed tensor after quanvolution.\n",
    "    \"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    processed = [\n",
    "        quanvolution(images[i].detach().cpu().numpy(), circuit, patch_size, n_qubits)\n",
    "        for i in range(batch_size)\n",
    "    ]\n",
    "\n",
    "    processed = np.array(processed)\n",
    "    return torch.tensor(processed, dtype=torch.float32).to(images.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev = qml.device(\"default.qubit\", wires=4)\n",
    "# # Parâmetros aleatórios para o circuito\n",
    "# n_layers = 2\n",
    "# rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "\n",
    "# @qml.qnode(dev, interface=\"torch\")\n",
    "# def circuit(phi):\n",
    "#     # Codificação de 4 valores de entrada clássicos\n",
    "#     for j in range(4):\n",
    "#         qml.RY(np.pi * phi[j], wires=j)\n",
    "\n",
    "#     # Camadas quânticas aleatórias\n",
    "#     qml.templates.layers.RandomLayers(rand_params, wires=list(range(4)))\n",
    "\n",
    "#     # Medidas produzindo 4 valores clássicos de saída\n",
    "#     return [qml.expval(qml.PauliZ(j)) for j in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY────────────────┤  <Z>\n",
      "1: ──RY──RY─╭●─────────┤  <Z>\n",
      "2: ──RY──RX─│───RZ──RX─┤  <Z>\n",
      "3: ──RY─────╰X─────────┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "# Configurar dispositivo\n",
    "n_qubits = 4\n",
    "n_layers = 1\n",
    "\n",
    "# Parâmetros aleatórios\n",
    "np.random.seed(42)\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, n_qubits))\n",
    "\n",
    "# Definir a função que retorna o dispositivo\n",
    "def get_device(n_qubits):\n",
    "    return qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Definir o circuito com camadas customizadas e RandomLayers\n",
    "def define_circuit(rand_params):\n",
    "    \"\"\"\n",
    "    Define a parametrized quantum circuit with custom layers and RandomLayers.\n",
    "\n",
    "    Args:\n",
    "    - rand_params: Parameters for the circuit layers.\n",
    "\n",
    "    Returns:\n",
    "    - A quantum circuit function (qml.QNode).\n",
    "    \"\"\"\n",
    "    dev = get_device(n_qubits)\n",
    "\n",
    "    @qml.qnode(dev, interface='torch')\n",
    "    def circuit(phi):\n",
    "        # Entrada inicial: aplica rotações baseadas em phi (dados de entrada)\n",
    "        for j in range(n_qubits):\n",
    "            qml.RY(np.pi * phi[j], wires=j)\n",
    "\n",
    "        qml.templates.layers.RandomLayers(rand_params, list(range(n_qubits)))\n",
    "\n",
    "        # Medição: expectativa do operador Pauli-Z em cada qubit\n",
    "        return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]\n",
    "\n",
    "    return circuit\n",
    "\n",
    "rand_circuit = define_circuit(rand_params)\n",
    "\n",
    "phi = np.random.uniform(size=n_qubits)\n",
    "\n",
    "result = rand_circuit(phi)\n",
    "\n",
    "expanded_circuit = rand_circuit.qtape.expand()\n",
    "print(expanded_circuit.draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quanvolution4x1**\n",
    "\n",
    "*4 qubits, 2 layers, 1 quanvolution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quanvolution4x1Model(nn.Module):\n",
    "    def __init__(self, rand_params, output_size = (14, 14), patch_size = 2, n_qubits = 4, num_classes = 2):\n",
    "        \"\"\"\n",
    "        Defines the CNN with quanvolution.\n",
    "\n",
    "        Args:\n",
    "        - rand_params: Parameters of the quantum circuit.\n",
    "        - output_size: Output size after quanvolution.\n",
    "        - n_qubits: Number of qubits in the quantum circuit.\n",
    "        - num_classes: Number of classes for classification.\n",
    "        \"\"\"\n",
    "        super(Quanvolution4x1Model, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_qubits = n_qubits\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.circuit = define_circuit(rand_params)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(output_size[0] * output_size[1] * n_qubits, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Passes the data through the network.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (batch_size, C, H, W).\n",
    "        \n",
    "        Returns:\n",
    "        - Logarithmic probabilities of the classes (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        x = torch.relu(x)\n",
    "        x = self.flatten(x) \n",
    "        x = self.fc(x)  \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quanvolution4x2**\n",
    "\n",
    "*4 qubits, 1 quantum layer per quanvolution, 2 quanvolution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quanvolution4x2Model(nn.Module):\n",
    "    def __init__(self, rand_params, output_size = (14, 14), patch_size = 2, n_qubits = 4, num_classes = 2):\n",
    "        \"\"\"\n",
    "        Defines the CNN with multiple quanvolution layers.\n",
    "\n",
    "        Args:\n",
    "        - rand_params: Parameters of the quantum circuit.\n",
    "        - output_size: Output size after the first quanvolution.\n",
    "        - n_qubits: Number of qubits in the quantum circuit.\n",
    "        - num_classes: Number of classes for classification.\n",
    "        \"\"\"\n",
    "        super(Quanvolution4x2Model, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_qubits = n_qubits\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.circuit = define_circuit(rand_params)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_intermediate = None \n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def initialize_fc_intermediate(self, x):\n",
    "        \"\"\"\n",
    "        Dynamically initializes the intermediate fully connected layer based on the input size.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor after quanvolution.\n",
    "        \"\"\"\n",
    "        if self.fc_intermediate is None:\n",
    "            flattened_size = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "            self.fc_intermediate = nn.Linear(flattened_size, 128).to(x.device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Passes the data through the network.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (batch_size, C, H, W).\n",
    "        \n",
    "        Returns:\n",
    "        - Logarithmic probabilities of the classes (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        #print(x.shape)\n",
    "        x = (x - x.mean()) / (x.std() + 1e-8)\n",
    "        x = torch.relu(x)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        #print(x.shape)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        self.initialize_fc_intermediate(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_intermediate(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quanvolution4x1x1**\n",
    "\n",
    "*4 qubits, 2 quantum layers per quanvolution, 1 convolution, 1 quanvolution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quanvolution4x1x1Model(nn.Module):\n",
    "    def __init__(self, rand_params, output_size=(14, 14), patch_size=2, n_qubits=4, num_classes=2, conv_out_channels=16, kernel_size=3):\n",
    "        \"\"\"\n",
    "        Defines the CNN with multiple quanvolution layers and a classical convolution layer.\n",
    "\n",
    "        Args:\n",
    "        - rand_params: Parameters of the quantum circuit.\n",
    "        - output_size: Output size after the first quanvolution.\n",
    "        - patch_size: Size of the patches for quanvolution.\n",
    "        - n_qubits: Number of qubits in the quantum circuit.\n",
    "        - num_classes: Number of classes for classification.\n",
    "        - conv_out_channels: Number of output channels for the classical convolution.\n",
    "        - kernel_size: Kernel size for the classical convolution.\n",
    "        \"\"\"\n",
    "        super(Quanvolution4x1x1Model, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_qubits = n_qubits\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=conv_out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.circuit = define_circuit(rand_params)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_intermediate = None \n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def initialize_fc_intermediate(self, x):\n",
    "        \"\"\"\n",
    "        Dynamically initializes the intermediate fully connected layer based on the input size.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor after quanvolution.\n",
    "        \"\"\"\n",
    "        if self.fc_intermediate is None:\n",
    "            flattened_size = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "            self.fc_intermediate = nn.Linear(flattened_size, 128).to(x.device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Passes the data through the network.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (batch_size, C, H, W).\n",
    "        \n",
    "        Returns:\n",
    "        - Logarithmic probabilities of the classes (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        self.initialize_fc_intermediate(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_intermediate(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quanvolution4x1x2**\n",
    "\n",
    "*4 qubits, 1 quantum layer per quanvolution, 1 convolution, 2 quanvolution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quanvolution4x1x2Model(nn.Module):\n",
    "    def __init__(self, rand_params, output_size=(14, 14), patch_size=2, n_qubits=4, num_classes=2, conv_out_channels=16, kernel_size=3):\n",
    "        \"\"\"\n",
    "        Defines the CNN with multiple quanvolution layers and a classical convolution layer.\n",
    "\n",
    "        Args:\n",
    "        - rand_params: Parameters of the quantum circuit.\n",
    "        - output_size: Output size after the first quanvolution.\n",
    "        - patch_size: Size of the patches for quanvolution.\n",
    "        - n_qubits: Number of qubits in the quantum circuit.\n",
    "        - num_classes: Number of classes for classification.\n",
    "        - conv_out_channels: Number of output channels for the classical convolution.\n",
    "        - kernel_size: Kernel size for the classical convolution.\n",
    "        \"\"\"\n",
    "        super(Quanvolution4x1x2Model, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_qubits = n_qubits\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=conv_out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.circuit = define_circuit(rand_params)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_intermediate = None \n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def initialize_fc_intermediate(self, x):\n",
    "        \"\"\"\n",
    "        Dynamically initializes the intermediate fully connected layer based on the input size.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor after quanvolution.\n",
    "        \"\"\"\n",
    "        if self.fc_intermediate is None:\n",
    "            flattened_size = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "            self.fc_intermediate = nn.Linear(flattened_size, 128).to(x.device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Passes the data through the network.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (batch_size, C, H, W).\n",
    "        \n",
    "        Returns:\n",
    "        - Logarithmic probabilities of the classes (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        self.initialize_fc_intermediate(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_intermediate(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quanvolution4x2x2Model(nn.Module):\n",
    "    def __init__(self, rand_params, output_size=(14, 14), patch_size=2, n_qubits=4, num_classes=2, conv_out_channels=16, kernel_size=3):\n",
    "        \"\"\"\n",
    "        Defines the CNN with multiple quanvolution layers and a classical convolution layer.\n",
    "\n",
    "        Args:\n",
    "        - rand_params: Parameters of the quantum circuit.\n",
    "        - output_size: Output size after the first quanvolution.\n",
    "        - patch_size: Size of the patches for quanvolution.\n",
    "        - n_qubits: Number of qubits in the quantum circuit.\n",
    "        - num_classes: Number of classes for classification.\n",
    "        - conv_out_channels: Number of output channels for the classical convolution.\n",
    "        - kernel_size: Kernel size for the classical convolution.\n",
    "        \"\"\"\n",
    "        super(Quanvolution4x2x2Model, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_qubits = n_qubits\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=conv_out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.circuit = define_circuit(rand_params)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_intermediate = None \n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def initialize_fc_intermediate(self, x):\n",
    "        \"\"\"\n",
    "        Dynamically initializes the intermediate fully connected layer based on the input size.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor after quanvolution.\n",
    "        \"\"\"\n",
    "        if self.fc_intermediate is None:\n",
    "            flattened_size = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "            self.fc_intermediate = nn.Linear(flattened_size, 128).to(x.device)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Passes the data through the network.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (batch_size, C, H, W).\n",
    "        \n",
    "        Returns:\n",
    "        - Logarithmic probabilities of the classes (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        self.initialize_fc_intermediate(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_intermediate(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Quanvolution4x2Model(rand_params).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight: Gradiente médio 0.022824741899967194\n",
      "fc.bias: Gradiente médio 0.19533714652061462\n",
      "fc_intermediate.weight: Gradiente médio 0.00191694893874228\n",
      "fc_intermediate.bias: Gradiente médio 0.0071063111536204815\n",
      "Epoch 1 Batch 1/9 Loss: 0.6825\n",
      "fc.weight: Gradiente médio 0.02044595405459404\n",
      "fc.bias: Gradiente médio 0.1570284068584442\n",
      "fc_intermediate.weight: Gradiente médio 0.0035692343953996897\n",
      "fc_intermediate.bias: Gradiente médio 0.013260073959827423\n",
      "Epoch 1 Batch 2/9 Loss: 0.6079\n",
      "fc.weight: Gradiente médio 0.006601417902857065\n",
      "fc.bias: Gradiente médio 0.03316666558384895\n",
      "fc_intermediate.weight: Gradiente médio 0.003910827916115522\n",
      "fc_intermediate.bias: Gradiente médio 0.014175163581967354\n",
      "Epoch 1 Batch 3/9 Loss: 0.6180\n",
      "fc.weight: Gradiente médio 0.007959913462400436\n",
      "fc.bias: Gradiente médio 0.0494462251663208\n",
      "fc_intermediate.weight: Gradiente médio 0.0039052870124578476\n",
      "fc_intermediate.bias: Gradiente médio 0.012663496658205986\n",
      "Epoch 1 Batch 4/9 Loss: 0.6325\n",
      "fc.weight: Gradiente médio 0.005058727227151394\n",
      "fc.bias: Gradiente médio 0.023846156895160675\n",
      "fc_intermediate.weight: Gradiente médio 0.004379673395305872\n",
      "fc_intermediate.bias: Gradiente médio 0.013719659298658371\n",
      "Epoch 1 Batch 5/9 Loss: 0.5366\n",
      "fc.weight: Gradiente médio 0.008791984990239143\n",
      "fc.bias: Gradiente médio 0.05181995406746864\n",
      "fc_intermediate.weight: Gradiente médio 0.004564766772091389\n",
      "fc_intermediate.bias: Gradiente médio 0.012312555685639381\n",
      "Epoch 1 Batch 6/9 Loss: 0.6055\n",
      "fc.weight: Gradiente médio 0.0057387081906199455\n",
      "fc.bias: Gradiente médio 0.023756859824061394\n",
      "fc_intermediate.weight: Gradiente médio 0.00493155512958765\n",
      "fc_intermediate.bias: Gradiente médio 0.012173797003924847\n",
      "Epoch 1 Batch 7/9 Loss: 0.5492\n",
      "fc.weight: Gradiente médio 0.006774526555091143\n",
      "fc.bias: Gradiente médio 0.0312516875565052\n",
      "fc_intermediate.weight: Gradiente médio 0.00526529410853982\n",
      "fc_intermediate.bias: Gradiente médio 0.01210081297904253\n",
      "Epoch 1 Batch 8/9 Loss: 0.5457\n",
      "fc.weight: Gradiente médio 0.012898980639874935\n",
      "fc.bias: Gradiente médio 0.09540808200836182\n",
      "fc_intermediate.weight: Gradiente médio 0.005956846754997969\n",
      "fc_intermediate.bias: Gradiente médio 0.011828295886516571\n",
      "Epoch 1 Batch 9/9 Loss: 0.6049\n",
      "Epoch 1 Training Loss: 0.5981\n",
      "fc.weight: Gradiente médio 0.00839938037097454\n",
      "fc.bias: Gradiente médio 0.05902376025915146\n",
      "fc_intermediate.weight: Gradiente médio 0.006700560450553894\n",
      "fc_intermediate.bias: Gradiente médio 0.013948721811175346\n",
      "Epoch 2 Batch 1/9 Loss: 0.5798\n",
      "fc.weight: Gradiente médio 0.005356001667678356\n",
      "fc.bias: Gradiente médio 0.025919824838638306\n",
      "fc_intermediate.weight: Gradiente médio 0.007206495385617018\n",
      "fc_intermediate.bias: Gradiente médio 0.015336629003286362\n",
      "Epoch 2 Batch 2/9 Loss: 0.5469\n",
      "fc.weight: Gradiente médio 0.01145855337381363\n",
      "fc.bias: Gradiente médio 0.06773105263710022\n",
      "fc_intermediate.weight: Gradiente médio 0.008342762477695942\n",
      "fc_intermediate.bias: Gradiente médio 0.018577171489596367\n",
      "Epoch 2 Batch 3/9 Loss: 0.5777\n",
      "fc.weight: Gradiente médio 0.007887281477451324\n",
      "fc.bias: Gradiente médio 0.01848241314291954\n",
      "fc_intermediate.weight: Gradiente médio 0.009334263391792774\n",
      "fc_intermediate.bias: Gradiente médio 0.020614204928278923\n",
      "Epoch 2 Batch 4/9 Loss: 0.5411\n",
      "fc.weight: Gradiente médio 0.006653738673776388\n",
      "fc.bias: Gradiente médio 0.028087187558412552\n",
      "fc_intermediate.weight: Gradiente médio 0.01017826795578003\n",
      "fc_intermediate.bias: Gradiente médio 0.02239193767309189\n",
      "Epoch 2 Batch 5/9 Loss: 0.5612\n",
      "fc.weight: Gradiente médio 0.012734359130263329\n",
      "fc.bias: Gradiente médio 0.07990234345197678\n",
      "fc_intermediate.weight: Gradiente médio 0.011443648487329483\n",
      "fc_intermediate.bias: Gradiente médio 0.026406992226839066\n",
      "Epoch 2 Batch 6/9 Loss: 0.6358\n",
      "fc.weight: Gradiente médio 0.01223490759730339\n",
      "fc.bias: Gradiente médio 0.10700090229511261\n",
      "fc_intermediate.weight: Gradiente médio 0.011279934085905552\n",
      "fc_intermediate.bias: Gradiente médio 0.023527849465608597\n",
      "Epoch 2 Batch 7/9 Loss: 0.5349\n",
      "fc.weight: Gradiente médio 0.017103182151913643\n",
      "fc.bias: Gradiente médio 0.1316554844379425\n",
      "fc_intermediate.weight: Gradiente médio 0.011027691885828972\n",
      "fc_intermediate.bias: Gradiente médio 0.021328790113329887\n",
      "Epoch 2 Batch 8/9 Loss: 0.5267\n",
      "fc.weight: Gradiente médio 0.0059042396023869514\n",
      "fc.bias: Gradiente médio 0.009474169462919235\n",
      "fc_intermediate.weight: Gradiente médio 0.01166568323969841\n",
      "fc_intermediate.bias: Gradiente médio 0.022273899987339973\n",
      "Epoch 2 Batch 9/9 Loss: 0.5921\n",
      "Epoch 2 Training Loss: 0.5662\n",
      "fc.weight: Gradiente médio 0.00915242824703455\n",
      "fc.bias: Gradiente médio 0.05615954473614693\n",
      "fc_intermediate.weight: Gradiente médio 0.012471816502511501\n",
      "fc_intermediate.bias: Gradiente médio 0.02413879707455635\n",
      "Epoch 3 Batch 1/9 Loss: 0.6126\n",
      "fc.weight: Gradiente médio 0.013864449225366116\n",
      "fc.bias: Gradiente médio 0.10016963630914688\n",
      "fc_intermediate.weight: Gradiente médio 0.012547577731311321\n",
      "fc_intermediate.bias: Gradiente médio 0.024376995861530304\n",
      "Epoch 3 Batch 2/9 Loss: 0.5771\n",
      "fc.weight: Gradiente médio 0.008530687540769577\n",
      "fc.bias: Gradiente médio 0.058758944272994995\n",
      "fc_intermediate.weight: Gradiente médio 0.013468070887029171\n",
      "fc_intermediate.bias: Gradiente médio 0.026433996856212616\n",
      "Epoch 3 Batch 3/9 Loss: 0.5115\n",
      "fc.weight: Gradiente médio 0.014022912830114365\n",
      "fc.bias: Gradiente médio 0.10735715925693512\n",
      "fc_intermediate.weight: Gradiente médio 0.014110148884356022\n",
      "fc_intermediate.bias: Gradiente médio 0.03006691113114357\n",
      "Epoch 3 Batch 4/9 Loss: 0.5121\n",
      "fc.weight: Gradiente médio 0.0053873565047979355\n",
      "fc.bias: Gradiente médio 0.026313520967960358\n",
      "fc_intermediate.weight: Gradiente médio 0.01472387369722128\n",
      "fc_intermediate.bias: Gradiente médio 0.0318816639482975\n",
      "Epoch 3 Batch 5/9 Loss: 0.5651\n",
      "fc.weight: Gradiente médio 0.017973463982343674\n",
      "fc.bias: Gradiente médio 0.1477774679660797\n",
      "fc_intermediate.weight: Gradiente médio 0.01565600372850895\n",
      "fc_intermediate.bias: Gradiente médio 0.038883600383996964\n",
      "Epoch 3 Batch 6/9 Loss: 0.4280\n",
      "fc.weight: Gradiente médio 0.0048660216853022575\n",
      "fc.bias: Gradiente médio 0.009317038580775261\n",
      "fc_intermediate.weight: Gradiente médio 0.01624828204512596\n",
      "fc_intermediate.bias: Gradiente médio 0.04052591323852539\n",
      "Epoch 3 Batch 7/9 Loss: 0.5360\n",
      "fc.weight: Gradiente médio 0.012801019474864006\n",
      "fc.bias: Gradiente médio 0.08756133913993835\n",
      "fc_intermediate.weight: Gradiente médio 0.01644892618060112\n",
      "fc_intermediate.bias: Gradiente médio 0.03670286014676094\n",
      "Epoch 3 Batch 8/9 Loss: 0.6349\n",
      "fc.weight: Gradiente médio 0.00954577885568142\n",
      "fc.bias: Gradiente médio 0.05163288116455078\n",
      "fc_intermediate.weight: Gradiente médio 0.017480352893471718\n",
      "fc_intermediate.bias: Gradiente médio 0.03665216267108917\n",
      "Epoch 3 Batch 9/9 Loss: 0.5433\n",
      "Epoch 3 Training Loss: 0.5467\n",
      "fc.weight: Gradiente médio 0.01800590753555298\n",
      "fc.bias: Gradiente médio 0.13302081823349\n",
      "fc_intermediate.weight: Gradiente médio 0.01848542131483555\n",
      "fc_intermediate.bias: Gradiente médio 0.034949127584695816\n",
      "Epoch 4 Batch 1/9 Loss: 0.6342\n",
      "fc.weight: Gradiente médio 0.008773562498390675\n",
      "fc.bias: Gradiente médio 0.06420985609292984\n",
      "fc_intermediate.weight: Gradiente médio 0.019047457724809647\n",
      "fc_intermediate.bias: Gradiente médio 0.03658933937549591\n",
      "Epoch 4 Batch 2/9 Loss: 0.4239\n",
      "fc.weight: Gradiente médio 0.00816548801958561\n",
      "fc.bias: Gradiente médio 0.06022193282842636\n",
      "fc_intermediate.weight: Gradiente médio 0.01959000527858734\n",
      "fc_intermediate.bias: Gradiente médio 0.0363549068570137\n",
      "Epoch 4 Batch 3/9 Loss: 0.5915\n",
      "fc.weight: Gradiente médio 0.00479529844596982\n",
      "fc.bias: Gradiente médio 0.015561103820800781\n",
      "fc_intermediate.weight: Gradiente médio 0.020173801109194756\n",
      "fc_intermediate.bias: Gradiente médio 0.03710171580314636\n",
      "Epoch 4 Batch 4/9 Loss: 0.5445\n",
      "fc.weight: Gradiente médio 0.005657657980918884\n",
      "fc.bias: Gradiente médio 0.042890582233667374\n",
      "fc_intermediate.weight: Gradiente médio 0.020851051434874535\n",
      "fc_intermediate.bias: Gradiente médio 0.03828859701752663\n",
      "Epoch 4 Batch 5/9 Loss: 0.5780\n",
      "fc.weight: Gradiente médio 0.005142430774867535\n",
      "fc.bias: Gradiente médio 0.012458361685276031\n",
      "fc_intermediate.weight: Gradiente médio 0.021768223494291306\n",
      "fc_intermediate.bias: Gradiente médio 0.04005321115255356\n",
      "Epoch 4 Batch 6/9 Loss: 0.4795\n",
      "fc.weight: Gradiente médio 0.005464909598231316\n",
      "fc.bias: Gradiente médio 0.02453739568591118\n",
      "fc_intermediate.weight: Gradiente médio 0.022698499262332916\n",
      "fc_intermediate.bias: Gradiente médio 0.04189768433570862\n",
      "Epoch 4 Batch 7/9 Loss: 0.4624\n",
      "fc.weight: Gradiente médio 0.0052331676706671715\n",
      "fc.bias: Gradiente médio 0.013204747810959816\n",
      "fc_intermediate.weight: Gradiente médio 0.022993892431259155\n",
      "fc_intermediate.bias: Gradiente médio 0.04223395138978958\n",
      "Epoch 4 Batch 8/9 Loss: 0.5382\n",
      "fc.weight: Gradiente médio 0.009960506111383438\n",
      "fc.bias: Gradiente médio 0.058317311108112335\n",
      "fc_intermediate.weight: Gradiente médio 0.024427929893136024\n",
      "fc_intermediate.bias: Gradiente médio 0.045431531965732574\n",
      "Epoch 4 Batch 9/9 Loss: 0.5234\n",
      "Epoch 4 Training Loss: 0.5306\n",
      "fc.weight: Gradiente médio 0.006548036355525255\n",
      "fc.bias: Gradiente médio 0.03984437137842178\n",
      "fc_intermediate.weight: Gradiente médio 0.024797869846224785\n",
      "fc_intermediate.bias: Gradiente médio 0.04607770964503288\n",
      "Epoch 5 Batch 1/9 Loss: 0.5131\n",
      "fc.weight: Gradiente médio 0.007088400423526764\n",
      "fc.bias: Gradiente médio 0.0562882125377655\n",
      "fc_intermediate.weight: Gradiente médio 0.025737229734659195\n",
      "fc_intermediate.bias: Gradiente médio 0.047781772911548615\n",
      "Epoch 5 Batch 2/9 Loss: 0.4598\n",
      "fc.weight: Gradiente médio 0.00805898942053318\n",
      "fc.bias: Gradiente médio 0.059276033192873\n",
      "fc_intermediate.weight: Gradiente médio 0.026541927829384804\n",
      "fc_intermediate.bias: Gradiente médio 0.04917598143219948\n",
      "Epoch 5 Batch 3/9 Loss: 0.5899\n",
      "fc.weight: Gradiente médio 0.0060582514852285385\n",
      "fc.bias: Gradiente médio 0.03134762868285179\n",
      "fc_intermediate.weight: Gradiente médio 0.02752380631864071\n",
      "fc_intermediate.bias: Gradiente médio 0.05113699287176132\n",
      "Epoch 5 Batch 4/9 Loss: 0.5525\n",
      "fc.weight: Gradiente médio 0.008438792079687119\n",
      "fc.bias: Gradiente médio 0.055695414543151855\n",
      "fc_intermediate.weight: Gradiente médio 0.027676749974489212\n",
      "fc_intermediate.bias: Gradiente médio 0.05126698315143585\n",
      "Epoch 5 Batch 5/9 Loss: 0.5370\n",
      "fc.weight: Gradiente médio 0.004688672721385956\n",
      "fc.bias: Gradiente médio 0.01849709264934063\n",
      "fc_intermediate.weight: Gradiente médio 0.028689837083220482\n",
      "fc_intermediate.bias: Gradiente médio 0.05312567204236984\n",
      "Epoch 5 Batch 6/9 Loss: 0.5409\n",
      "fc.weight: Gradiente médio 0.006936023943126202\n",
      "fc.bias: Gradiente médio 0.05184798687696457\n",
      "fc_intermediate.weight: Gradiente médio 0.02953004278242588\n",
      "fc_intermediate.bias: Gradiente médio 0.0552246980369091\n",
      "Epoch 5 Batch 7/9 Loss: 0.4727\n",
      "fc.weight: Gradiente médio 0.005156835075467825\n",
      "fc.bias: Gradiente médio 0.031497158110141754\n",
      "fc_intermediate.weight: Gradiente médio 0.030347760766744614\n",
      "fc_intermediate.bias: Gradiente médio 0.0574381947517395\n",
      "Epoch 5 Batch 8/9 Loss: 0.5305\n",
      "fc.weight: Gradiente médio 0.017568711191415787\n",
      "fc.bias: Gradiente médio 0.1299489289522171\n",
      "fc_intermediate.weight: Gradiente médio 0.03096606768667698\n",
      "fc_intermediate.bias: Gradiente médio 0.06300212442874908\n",
      "Epoch 5 Batch 9/9 Loss: 0.4501\n",
      "Epoch 5 Training Loss: 0.5163\n",
      "fc.weight: Gradiente médio 0.004540395922958851\n",
      "fc.bias: Gradiente médio 0.011920537799596786\n",
      "fc_intermediate.weight: Gradiente médio 0.03185902163386345\n",
      "fc_intermediate.bias: Gradiente médio 0.0640186071395874\n",
      "Epoch 6 Batch 1/9 Loss: 0.5174\n",
      "fc.weight: Gradiente médio 0.004590407479554415\n",
      "fc.bias: Gradiente médio 0.016904685646295547\n",
      "fc_intermediate.weight: Gradiente médio 0.033043213188648224\n",
      "fc_intermediate.bias: Gradiente médio 0.06558351218700409\n",
      "Epoch 6 Batch 2/9 Loss: 0.4835\n",
      "fc.weight: Gradiente médio 0.01582978293299675\n",
      "fc.bias: Gradiente médio 0.12366306036710739\n",
      "fc_intermediate.weight: Gradiente médio 0.03395964950323105\n",
      "fc_intermediate.bias: Gradiente médio 0.07363895326852798\n",
      "Epoch 6 Batch 3/9 Loss: 0.4044\n",
      "fc.weight: Gradiente médio 0.007452679332345724\n",
      "fc.bias: Gradiente médio 0.05756759271025658\n",
      "fc_intermediate.weight: Gradiente médio 0.03472771868109703\n",
      "fc_intermediate.bias: Gradiente médio 0.07817714661359787\n",
      "Epoch 6 Batch 4/9 Loss: 0.4452\n",
      "fc.weight: Gradiente médio 0.012185044586658478\n",
      "fc.bias: Gradiente médio 0.09117774665355682\n",
      "fc_intermediate.weight: Gradiente médio 0.03516913950443268\n",
      "fc_intermediate.bias: Gradiente médio 0.0730200707912445\n",
      "Epoch 6 Batch 5/9 Loss: 0.6178\n",
      "fc.weight: Gradiente médio 0.005629749968647957\n",
      "fc.bias: Gradiente médio 0.03405585139989853\n",
      "fc_intermediate.weight: Gradiente médio 0.03540511056780815\n",
      "fc_intermediate.bias: Gradiente médio 0.07091005146503448\n",
      "Epoch 6 Batch 6/9 Loss: 0.5467\n",
      "fc.weight: Gradiente médio 0.0034555410966277122\n",
      "fc.bias: Gradiente médio 0.007378291338682175\n",
      "fc_intermediate.weight: Gradiente médio 0.03637927398085594\n",
      "fc_intermediate.bias: Gradiente médio 0.0725824236869812\n",
      "Epoch 6 Batch 7/9 Loss: 0.4573\n",
      "fc.weight: Gradiente médio 0.013890940696001053\n",
      "fc.bias: Gradiente médio 0.10139651596546173\n",
      "fc_intermediate.weight: Gradiente médio 0.03752678260207176\n",
      "fc_intermediate.bias: Gradiente médio 0.07075490802526474\n",
      "Epoch 6 Batch 8/9 Loss: 0.5744\n",
      "fc.weight: Gradiente médio 0.024895712733268738\n",
      "fc.bias: Gradiente médio 0.19209036231040955\n",
      "fc_intermediate.weight: Gradiente médio 0.039002928882837296\n",
      "fc_intermediate.bias: Gradiente médio 0.07548204809427261\n",
      "Epoch 6 Batch 9/9 Loss: 0.6865\n",
      "Epoch 6 Training Loss: 0.5259\n",
      "fc.weight: Gradiente médio 0.007913412526249886\n",
      "fc.bias: Gradiente médio 0.049584101885557175\n",
      "fc_intermediate.weight: Gradiente médio 0.040261976420879364\n",
      "fc_intermediate.bias: Gradiente médio 0.07818406820297241\n",
      "Epoch 7 Batch 1/9 Loss: 0.5811\n",
      "fc.weight: Gradiente médio 0.004418566823005676\n",
      "fc.bias: Gradiente médio 0.0006046993657946587\n",
      "fc_intermediate.weight: Gradiente médio 0.041521646082401276\n",
      "fc_intermediate.bias: Gradiente médio 0.07975849509239197\n",
      "Epoch 7 Batch 2/9 Loss: 0.4400\n",
      "fc.weight: Gradiente médio 0.008014767430722713\n",
      "fc.bias: Gradiente médio 0.05050745606422424\n",
      "fc_intermediate.weight: Gradiente médio 0.042681556195020676\n",
      "fc_intermediate.bias: Gradiente médio 0.08325520157814026\n",
      "Epoch 7 Batch 3/9 Loss: 0.5706\n",
      "fc.weight: Gradiente médio 0.01498460490256548\n",
      "fc.bias: Gradiente médio 0.11449483782052994\n",
      "fc_intermediate.weight: Gradiente médio 0.04257480427622795\n",
      "fc_intermediate.bias: Gradiente médio 0.08137784898281097\n",
      "Epoch 7 Batch 4/9 Loss: 0.4583\n",
      "fc.weight: Gradiente médio 0.00873597338795662\n",
      "fc.bias: Gradiente médio 0.06155475601553917\n",
      "fc_intermediate.weight: Gradiente médio 0.04315721616148949\n",
      "fc_intermediate.bias: Gradiente médio 0.08257925510406494\n",
      "Epoch 7 Batch 5/9 Loss: 0.4372\n",
      "fc.weight: Gradiente médio 0.007298964075744152\n",
      "fc.bias: Gradiente médio 0.053131867200136185\n",
      "fc_intermediate.weight: Gradiente médio 0.04389774054288864\n",
      "fc_intermediate.bias: Gradiente médio 0.08325635641813278\n",
      "Epoch 7 Batch 6/9 Loss: 0.5504\n",
      "fc.weight: Gradiente médio 0.0043311212211847305\n",
      "fc.bias: Gradiente médio 0.012634653598070145\n",
      "fc_intermediate.weight: Gradiente médio 0.04490814357995987\n",
      "fc_intermediate.bias: Gradiente médio 0.0858343243598938\n",
      "Epoch 7 Batch 7/9 Loss: 0.5132\n",
      "fc.weight: Gradiente médio 0.004224042408168316\n",
      "fc.bias: Gradiente médio 0.014297274872660637\n",
      "fc_intermediate.weight: Gradiente médio 0.04573884233832359\n",
      "fc_intermediate.bias: Gradiente médio 0.08780272305011749\n",
      "Epoch 7 Batch 8/9 Loss: 0.5409\n",
      "fc.weight: Gradiente médio 0.013082079589366913\n",
      "fc.bias: Gradiente médio 0.09139237552881241\n",
      "fc_intermediate.weight: Gradiente médio 0.046006444841623306\n",
      "fc_intermediate.bias: Gradiente médio 0.08908628672361374\n",
      "Epoch 7 Batch 9/9 Loss: 0.4786\n",
      "Epoch 7 Training Loss: 0.5078\n",
      "fc.weight: Gradiente médio 0.014520646072924137\n",
      "fc.bias: Gradiente médio 0.10905493795871735\n",
      "fc_intermediate.weight: Gradiente médio 0.046869393438100815\n",
      "fc_intermediate.bias: Gradiente médio 0.09483576565980911\n",
      "Epoch 8 Batch 1/9 Loss: 0.4490\n",
      "fc.weight: Gradiente médio 0.006232755724340677\n",
      "fc.bias: Gradiente médio 0.03444620966911316\n",
      "fc_intermediate.weight: Gradiente médio 0.04802725091576576\n",
      "fc_intermediate.bias: Gradiente médio 0.09481848031282425\n",
      "Epoch 8 Batch 2/9 Loss: 0.5526\n",
      "fc.weight: Gradiente médio 0.0050543830730021\n",
      "fc.bias: Gradiente médio 0.023653417825698853\n",
      "fc_intermediate.weight: Gradiente médio 0.04901184141635895\n",
      "fc_intermediate.bias: Gradiente médio 0.09840992093086243\n",
      "Epoch 8 Batch 3/9 Loss: 0.4543\n",
      "fc.weight: Gradiente médio 0.006486615166068077\n",
      "fc.bias: Gradiente médio 0.027513787150382996\n",
      "fc_intermediate.weight: Gradiente médio 0.0501427948474884\n",
      "fc_intermediate.bias: Gradiente médio 0.09978944063186646\n",
      "Epoch 8 Batch 4/9 Loss: 0.5551\n",
      "fc.weight: Gradiente médio 0.0041549596935510635\n",
      "fc.bias: Gradiente médio 0.010095616802573204\n",
      "fc_intermediate.weight: Gradiente médio 0.051172833889722824\n",
      "fc_intermediate.bias: Gradiente médio 0.10253683477640152\n",
      "Epoch 8 Batch 5/9 Loss: 0.4286\n",
      "fc.weight: Gradiente médio 0.006932171061635017\n",
      "fc.bias: Gradiente médio 0.04655739292502403\n",
      "fc_intermediate.weight: Gradiente médio 0.05204121023416519\n",
      "fc_intermediate.bias: Gradiente médio 0.10127376765012741\n",
      "Epoch 8 Batch 6/9 Loss: 0.5294\n",
      "fc.weight: Gradiente médio 0.004334114957600832\n",
      "fc.bias: Gradiente médio 0.020487824454903603\n",
      "fc_intermediate.weight: Gradiente médio 0.05258923023939133\n",
      "fc_intermediate.bias: Gradiente médio 0.10216845571994781\n",
      "Epoch 8 Batch 7/9 Loss: 0.4968\n",
      "fc.weight: Gradiente médio 0.00505625456571579\n",
      "fc.bias: Gradiente médio 0.02591433748602867\n",
      "fc_intermediate.weight: Gradiente médio 0.053076256066560745\n",
      "fc_intermediate.bias: Gradiente médio 0.10248994827270508\n",
      "Epoch 8 Batch 8/9 Loss: 0.5469\n",
      "fc.weight: Gradiente médio 0.008089118637144566\n",
      "fc.bias: Gradiente médio 0.028244048357009888\n",
      "fc_intermediate.weight: Gradiente médio 0.05386939272284508\n",
      "fc_intermediate.bias: Gradiente médio 0.10411816835403442\n",
      "Epoch 8 Batch 9/9 Loss: 0.5086\n",
      "Epoch 8 Training Loss: 0.5024\n",
      "fc.weight: Gradiente médio 0.0040664407424628735\n",
      "fc.bias: Gradiente médio 0.016727101057767868\n",
      "fc_intermediate.weight: Gradiente médio 0.054988693445920944\n",
      "fc_intermediate.bias: Gradiente médio 0.10693256556987762\n",
      "Epoch 9 Batch 1/9 Loss: 0.4225\n",
      "fc.weight: Gradiente médio 0.006510681007057428\n",
      "fc.bias: Gradiente médio 0.036690615117549896\n",
      "fc_intermediate.weight: Gradiente médio 0.055887460708618164\n",
      "fc_intermediate.bias: Gradiente médio 0.10720469057559967\n",
      "Epoch 9 Batch 2/9 Loss: 0.5801\n",
      "fc.weight: Gradiente médio 0.004957268945872784\n",
      "fc.bias: Gradiente médio 0.025776050984859467\n",
      "fc_intermediate.weight: Gradiente médio 0.056462906301021576\n",
      "fc_intermediate.bias: Gradiente médio 0.10787534713745117\n",
      "Epoch 9 Batch 3/9 Loss: 0.4592\n",
      "fc.weight: Gradiente médio 0.004808300174772739\n",
      "fc.bias: Gradiente médio 0.019197020679712296\n",
      "fc_intermediate.weight: Gradiente médio 0.05720941349864006\n",
      "fc_intermediate.bias: Gradiente médio 0.1095152497291565\n",
      "Epoch 9 Batch 4/9 Loss: 0.5359\n",
      "fc.weight: Gradiente médio 0.008312473073601723\n",
      "fc.bias: Gradiente médio 0.05946929752826691\n",
      "fc_intermediate.weight: Gradiente médio 0.058016445487737656\n",
      "fc_intermediate.bias: Gradiente médio 0.11230863630771637\n",
      "Epoch 9 Batch 5/9 Loss: 0.4081\n",
      "fc.weight: Gradiente médio 0.00693069864064455\n",
      "fc.bias: Gradiente médio 0.050132568925619125\n",
      "fc_intermediate.weight: Gradiente médio 0.05896101891994476\n",
      "fc_intermediate.bias: Gradiente médio 0.11256441473960876\n",
      "Epoch 9 Batch 6/9 Loss: 0.5652\n",
      "fc.weight: Gradiente médio 0.016303781419992447\n",
      "fc.bias: Gradiente médio 0.11523891985416412\n",
      "fc_intermediate.weight: Gradiente médio 0.06090482696890831\n",
      "fc_intermediate.bias: Gradiente médio 0.11666832864284515\n",
      "Epoch 9 Batch 7/9 Loss: 0.5465\n",
      "fc.weight: Gradiente médio 0.005751786753535271\n",
      "fc.bias: Gradiente médio 0.034427106380462646\n",
      "fc_intermediate.weight: Gradiente médio 0.061777420341968536\n",
      "fc_intermediate.bias: Gradiente médio 0.11848501861095428\n",
      "Epoch 9 Batch 8/9 Loss: 0.5146\n",
      "fc.weight: Gradiente médio 0.012141588144004345\n",
      "fc.bias: Gradiente médio 0.09178495407104492\n",
      "fc_intermediate.weight: Gradiente médio 0.06225832924246788\n",
      "fc_intermediate.bias: Gradiente médio 0.11842885613441467\n",
      "Epoch 9 Batch 9/9 Loss: 0.3938\n",
      "Epoch 9 Training Loss: 0.4918\n",
      "fc.weight: Gradiente médio 0.004538333509117365\n",
      "fc.bias: Gradiente médio 0.0008803736418485641\n",
      "fc_intermediate.weight: Gradiente médio 0.063196562230587\n",
      "fc_intermediate.bias: Gradiente médio 0.12010467052459717\n",
      "Epoch 10 Batch 1/9 Loss: 0.4824\n",
      "fc.weight: Gradiente médio 0.01038144901394844\n",
      "fc.bias: Gradiente médio 0.07765321433544159\n",
      "fc_intermediate.weight: Gradiente médio 0.06388682872056961\n",
      "fc_intermediate.bias: Gradiente médio 0.12265420705080032\n",
      "Epoch 10 Batch 2/9 Loss: 0.4690\n",
      "fc.weight: Gradiente médio 0.006220868788659573\n",
      "fc.bias: Gradiente médio 0.03411561995744705\n",
      "fc_intermediate.weight: Gradiente médio 0.06489182263612747\n",
      "fc_intermediate.bias: Gradiente médio 0.12324617803096771\n",
      "Epoch 10 Batch 3/9 Loss: 0.5242\n",
      "fc.weight: Gradiente médio 0.00402508769184351\n",
      "fc.bias: Gradiente médio 0.01817680522799492\n",
      "fc_intermediate.weight: Gradiente médio 0.06595603376626968\n",
      "fc_intermediate.bias: Gradiente médio 0.1250247359275818\n",
      "Epoch 10 Batch 4/9 Loss: 0.4995\n",
      "fc.weight: Gradiente médio 0.006184377707540989\n",
      "fc.bias: Gradiente médio 0.040166664868593216\n",
      "fc_intermediate.weight: Gradiente médio 0.06713677197694778\n",
      "fc_intermediate.bias: Gradiente médio 0.12878389656543732\n",
      "Epoch 10 Batch 5/9 Loss: 0.4635\n",
      "fc.weight: Gradiente médio 0.006636911537498236\n",
      "fc.bias: Gradiente médio 0.03666979819536209\n",
      "fc_intermediate.weight: Gradiente médio 0.06786274164915085\n",
      "fc_intermediate.bias: Gradiente médio 0.12918545305728912\n",
      "Epoch 10 Batch 6/9 Loss: 0.5668\n",
      "fc.weight: Gradiente médio 0.008023001253604889\n",
      "fc.bias: Gradiente médio 0.05831465870141983\n",
      "fc_intermediate.weight: Gradiente médio 0.06887289136648178\n",
      "fc_intermediate.bias: Gradiente médio 0.13323412835597992\n",
      "Epoch 10 Batch 7/9 Loss: 0.4569\n",
      "fc.weight: Gradiente médio 0.0037868055514991283\n",
      "fc.bias: Gradiente médio 4.393234848976135e-05\n",
      "fc_intermediate.weight: Gradiente médio 0.06964915245771408\n",
      "fc_intermediate.bias: Gradiente médio 0.13420292735099792\n",
      "Epoch 10 Batch 8/9 Loss: 0.4673\n",
      "fc.weight: Gradiente médio 0.006341804284602404\n",
      "fc.bias: Gradiente médio 0.0003350991755723953\n",
      "fc_intermediate.weight: Gradiente médio 0.07082011550664902\n",
      "fc_intermediate.bias: Gradiente médio 0.1364361196756363\n",
      "Epoch 10 Batch 9/9 Loss: 0.5080\n",
      "Epoch 10 Training Loss: 0.4931\n",
      "fc.weight: Gradiente médio 0.005600073374807835\n",
      "fc.bias: Gradiente médio 0.0215417742729187\n",
      "fc_intermediate.weight: Gradiente médio 0.0717860609292984\n",
      "fc_intermediate.bias: Gradiente médio 0.13806873559951782\n",
      "Epoch 11 Batch 1/9 Loss: 0.5654\n",
      "fc.weight: Gradiente médio 0.005042869597673416\n",
      "fc.bias: Gradiente médio 0.024818193167448044\n",
      "fc_intermediate.weight: Gradiente médio 0.07318197935819626\n",
      "fc_intermediate.bias: Gradiente médio 0.14154350757598877\n",
      "Epoch 11 Batch 2/9 Loss: 0.4011\n",
      "fc.weight: Gradiente médio 0.006171745248138905\n",
      "fc.bias: Gradiente médio 0.03727952763438225\n",
      "fc_intermediate.weight: Gradiente médio 0.07425961643457413\n",
      "fc_intermediate.bias: Gradiente médio 0.14241254329681396\n",
      "Epoch 11 Batch 3/9 Loss: 0.5344\n",
      "fc.weight: Gradiente médio 0.006102989427745342\n",
      "fc.bias: Gradiente médio 0.03341693803668022\n",
      "fc_intermediate.weight: Gradiente médio 0.07518196851015091\n",
      "fc_intermediate.bias: Gradiente médio 0.14537322521209717\n",
      "Epoch 11 Batch 4/9 Loss: 0.4593\n",
      "fc.weight: Gradiente médio 0.010255217552185059\n",
      "fc.bias: Gradiente médio 0.0672675222158432\n",
      "fc_intermediate.weight: Gradiente médio 0.07654180377721786\n",
      "fc_intermediate.bias: Gradiente médio 0.1465126872062683\n",
      "Epoch 11 Batch 5/9 Loss: 0.5890\n",
      "fc.weight: Gradiente médio 0.012508295476436615\n",
      "fc.bias: Gradiente médio 0.09405501186847687\n",
      "fc_intermediate.weight: Gradiente médio 0.0771554708480835\n",
      "fc_intermediate.bias: Gradiente médio 0.15039929747581482\n",
      "Epoch 11 Batch 6/9 Loss: 0.3894\n",
      "fc.weight: Gradiente médio 0.004660633858293295\n",
      "fc.bias: Gradiente médio 0.021121472120285034\n",
      "fc_intermediate.weight: Gradiente médio 0.07825644314289093\n",
      "fc_intermediate.bias: Gradiente médio 0.1515318602323532\n",
      "Epoch 11 Batch 7/9 Loss: 0.4770\n",
      "fc.weight: Gradiente médio 0.010930325835943222\n",
      "fc.bias: Gradiente médio 0.08221829682588577\n",
      "fc_intermediate.weight: Gradiente médio 0.07976996153593063\n",
      "fc_intermediate.bias: Gradiente médio 0.15322895348072052\n",
      "Epoch 11 Batch 8/9 Loss: 0.5420\n",
      "fc.weight: Gradiente médio 0.02356429398059845\n",
      "fc.bias: Gradiente médio 0.18095244467258453\n",
      "fc_intermediate.weight: Gradiente médio 0.07935210317373276\n",
      "fc_intermediate.bias: Gradiente médio 0.15616577863693237\n",
      "Epoch 11 Batch 9/9 Loss: 0.4039\n",
      "Epoch 11 Training Loss: 0.4846\n",
      "fc.weight: Gradiente médio 0.006968280300498009\n",
      "fc.bias: Gradiente médio 0.04719877615571022\n",
      "fc_intermediate.weight: Gradiente médio 0.08059272170066833\n",
      "fc_intermediate.bias: Gradiente médio 0.1601170301437378\n",
      "Epoch 12 Batch 1/9 Loss: 0.4239\n",
      "fc.weight: Gradiente médio 0.006244124379009008\n",
      "fc.bias: Gradiente médio 0.037067998200654984\n",
      "fc_intermediate.weight: Gradiente médio 0.08144635707139969\n",
      "fc_intermediate.bias: Gradiente médio 0.16435815393924713\n",
      "Epoch 12 Batch 2/9 Loss: 0.4694\n",
      "fc.weight: Gradiente médio 0.0042066993191838264\n",
      "fc.bias: Gradiente médio 0.010914481244981289\n",
      "fc_intermediate.weight: Gradiente médio 0.082245834171772\n",
      "fc_intermediate.bias: Gradiente médio 0.16489897668361664\n",
      "Epoch 12 Batch 3/9 Loss: 0.4561\n",
      "fc.weight: Gradiente médio 0.003901757998391986\n",
      "fc.bias: Gradiente médio 0.013897838070988655\n",
      "fc_intermediate.weight: Gradiente médio 0.08348127454519272\n",
      "fc_intermediate.bias: Gradiente médio 0.1677132099866867\n",
      "Epoch 12 Batch 4/9 Loss: 0.4686\n",
      "fc.weight: Gradiente médio 0.009952878579497337\n",
      "fc.bias: Gradiente médio 0.07210015505552292\n",
      "fc_intermediate.weight: Gradiente médio 0.0843173936009407\n",
      "fc_intermediate.bias: Gradiente médio 0.16553214192390442\n",
      "Epoch 12 Batch 5/9 Loss: 0.5703\n",
      "fc.weight: Gradiente médio 0.016910091042518616\n",
      "fc.bias: Gradiente médio 0.13186536729335785\n",
      "fc_intermediate.weight: Gradiente médio 0.08582405745983124\n",
      "fc_intermediate.bias: Gradiente médio 0.16432787477970123\n",
      "Epoch 12 Batch 6/9 Loss: 0.5823\n",
      "fc.weight: Gradiente médio 0.004284191410988569\n",
      "fc.bias: Gradiente médio 0.018460426479578018\n",
      "fc_intermediate.weight: Gradiente médio 0.08689938485622406\n",
      "fc_intermediate.bias: Gradiente médio 0.16740378737449646\n",
      "Epoch 12 Batch 7/9 Loss: 0.3933\n",
      "fc.weight: Gradiente médio 0.009554864838719368\n",
      "fc.bias: Gradiente médio 0.06543169170618057\n",
      "fc_intermediate.weight: Gradiente médio 0.08807395398616791\n",
      "fc_intermediate.bias: Gradiente médio 0.16933073103427887\n",
      "Epoch 12 Batch 8/9 Loss: 0.5072\n",
      "fc.weight: Gradiente médio 0.01612647995352745\n",
      "fc.bias: Gradiente médio 0.12999312579631805\n",
      "fc_intermediate.weight: Gradiente médio 0.09000398218631744\n",
      "fc_intermediate.bias: Gradiente médio 0.17439332604408264\n",
      "Epoch 12 Batch 9/9 Loss: 0.5891\n",
      "Epoch 12 Training Loss: 0.4956\n",
      "fc.weight: Gradiente médio 0.005568963475525379\n",
      "fc.bias: Gradiente médio 0.03291536495089531\n",
      "fc_intermediate.weight: Gradiente médio 0.0912269651889801\n",
      "fc_intermediate.bias: Gradiente médio 0.17862161993980408\n",
      "Epoch 13 Batch 1/9 Loss: 0.5072\n",
      "fc.weight: Gradiente médio 0.003481338731944561\n",
      "fc.bias: Gradiente médio 0.013451261445879936\n",
      "fc_intermediate.weight: Gradiente médio 0.09253096580505371\n",
      "fc_intermediate.bias: Gradiente médio 0.18064576387405396\n",
      "Epoch 13 Batch 2/9 Loss: 0.4657\n",
      "fc.weight: Gradiente médio 0.011770574375987053\n",
      "fc.bias: Gradiente médio 0.09037121385335922\n",
      "fc_intermediate.weight: Gradiente médio 0.09285447001457214\n",
      "fc_intermediate.bias: Gradiente médio 0.17915579676628113\n",
      "Epoch 13 Batch 3/9 Loss: 0.4482\n",
      "fc.weight: Gradiente médio 0.012055709958076477\n",
      "fc.bias: Gradiente médio 0.09047289937734604\n",
      "fc_intermediate.weight: Gradiente médio 0.09338033944368362\n",
      "fc_intermediate.bias: Gradiente médio 0.17921291291713715\n",
      "Epoch 13 Batch 4/9 Loss: 0.4265\n",
      "fc.weight: Gradiente médio 0.0053389170207083225\n",
      "fc.bias: Gradiente médio 0.019130568951368332\n",
      "fc_intermediate.weight: Gradiente médio 0.09372872859239578\n",
      "fc_intermediate.bias: Gradiente médio 0.17861106991767883\n",
      "Epoch 13 Batch 5/9 Loss: 0.5957\n",
      "fc.weight: Gradiente médio 0.00850737001746893\n",
      "fc.bias: Gradiente médio 0.05869327485561371\n",
      "fc_intermediate.weight: Gradiente médio 0.09552813321352005\n",
      "fc_intermediate.bias: Gradiente médio 0.1836649477481842\n",
      "Epoch 13 Batch 6/9 Loss: 0.5087\n",
      "fc.weight: Gradiente médio 0.004826522897928953\n",
      "fc.bias: Gradiente médio 0.008860241621732712\n",
      "fc_intermediate.weight: Gradiente médio 0.09692841023206711\n",
      "fc_intermediate.bias: Gradiente médio 0.18669915199279785\n",
      "Epoch 13 Batch 7/9 Loss: 0.4943\n",
      "fc.weight: Gradiente médio 0.007588816806674004\n",
      "fc.bias: Gradiente médio 0.05627819895744324\n",
      "fc_intermediate.weight: Gradiente médio 0.09814278036355972\n",
      "fc_intermediate.bias: Gradiente médio 0.18936608731746674\n",
      "Epoch 13 Batch 8/9 Loss: 0.4440\n",
      "fc.weight: Gradiente médio 0.01541395764797926\n",
      "fc.bias: Gradiente médio 0.12113802134990692\n",
      "fc_intermediate.weight: Gradiente médio 0.09848394244909286\n",
      "fc_intermediate.bias: Gradiente médio 0.19101375341415405\n",
      "Epoch 13 Batch 9/9 Loss: 0.4610\n",
      "Epoch 13 Training Loss: 0.4835\n",
      "fc.weight: Gradiente médio 0.004877857398241758\n",
      "fc.bias: Gradiente médio 0.020227517932653427\n",
      "fc_intermediate.weight: Gradiente médio 0.0999046042561531\n",
      "fc_intermediate.bias: Gradiente médio 0.19407345354557037\n",
      "Epoch 14 Batch 1/9 Loss: 0.5102\n",
      "fc.weight: Gradiente médio 0.005518205929547548\n",
      "fc.bias: Gradiente médio 0.031174354255199432\n",
      "fc_intermediate.weight: Gradiente médio 0.10101569443941116\n",
      "fc_intermediate.bias: Gradiente médio 0.1972638964653015\n",
      "Epoch 14 Batch 2/9 Loss: 0.4410\n",
      "fc.weight: Gradiente médio 0.007404644507914782\n",
      "fc.bias: Gradiente médio 0.05659490451216698\n",
      "fc_intermediate.weight: Gradiente médio 0.10200779885053635\n",
      "fc_intermediate.bias: Gradiente médio 0.20104274153709412\n",
      "Epoch 14 Batch 3/9 Loss: 0.4054\n",
      "fc.weight: Gradiente médio 0.0067281415686011314\n",
      "fc.bias: Gradiente médio 0.03944831341505051\n",
      "fc_intermediate.weight: Gradiente médio 0.10303014516830444\n",
      "fc_intermediate.bias: Gradiente médio 0.20108728110790253\n",
      "Epoch 14 Batch 4/9 Loss: 0.4898\n",
      "fc.weight: Gradiente médio 0.006416372023522854\n",
      "fc.bias: Gradiente médio 0.04169440269470215\n",
      "fc_intermediate.weight: Gradiente médio 0.10403334349393845\n",
      "fc_intermediate.bias: Gradiente médio 0.20171281695365906\n",
      "Epoch 14 Batch 5/9 Loss: 0.5236\n",
      "fc.weight: Gradiente médio 0.0073653217405080795\n",
      "fc.bias: Gradiente médio 0.05692620202898979\n",
      "fc_intermediate.weight: Gradiente médio 0.10505594313144684\n",
      "fc_intermediate.bias: Gradiente médio 0.2020910680294037\n",
      "Epoch 14 Batch 6/9 Loss: 0.5479\n",
      "fc.weight: Gradiente médio 0.006288533564656973\n",
      "fc.bias: Gradiente médio 0.026788480579853058\n",
      "fc_intermediate.weight: Gradiente médio 0.10656075179576874\n",
      "fc_intermediate.bias: Gradiente médio 0.20502059161663055\n",
      "Epoch 14 Batch 7/9 Loss: 0.5020\n",
      "fc.weight: Gradiente médio 0.0035291332751512527\n",
      "fc.bias: Gradiente médio 0.00351821631193161\n",
      "fc_intermediate.weight: Gradiente médio 0.10769033432006836\n",
      "fc_intermediate.bias: Gradiente médio 0.20705533027648926\n",
      "Epoch 14 Batch 8/9 Loss: 0.4547\n",
      "fc.weight: Gradiente médio 0.0053820498287677765\n",
      "fc.bias: Gradiente médio 0.017676683142781258\n",
      "fc_intermediate.weight: Gradiente médio 0.10865472257137299\n",
      "fc_intermediate.bias: Gradiente médio 0.20988476276397705\n",
      "Epoch 14 Batch 9/9 Loss: 0.4382\n",
      "Epoch 14 Training Loss: 0.4792\n",
      "fc.weight: Gradiente médio 0.010424623265862465\n",
      "fc.bias: Gradiente médio 0.06892929971218109\n",
      "fc_intermediate.weight: Gradiente médio 0.11027291417121887\n",
      "fc_intermediate.bias: Gradiente médio 0.21247655153274536\n",
      "Epoch 15 Batch 1/9 Loss: 0.4937\n",
      "fc.weight: Gradiente médio 0.004816568922251463\n",
      "fc.bias: Gradiente médio 0.023139532655477524\n",
      "fc_intermediate.weight: Gradiente médio 0.11116728186607361\n",
      "fc_intermediate.bias: Gradiente médio 0.2121797800064087\n",
      "Epoch 15 Batch 2/9 Loss: 0.5593\n",
      "fc.weight: Gradiente médio 0.00734954746440053\n",
      "fc.bias: Gradiente médio 0.04988359659910202\n",
      "fc_intermediate.weight: Gradiente médio 0.11237430572509766\n",
      "fc_intermediate.bias: Gradiente médio 0.2157943844795227\n",
      "Epoch 15 Batch 3/9 Loss: 0.5384\n",
      "fc.weight: Gradiente médio 0.006848054472357035\n",
      "fc.bias: Gradiente médio 0.03826921805739403\n",
      "fc_intermediate.weight: Gradiente médio 0.11389628052711487\n",
      "fc_intermediate.bias: Gradiente médio 0.2199389636516571\n",
      "Epoch 15 Batch 4/9 Loss: 0.5008\n",
      "fc.weight: Gradiente médio 0.007375141605734825\n",
      "fc.bias: Gradiente médio 0.04988512024283409\n",
      "fc_intermediate.weight: Gradiente médio 0.11443369835615158\n",
      "fc_intermediate.bias: Gradiente médio 0.22015275061130524\n",
      "Epoch 15 Batch 5/9 Loss: 0.4102\n",
      "fc.weight: Gradiente médio 0.006079858168959618\n",
      "fc.bias: Gradiente médio 0.034973107278347015\n",
      "fc_intermediate.weight: Gradiente médio 0.11542997509241104\n",
      "fc_intermediate.bias: Gradiente médio 0.22218286991119385\n",
      "Epoch 15 Batch 6/9 Loss: 0.4168\n",
      "fc.weight: Gradiente médio 0.005623277742415667\n",
      "fc.bias: Gradiente médio 0.040572959929704666\n",
      "fc_intermediate.weight: Gradiente médio 0.11658605933189392\n",
      "fc_intermediate.bias: Gradiente médio 0.2240273356437683\n",
      "Epoch 15 Batch 7/9 Loss: 0.5268\n",
      "fc.weight: Gradiente médio 0.006238234229385853\n",
      "fc.bias: Gradiente médio 0.04879685863852501\n",
      "fc_intermediate.weight: Gradiente médio 0.11781422048807144\n",
      "fc_intermediate.bias: Gradiente médio 0.2272094041109085\n",
      "Epoch 15 Batch 8/9 Loss: 0.4235\n",
      "fc.weight: Gradiente médio 0.013049358502030373\n",
      "fc.bias: Gradiente médio 0.09693776071071625\n",
      "fc_intermediate.weight: Gradiente médio 0.11886502802371979\n",
      "fc_intermediate.bias: Gradiente médio 0.23278793692588806\n",
      "Epoch 15 Batch 9/9 Loss: 0.4190\n",
      "Epoch 15 Training Loss: 0.4765\n",
      "fc.weight: Gradiente médio 0.0037008975632488728\n",
      "fc.bias: Gradiente médio 0.010020183399319649\n",
      "fc_intermediate.weight: Gradiente médio 0.12047582864761353\n",
      "fc_intermediate.bias: Gradiente médio 0.23603998124599457\n",
      "Epoch 16 Batch 1/9 Loss: 0.4212\n",
      "fc.weight: Gradiente médio 0.008001308888196945\n",
      "fc.bias: Gradiente médio 0.060841839760541916\n",
      "fc_intermediate.weight: Gradiente médio 0.12207293510437012\n",
      "fc_intermediate.bias: Gradiente médio 0.2373409867286682\n",
      "Epoch 16 Batch 2/9 Loss: 0.5264\n",
      "fc.weight: Gradiente médio 0.006134212948381901\n",
      "fc.bias: Gradiente médio 0.030072078108787537\n",
      "fc_intermediate.weight: Gradiente médio 0.12344802916049957\n",
      "fc_intermediate.bias: Gradiente médio 0.23934796452522278\n",
      "Epoch 16 Batch 3/9 Loss: 0.4430\n",
      "fc.weight: Gradiente médio 0.006893320009112358\n",
      "fc.bias: Gradiente médio 0.044895417988300323\n",
      "fc_intermediate.weight: Gradiente médio 0.12390471994876862\n",
      "fc_intermediate.bias: Gradiente médio 0.23952043056488037\n",
      "Epoch 16 Batch 4/9 Loss: 0.5656\n",
      "fc.weight: Gradiente médio 0.0034822034649550915\n",
      "fc.bias: Gradiente médio 0.0011634677648544312\n",
      "fc_intermediate.weight: Gradiente médio 0.12516282498836517\n",
      "fc_intermediate.bias: Gradiente médio 0.2427288293838501\n",
      "Epoch 16 Batch 5/9 Loss: 0.4075\n",
      "fc.weight: Gradiente médio 0.006355820223689079\n",
      "fc.bias: Gradiente médio 0.0413057841360569\n",
      "fc_intermediate.weight: Gradiente médio 0.1258113831281662\n",
      "fc_intermediate.bias: Gradiente médio 0.245444655418396\n",
      "Epoch 16 Batch 6/9 Loss: 0.5071\n",
      "fc.weight: Gradiente médio 0.004044150467962027\n",
      "fc.bias: Gradiente médio 0.019907794892787933\n",
      "fc_intermediate.weight: Gradiente médio 0.12730823457241058\n",
      "fc_intermediate.bias: Gradiente médio 0.24950028955936432\n",
      "Epoch 16 Batch 7/9 Loss: 0.4153\n",
      "fc.weight: Gradiente médio 0.004883870482444763\n",
      "fc.bias: Gradiente médio 0.026544345542788506\n",
      "fc_intermediate.weight: Gradiente médio 0.12832807004451752\n",
      "fc_intermediate.bias: Gradiente médio 0.2503279745578766\n",
      "Epoch 16 Batch 8/9 Loss: 0.4731\n",
      "fc.weight: Gradiente médio 0.009824136272072792\n",
      "fc.bias: Gradiente médio 0.07013967633247375\n",
      "fc_intermediate.weight: Gradiente médio 0.1296025812625885\n",
      "fc_intermediate.bias: Gradiente médio 0.2491137683391571\n",
      "Epoch 16 Batch 9/9 Loss: 0.5210\n",
      "Epoch 16 Training Loss: 0.4756\n",
      "fc.weight: Gradiente médio 0.013299599289894104\n",
      "fc.bias: Gradiente médio 0.09674319624900818\n",
      "fc_intermediate.weight: Gradiente médio 0.13177400827407837\n",
      "fc_intermediate.bias: Gradiente médio 0.2541452646255493\n",
      "Epoch 17 Batch 1/9 Loss: 0.5595\n",
      "fc.weight: Gradiente médio 0.011442483402788639\n",
      "fc.bias: Gradiente médio 0.08617936074733734\n",
      "fc_intermediate.weight: Gradiente médio 0.1334547996520996\n",
      "fc_intermediate.bias: Gradiente médio 0.257744163274765\n",
      "Epoch 17 Batch 2/9 Loss: 0.5121\n",
      "fc.weight: Gradiente médio 0.004770600236952305\n",
      "fc.bias: Gradiente médio 0.023706607520580292\n",
      "fc_intermediate.weight: Gradiente médio 0.13495483994483948\n",
      "fc_intermediate.bias: Gradiente médio 0.26157230138778687\n",
      "Epoch 17 Batch 3/9 Loss: 0.5147\n",
      "fc.weight: Gradiente médio 0.008016751147806644\n",
      "fc.bias: Gradiente médio 0.05511818453669548\n",
      "fc_intermediate.weight: Gradiente médio 0.13568401336669922\n",
      "fc_intermediate.bias: Gradiente médio 0.26196998357772827\n",
      "Epoch 17 Batch 4/9 Loss: 0.4492\n",
      "fc.weight: Gradiente médio 0.00548693398013711\n",
      "fc.bias: Gradiente médio 0.03481125831604004\n",
      "fc_intermediate.weight: Gradiente médio 0.13625074923038483\n",
      "fc_intermediate.bias: Gradiente médio 0.2617194354534149\n",
      "Epoch 17 Batch 5/9 Loss: 0.5006\n",
      "fc.weight: Gradiente médio 0.01611253246665001\n",
      "fc.bias: Gradiente médio 0.13034601509571075\n",
      "fc_intermediate.weight: Gradiente médio 0.13707681000232697\n",
      "fc_intermediate.bias: Gradiente médio 0.2642533779144287\n",
      "Epoch 17 Batch 6/9 Loss: 0.4014\n",
      "fc.weight: Gradiente médio 0.004652836360037327\n",
      "fc.bias: Gradiente médio 0.01794089749455452\n",
      "fc_intermediate.weight: Gradiente médio 0.1384425014257431\n",
      "fc_intermediate.bias: Gradiente médio 0.2660796046257019\n",
      "Epoch 17 Batch 7/9 Loss: 0.5022\n",
      "fc.weight: Gradiente médio 0.010058188810944557\n",
      "fc.bias: Gradiente médio 0.070903480052948\n",
      "fc_intermediate.weight: Gradiente médio 0.13925983011722565\n",
      "fc_intermediate.bias: Gradiente médio 0.2697593867778778\n",
      "Epoch 17 Batch 8/9 Loss: 0.4440\n",
      "fc.weight: Gradiente médio 0.008832884952425957\n",
      "fc.bias: Gradiente médio 0.0724615752696991\n",
      "fc_intermediate.weight: Gradiente médio 0.13993123173713684\n",
      "fc_intermediate.bias: Gradiente médio 0.27267706394195557\n",
      "Epoch 17 Batch 9/9 Loss: 0.3573\n",
      "Epoch 17 Training Loss: 0.4712\n",
      "fc.weight: Gradiente médio 0.007022634148597717\n",
      "fc.bias: Gradiente médio 0.0493147037923336\n",
      "fc_intermediate.weight: Gradiente médio 0.1407880187034607\n",
      "fc_intermediate.bias: Gradiente médio 0.2761555016040802\n",
      "Epoch 18 Batch 1/9 Loss: 0.4728\n",
      "fc.weight: Gradiente médio 0.0068757846020162106\n",
      "fc.bias: Gradiente médio 0.030351772904396057\n",
      "fc_intermediate.weight: Gradiente médio 0.14214038848876953\n",
      "fc_intermediate.bias: Gradiente médio 0.277288019657135\n",
      "Epoch 18 Batch 2/9 Loss: 0.5144\n",
      "fc.weight: Gradiente médio 0.0038233264349400997\n",
      "fc.bias: Gradiente médio 0.0017071878537535667\n",
      "fc_intermediate.weight: Gradiente médio 0.1434646099805832\n",
      "fc_intermediate.bias: Gradiente médio 0.27880534529685974\n",
      "Epoch 18 Batch 3/9 Loss: 0.4419\n",
      "fc.weight: Gradiente médio 0.0031285679433494806\n",
      "fc.bias: Gradiente médio 0.006181573495268822\n",
      "fc_intermediate.weight: Gradiente médio 0.14494507014751434\n",
      "fc_intermediate.bias: Gradiente médio 0.2819920778274536\n",
      "Epoch 18 Batch 4/9 Loss: 0.4159\n",
      "fc.weight: Gradiente médio 0.0039714244194328785\n",
      "fc.bias: Gradiente médio 0.006890580058097839\n",
      "fc_intermediate.weight: Gradiente médio 0.14564251899719238\n",
      "fc_intermediate.bias: Gradiente médio 0.2829686403274536\n",
      "Epoch 18 Batch 5/9 Loss: 0.5028\n",
      "fc.weight: Gradiente médio 0.019105931743979454\n",
      "fc.bias: Gradiente médio 0.1399250328540802\n",
      "fc_intermediate.weight: Gradiente médio 0.1475229263305664\n",
      "fc_intermediate.bias: Gradiente médio 0.28139278292655945\n",
      "Epoch 18 Batch 6/9 Loss: 0.5856\n",
      "fc.weight: Gradiente médio 0.007170125842094421\n",
      "fc.bias: Gradiente médio 0.05859306454658508\n",
      "fc_intermediate.weight: Gradiente médio 0.14867566525936127\n",
      "fc_intermediate.bias: Gradiente médio 0.28585031628608704\n",
      "Epoch 18 Batch 7/9 Loss: 0.3486\n",
      "fc.weight: Gradiente médio 0.009746317751705647\n",
      "fc.bias: Gradiente médio 0.08007367700338364\n",
      "fc_intermediate.weight: Gradiente médio 0.1501660943031311\n",
      "fc_intermediate.bias: Gradiente médio 0.28746747970581055\n",
      "Epoch 18 Batch 8/9 Loss: 0.4845\n",
      "fc.weight: Gradiente médio 0.01817571558058262\n",
      "fc.bias: Gradiente médio 0.1303163766860962\n",
      "fc_intermediate.weight: Gradiente médio 0.1524125188589096\n",
      "fc_intermediate.bias: Gradiente médio 0.2922252416610718\n",
      "Epoch 18 Batch 9/9 Loss: 0.5300\n",
      "Epoch 18 Training Loss: 0.4774\n",
      "fc.weight: Gradiente médio 0.004419571254402399\n",
      "fc.bias: Gradiente médio 0.012523632496595383\n",
      "fc_intermediate.weight: Gradiente médio 0.15387359261512756\n",
      "fc_intermediate.bias: Gradiente médio 0.29507631063461304\n",
      "Epoch 19 Batch 1/9 Loss: 0.4230\n",
      "fc.weight: Gradiente médio 0.004553652368485928\n",
      "fc.bias: Gradiente médio 0.01293567568063736\n",
      "fc_intermediate.weight: Gradiente médio 0.1549072563648224\n",
      "fc_intermediate.bias: Gradiente médio 0.29762595891952515\n",
      "Epoch 19 Batch 2/9 Loss: 0.5631\n",
      "fc.weight: Gradiente médio 0.006677580066025257\n",
      "fc.bias: Gradiente médio 0.02873237058520317\n",
      "fc_intermediate.weight: Gradiente médio 0.15577365458011627\n",
      "fc_intermediate.bias: Gradiente médio 0.2969158887863159\n",
      "Epoch 19 Batch 3/9 Loss: 0.5372\n",
      "fc.weight: Gradiente médio 0.00900760293006897\n",
      "fc.bias: Gradiente médio 0.056730061769485474\n",
      "fc_intermediate.weight: Gradiente médio 0.1575908362865448\n",
      "fc_intermediate.bias: Gradiente médio 0.30033984780311584\n",
      "Epoch 19 Batch 4/9 Loss: 0.4672\n",
      "fc.weight: Gradiente médio 0.01132032461464405\n",
      "fc.bias: Gradiente médio 0.09083393216133118\n",
      "fc_intermediate.weight: Gradiente médio 0.15830621123313904\n",
      "fc_intermediate.bias: Gradiente médio 0.30048778653144836\n",
      "Epoch 19 Batch 5/9 Loss: 0.4188\n",
      "fc.weight: Gradiente médio 0.004372990224510431\n",
      "fc.bias: Gradiente médio 0.010336752980947495\n",
      "fc_intermediate.weight: Gradiente médio 0.15974177420139313\n",
      "fc_intermediate.bias: Gradiente médio 0.304670512676239\n",
      "Epoch 19 Batch 6/9 Loss: 0.4755\n",
      "fc.weight: Gradiente médio 0.008413318544626236\n",
      "fc.bias: Gradiente médio 0.06426171213388443\n",
      "fc_intermediate.weight: Gradiente médio 0.16063125431537628\n",
      "fc_intermediate.bias: Gradiente médio 0.3053872287273407\n",
      "Epoch 19 Batch 7/9 Loss: 0.4977\n",
      "fc.weight: Gradiente médio 0.006973699666559696\n",
      "fc.bias: Gradiente médio 0.048312075436115265\n",
      "fc_intermediate.weight: Gradiente médio 0.1618582010269165\n",
      "fc_intermediate.bias: Gradiente médio 0.3090463876724243\n",
      "Epoch 19 Batch 8/9 Loss: 0.3876\n",
      "fc.weight: Gradiente médio 0.007082698866724968\n",
      "fc.bias: Gradiente médio 0.033020853996276855\n",
      "fc_intermediate.weight: Gradiente médio 0.16338913142681122\n",
      "fc_intermediate.bias: Gradiente médio 0.31214195489883423\n",
      "Epoch 19 Batch 9/9 Loss: 0.4259\n",
      "Epoch 19 Training Loss: 0.4662\n",
      "fc.weight: Gradiente médio 0.004407093394547701\n",
      "fc.bias: Gradiente médio 0.013785334303975105\n",
      "fc_intermediate.weight: Gradiente médio 0.1647116243839264\n",
      "fc_intermediate.bias: Gradiente médio 0.313776433467865\n",
      "Epoch 20 Batch 1/9 Loss: 0.4731\n",
      "fc.weight: Gradiente médio 0.00417556194588542\n",
      "fc.bias: Gradiente médio 0.008908875286579132\n",
      "fc_intermediate.weight: Gradiente médio 0.1662248820066452\n",
      "fc_intermediate.bias: Gradiente médio 0.3170819878578186\n",
      "Epoch 20 Batch 2/9 Loss: 0.5251\n",
      "fc.weight: Gradiente médio 0.01122174970805645\n",
      "fc.bias: Gradiente médio 0.0876171663403511\n",
      "fc_intermediate.weight: Gradiente médio 0.16742098331451416\n",
      "fc_intermediate.bias: Gradiente médio 0.3219560384750366\n",
      "Epoch 20 Batch 3/9 Loss: 0.3990\n",
      "fc.weight: Gradiente médio 0.007305268198251724\n",
      "fc.bias: Gradiente médio 0.035657092928886414\n",
      "fc_intermediate.weight: Gradiente médio 0.16824686527252197\n",
      "fc_intermediate.bias: Gradiente médio 0.3235151171684265\n",
      "Epoch 20 Batch 4/9 Loss: 0.5117\n",
      "fc.weight: Gradiente médio 0.003444560104981065\n",
      "fc.bias: Gradiente médio 0.01694559119641781\n",
      "fc_intermediate.weight: Gradiente médio 0.16976985335350037\n",
      "fc_intermediate.bias: Gradiente médio 0.32652029395103455\n",
      "Epoch 20 Batch 5/9 Loss: 0.4550\n",
      "fc.weight: Gradiente médio 0.005546200089156628\n",
      "fc.bias: Gradiente médio 0.025955500081181526\n",
      "fc_intermediate.weight: Gradiente médio 0.17071856558322906\n",
      "fc_intermediate.bias: Gradiente médio 0.3293159604072571\n",
      "Epoch 20 Batch 6/9 Loss: 0.4209\n",
      "fc.weight: Gradiente médio 0.010282169096171856\n",
      "fc.bias: Gradiente médio 0.0723552256822586\n",
      "fc_intermediate.weight: Gradiente médio 0.1717071235179901\n",
      "fc_intermediate.bias: Gradiente médio 0.3343861401081085\n",
      "Epoch 20 Batch 7/9 Loss: 0.4485\n",
      "fc.weight: Gradiente médio 0.012245962396264076\n",
      "fc.bias: Gradiente médio 0.08361084014177322\n",
      "fc_intermediate.weight: Gradiente médio 0.17326152324676514\n",
      "fc_intermediate.bias: Gradiente médio 0.33359193801879883\n",
      "Epoch 20 Batch 8/9 Loss: 0.4999\n",
      "fc.weight: Gradiente médio 0.00892563909292221\n",
      "fc.bias: Gradiente médio 0.047766413539648056\n",
      "fc_intermediate.weight: Gradiente médio 0.17495504021644592\n",
      "fc_intermediate.bias: Gradiente médio 0.33606040477752686\n",
      "Epoch 20 Batch 9/9 Loss: 0.5033\n",
      "Epoch 20 Training Loss: 0.4707\n",
      "fc.weight: Gradiente médio 0.0048189954832196236\n",
      "fc.bias: Gradiente médio 0.01970631629228592\n",
      "fc_intermediate.weight: Gradiente médio 0.1767204850912094\n",
      "fc_intermediate.bias: Gradiente médio 0.3398636281490326\n",
      "Epoch 21 Batch 1/9 Loss: 0.4183\n",
      "fc.weight: Gradiente médio 0.005553697235882282\n",
      "fc.bias: Gradiente médio 0.016525549814105034\n",
      "fc_intermediate.weight: Gradiente médio 0.17825500667095184\n",
      "fc_intermediate.bias: Gradiente médio 0.3414027690887451\n",
      "Epoch 21 Batch 2/9 Loss: 0.4508\n",
      "fc.weight: Gradiente médio 0.005102408118546009\n",
      "fc.bias: Gradiente médio 0.03198704868555069\n",
      "fc_intermediate.weight: Gradiente médio 0.1796213984489441\n",
      "fc_intermediate.bias: Gradiente médio 0.34345629811286926\n",
      "Epoch 21 Batch 3/9 Loss: 0.4760\n",
      "fc.weight: Gradiente médio 0.004018507897853851\n",
      "fc.bias: Gradiente médio 0.0024433471262454987\n",
      "fc_intermediate.weight: Gradiente médio 0.18124167621135712\n",
      "fc_intermediate.bias: Gradiente médio 0.3464829921722412\n",
      "Epoch 21 Batch 4/9 Loss: 0.4629\n",
      "fc.weight: Gradiente médio 0.005105539225041866\n",
      "fc.bias: Gradiente médio 0.021492956206202507\n",
      "fc_intermediate.weight: Gradiente médio 0.18199971318244934\n",
      "fc_intermediate.bias: Gradiente médio 0.34754183888435364\n",
      "Epoch 21 Batch 5/9 Loss: 0.5030\n",
      "fc.weight: Gradiente médio 0.004253477789461613\n",
      "fc.bias: Gradiente médio 0.019954130053520203\n",
      "fc_intermediate.weight: Gradiente médio 0.18317626416683197\n",
      "fc_intermediate.bias: Gradiente médio 0.3491588830947876\n",
      "Epoch 21 Batch 6/9 Loss: 0.4263\n",
      "fc.weight: Gradiente médio 0.005189395043998957\n",
      "fc.bias: Gradiente médio 0.031297557055950165\n",
      "fc_intermediate.weight: Gradiente médio 0.18474523723125458\n",
      "fc_intermediate.bias: Gradiente médio 0.3525438606739044\n",
      "Epoch 21 Batch 7/9 Loss: 0.5061\n",
      "fc.weight: Gradiente médio 0.007077729795128107\n",
      "fc.bias: Gradiente médio 0.050141576677560806\n",
      "fc_intermediate.weight: Gradiente médio 0.18658187985420227\n",
      "fc_intermediate.bias: Gradiente médio 0.35620027780532837\n",
      "Epoch 21 Batch 8/9 Loss: 0.5744\n",
      "fc.weight: Gradiente médio 0.010387648828327656\n",
      "fc.bias: Gradiente médio 0.07426111400127411\n",
      "fc_intermediate.weight: Gradiente médio 0.1872321367263794\n",
      "fc_intermediate.bias: Gradiente médio 0.35864928364753723\n",
      "Epoch 21 Batch 9/9 Loss: 0.2827\n",
      "Epoch 21 Training Loss: 0.4556\n",
      "fc.weight: Gradiente médio 0.004146179184317589\n",
      "fc.bias: Gradiente médio 0.027703339233994484\n",
      "fc_intermediate.weight: Gradiente médio 0.1884857416152954\n",
      "fc_intermediate.bias: Gradiente médio 0.36160606145858765\n",
      "Epoch 22 Batch 1/9 Loss: 0.3928\n",
      "fc.weight: Gradiente médio 0.009286515414714813\n",
      "fc.bias: Gradiente médio 0.07142214477062225\n",
      "fc_intermediate.weight: Gradiente médio 0.1897333860397339\n",
      "fc_intermediate.bias: Gradiente médio 0.3647717237472534\n",
      "Epoch 22 Batch 2/9 Loss: 0.3969\n",
      "fc.weight: Gradiente médio 0.004983767867088318\n",
      "fc.bias: Gradiente médio 0.012258535251021385\n",
      "fc_intermediate.weight: Gradiente médio 0.19078689813613892\n",
      "fc_intermediate.bias: Gradiente médio 0.36633235216140747\n",
      "Epoch 22 Batch 3/9 Loss: 0.4694\n",
      "fc.weight: Gradiente médio 0.008530056104063988\n",
      "fc.bias: Gradiente médio 0.05763523653149605\n",
      "fc_intermediate.weight: Gradiente médio 0.19231721758842468\n",
      "fc_intermediate.bias: Gradiente médio 0.3678586483001709\n",
      "Epoch 22 Batch 4/9 Loss: 0.4713\n",
      "fc.weight: Gradiente médio 0.004126663785427809\n",
      "fc.bias: Gradiente médio 0.010921221226453781\n",
      "fc_intermediate.weight: Gradiente médio 0.19403477013111115\n",
      "fc_intermediate.bias: Gradiente médio 0.3721909523010254\n",
      "Epoch 22 Batch 5/9 Loss: 0.4584\n",
      "fc.weight: Gradiente médio 0.009039344266057014\n",
      "fc.bias: Gradiente médio 0.06481758505105972\n",
      "fc_intermediate.weight: Gradiente médio 0.1960066705942154\n",
      "fc_intermediate.bias: Gradiente médio 0.3762439787387848\n",
      "Epoch 22 Batch 6/9 Loss: 0.5503\n",
      "fc.weight: Gradiente médio 0.0065093329176306725\n",
      "fc.bias: Gradiente médio 0.043446969240903854\n",
      "fc_intermediate.weight: Gradiente médio 0.19726958870887756\n",
      "fc_intermediate.bias: Gradiente médio 0.377789169549942\n",
      "Epoch 22 Batch 7/9 Loss: 0.5521\n",
      "fc.weight: Gradiente médio 0.011960195377469063\n",
      "fc.bias: Gradiente médio 0.08725813776254654\n",
      "fc_intermediate.weight: Gradiente médio 0.1979171484708786\n",
      "fc_intermediate.bias: Gradiente médio 0.3785737156867981\n",
      "Epoch 22 Batch 8/9 Loss: 0.4346\n",
      "fc.weight: Gradiente médio 0.005047165788710117\n",
      "fc.bias: Gradiente médio 0.009862011298537254\n",
      "fc_intermediate.weight: Gradiente médio 0.1993684470653534\n",
      "fc_intermediate.bias: Gradiente médio 0.38151270151138306\n",
      "Epoch 22 Batch 9/9 Loss: 0.4328\n",
      "Epoch 22 Training Loss: 0.4621\n",
      "fc.weight: Gradiente médio 0.004564633592963219\n",
      "fc.bias: Gradiente médio 0.031850267201662064\n",
      "fc_intermediate.weight: Gradiente médio 0.2007143795490265\n",
      "fc_intermediate.bias: Gradiente médio 0.3855808973312378\n",
      "Epoch 23 Batch 1/9 Loss: 0.4385\n",
      "fc.weight: Gradiente médio 0.012796640396118164\n",
      "fc.bias: Gradiente médio 0.10174012184143066\n",
      "fc_intermediate.weight: Gradiente médio 0.20167852938175201\n",
      "fc_intermediate.bias: Gradiente médio 0.3905537724494934\n",
      "Epoch 23 Batch 2/9 Loss: 0.3467\n",
      "fc.weight: Gradiente médio 0.011025698855519295\n",
      "fc.bias: Gradiente médio 0.07984276115894318\n",
      "fc_intermediate.weight: Gradiente médio 0.20371367037296295\n",
      "fc_intermediate.bias: Gradiente médio 0.3920278549194336\n",
      "Epoch 23 Batch 3/9 Loss: 0.5562\n",
      "fc.weight: Gradiente médio 0.012998638674616814\n",
      "fc.bias: Gradiente médio 0.09968339651823044\n",
      "fc_intermediate.weight: Gradiente médio 0.20558173954486847\n",
      "fc_intermediate.bias: Gradiente médio 0.3945903182029724\n",
      "Epoch 23 Batch 4/9 Loss: 0.5444\n",
      "fc.weight: Gradiente médio 0.010682162828743458\n",
      "fc.bias: Gradiente médio 0.07936365157365799\n",
      "fc_intermediate.weight: Gradiente médio 0.20762023329734802\n",
      "fc_intermediate.bias: Gradiente médio 0.3985772430896759\n",
      "Epoch 23 Batch 5/9 Loss: 0.5901\n",
      "fc.weight: Gradiente médio 0.0068657537922263145\n",
      "fc.bias: Gradiente médio 0.04227350279688835\n",
      "fc_intermediate.weight: Gradiente médio 0.20833691954612732\n",
      "fc_intermediate.bias: Gradiente médio 0.3994864225387573\n",
      "Epoch 23 Batch 6/9 Loss: 0.4455\n",
      "fc.weight: Gradiente médio 0.00906939897686243\n",
      "fc.bias: Gradiente médio 0.06158493831753731\n",
      "fc_intermediate.weight: Gradiente médio 0.2093876600265503\n",
      "fc_intermediate.bias: Gradiente médio 0.4010271430015564\n",
      "Epoch 23 Batch 7/9 Loss: 0.4096\n",
      "fc.weight: Gradiente médio 0.011881708167493343\n",
      "fc.bias: Gradiente médio 0.08952545374631882\n",
      "fc_intermediate.weight: Gradiente médio 0.2102883756160736\n",
      "fc_intermediate.bias: Gradiente médio 0.40348541736602783\n",
      "Epoch 23 Batch 8/9 Loss: 0.3622\n",
      "fc.weight: Gradiente médio 0.008884428068995476\n",
      "fc.bias: Gradiente médio 0.048617199063301086\n",
      "fc_intermediate.weight: Gradiente médio 0.21215683221817017\n",
      "fc_intermediate.bias: Gradiente médio 0.4060266613960266\n",
      "Epoch 23 Batch 9/9 Loss: 0.5072\n",
      "Epoch 23 Training Loss: 0.4667\n",
      "fc.weight: Gradiente médio 0.005314399488270283\n",
      "fc.bias: Gradiente médio 0.03107667714357376\n",
      "fc_intermediate.weight: Gradiente médio 0.21344339847564697\n",
      "fc_intermediate.bias: Gradiente médio 0.4092789590358734\n",
      "Epoch 24 Batch 1/9 Loss: 0.4432\n",
      "fc.weight: Gradiente médio 0.009108273312449455\n",
      "fc.bias: Gradiente médio 0.06232364475727081\n",
      "fc_intermediate.weight: Gradiente médio 0.2144121527671814\n",
      "fc_intermediate.bias: Gradiente médio 0.41260790824890137\n",
      "Epoch 24 Batch 2/9 Loss: 0.4194\n",
      "fc.weight: Gradiente médio 0.005599506199359894\n",
      "fc.bias: Gradiente médio 0.03641291707754135\n",
      "fc_intermediate.weight: Gradiente médio 0.21553245186805725\n",
      "fc_intermediate.bias: Gradiente médio 0.4158892333507538\n",
      "Epoch 24 Batch 3/9 Loss: 0.3732\n",
      "fc.weight: Gradiente médio 0.00985865667462349\n",
      "fc.bias: Gradiente médio 0.07174164056777954\n",
      "fc_intermediate.weight: Gradiente médio 0.2171899825334549\n",
      "fc_intermediate.bias: Gradiente médio 0.41717374324798584\n",
      "Epoch 24 Batch 4/9 Loss: 0.5366\n",
      "fc.weight: Gradiente médio 0.0038698632270097733\n",
      "fc.bias: Gradiente médio 0.0020160432904958725\n",
      "fc_intermediate.weight: Gradiente médio 0.21867841482162476\n",
      "fc_intermediate.bias: Gradiente médio 0.41985946893692017\n",
      "Epoch 24 Batch 5/9 Loss: 0.4977\n",
      "fc.weight: Gradiente médio 0.006542045623064041\n",
      "fc.bias: Gradiente médio 0.04710479825735092\n",
      "fc_intermediate.weight: Gradiente médio 0.22016416490077972\n",
      "fc_intermediate.bias: Gradiente médio 0.4204499125480652\n",
      "Epoch 24 Batch 6/9 Loss: 0.5013\n",
      "fc.weight: Gradiente médio 0.01031546015292406\n",
      "fc.bias: Gradiente médio 0.06991192698478699\n",
      "fc_intermediate.weight: Gradiente médio 0.2220836579799652\n",
      "fc_intermediate.bias: Gradiente médio 0.42398619651794434\n",
      "Epoch 24 Batch 7/9 Loss: 0.5249\n",
      "fc.weight: Gradiente médio 0.011801930144429207\n",
      "fc.bias: Gradiente médio 0.08587104827165604\n",
      "fc_intermediate.weight: Gradiente médio 0.2246633619070053\n",
      "fc_intermediate.bias: Gradiente médio 0.4298686385154724\n",
      "Epoch 24 Batch 8/9 Loss: 0.4899\n",
      "fc.weight: Gradiente médio 0.012874681502580643\n",
      "fc.bias: Gradiente médio 0.09892665594816208\n",
      "fc_intermediate.weight: Gradiente médio 0.22505317628383636\n",
      "fc_intermediate.bias: Gradiente médio 0.42926061153411865\n",
      "Epoch 24 Batch 9/9 Loss: 0.2921\n",
      "Epoch 24 Training Loss: 0.4531\n",
      "fc.weight: Gradiente médio 0.005224534776061773\n",
      "fc.bias: Gradiente médio 0.0193832628428936\n",
      "fc_intermediate.weight: Gradiente médio 0.22657696902751923\n",
      "fc_intermediate.bias: Gradiente médio 0.433416485786438\n",
      "Epoch 25 Batch 1/9 Loss: 0.5092\n",
      "fc.weight: Gradiente médio 0.004116566851735115\n",
      "fc.bias: Gradiente médio 0.012184484861791134\n",
      "fc_intermediate.weight: Gradiente médio 0.2283795326948166\n",
      "fc_intermediate.bias: Gradiente médio 0.4372118413448334\n",
      "Epoch 25 Batch 2/9 Loss: 0.4345\n",
      "fc.weight: Gradiente médio 0.003650289261713624\n",
      "fc.bias: Gradiente médio 0.011419636197388172\n",
      "fc_intermediate.weight: Gradiente médio 0.22923605144023895\n",
      "fc_intermediate.bias: Gradiente médio 0.4382788836956024\n",
      "Epoch 25 Batch 3/9 Loss: 0.4064\n",
      "fc.weight: Gradiente médio 0.00903055164963007\n",
      "fc.bias: Gradiente médio 0.05917220935225487\n",
      "fc_intermediate.weight: Gradiente médio 0.23175647854804993\n",
      "fc_intermediate.bias: Gradiente médio 0.44348570704460144\n",
      "Epoch 25 Batch 4/9 Loss: 0.4359\n",
      "fc.weight: Gradiente médio 0.014112045988440514\n",
      "fc.bias: Gradiente médio 0.10518716275691986\n",
      "fc_intermediate.weight: Gradiente médio 0.2320248931646347\n",
      "fc_intermediate.bias: Gradiente médio 0.44358301162719727\n",
      "Epoch 25 Batch 5/9 Loss: 0.3757\n",
      "fc.weight: Gradiente médio 0.010526932775974274\n",
      "fc.bias: Gradiente médio 0.06981998682022095\n",
      "fc_intermediate.weight: Gradiente médio 0.23255686461925507\n",
      "fc_intermediate.bias: Gradiente médio 0.44479265809059143\n",
      "Epoch 25 Batch 6/9 Loss: 0.4319\n",
      "fc.weight: Gradiente médio 0.016412407159805298\n",
      "fc.bias: Gradiente médio 0.11050738394260406\n",
      "fc_intermediate.weight: Gradiente médio 0.23512795567512512\n",
      "fc_intermediate.bias: Gradiente médio 0.44836509227752686\n",
      "Epoch 25 Batch 7/9 Loss: 0.5137\n",
      "fc.weight: Gradiente médio 0.004575888626277447\n",
      "fc.bias: Gradiente médio 0.0011814944446086884\n",
      "fc_intermediate.weight: Gradiente médio 0.236361563205719\n",
      "fc_intermediate.bias: Gradiente médio 0.44932034611701965\n",
      "Epoch 25 Batch 8/9 Loss: 0.5551\n",
      "fc.weight: Gradiente médio 0.005614116787910461\n",
      "fc.bias: Gradiente médio 0.018403824418783188\n",
      "fc_intermediate.weight: Gradiente médio 0.23827552795410156\n",
      "fc_intermediate.bias: Gradiente médio 0.45500022172927856\n",
      "Epoch 25 Batch 9/9 Loss: 0.4735\n",
      "Epoch 25 Training Loss: 0.4595\n",
      "fc.weight: Gradiente médio 0.00554991140961647\n",
      "fc.bias: Gradiente médio 0.02232598513364792\n",
      "fc_intermediate.weight: Gradiente médio 0.23928005993366241\n",
      "fc_intermediate.bias: Gradiente médio 0.4558057188987732\n",
      "Epoch 26 Batch 1/9 Loss: 0.5444\n",
      "fc.weight: Gradiente médio 0.01002743374556303\n",
      "fc.bias: Gradiente médio 0.07516820728778839\n",
      "fc_intermediate.weight: Gradiente médio 0.24129289388656616\n",
      "fc_intermediate.bias: Gradiente médio 0.4591022729873657\n",
      "Epoch 26 Batch 2/9 Loss: 0.5261\n",
      "fc.weight: Gradiente médio 0.012650699354708195\n",
      "fc.bias: Gradiente médio 0.09708546102046967\n",
      "fc_intermediate.weight: Gradiente médio 0.24222932755947113\n",
      "fc_intermediate.bias: Gradiente médio 0.4609789252281189\n",
      "Epoch 26 Batch 3/9 Loss: 0.4022\n",
      "fc.weight: Gradiente médio 0.005533464252948761\n",
      "fc.bias: Gradiente médio 0.02255229651927948\n",
      "fc_intermediate.weight: Gradiente médio 0.2443009912967682\n",
      "fc_intermediate.bias: Gradiente médio 0.46549370884895325\n",
      "Epoch 26 Batch 4/9 Loss: 0.4290\n",
      "fc.weight: Gradiente médio 0.006223832257091999\n",
      "fc.bias: Gradiente médio 0.0445159450173378\n",
      "fc_intermediate.weight: Gradiente médio 0.24601799249649048\n",
      "fc_intermediate.bias: Gradiente médio 0.46908479928970337\n",
      "Epoch 26 Batch 5/9 Loss: 0.5271\n",
      "fc.weight: Gradiente médio 0.004889213014394045\n",
      "fc.bias: Gradiente médio 0.021689485758543015\n",
      "fc_intermediate.weight: Gradiente médio 0.2475230097770691\n",
      "fc_intermediate.bias: Gradiente médio 0.4718140959739685\n",
      "Epoch 26 Batch 6/9 Loss: 0.4658\n",
      "fc.weight: Gradiente médio 0.00906439870595932\n",
      "fc.bias: Gradiente médio 0.06793361157178879\n",
      "fc_intermediate.weight: Gradiente médio 0.2486242651939392\n",
      "fc_intermediate.bias: Gradiente médio 0.4745914936065674\n",
      "Epoch 26 Batch 7/9 Loss: 0.3323\n",
      "fc.weight: Gradiente médio 0.003566563595086336\n",
      "fc.bias: Gradiente médio 0.002032458782196045\n",
      "fc_intermediate.weight: Gradiente médio 0.2501952350139618\n",
      "fc_intermediate.bias: Gradiente médio 0.4775063693523407\n",
      "Epoch 26 Batch 8/9 Loss: 0.4417\n",
      "fc.weight: Gradiente médio 0.005126971751451492\n",
      "fc.bias: Gradiente médio 0.014567501842975616\n",
      "fc_intermediate.weight: Gradiente médio 0.2510733902454376\n",
      "fc_intermediate.bias: Gradiente médio 0.4782368540763855\n",
      "Epoch 26 Batch 9/9 Loss: 0.4375\n",
      "Epoch 26 Training Loss: 0.4562\n",
      "fc.weight: Gradiente médio 0.003962043207138777\n",
      "fc.bias: Gradiente médio 0.008572304621338844\n",
      "fc_intermediate.weight: Gradiente médio 0.25225624442100525\n",
      "fc_intermediate.bias: Gradiente médio 0.47915899753570557\n",
      "Epoch 27 Batch 1/9 Loss: 0.5079\n",
      "fc.weight: Gradiente médio 0.007056175731122494\n",
      "fc.bias: Gradiente médio 0.05255436897277832\n",
      "fc_intermediate.weight: Gradiente médio 0.2540447413921356\n",
      "fc_intermediate.bias: Gradiente médio 0.48275619745254517\n",
      "Epoch 27 Batch 2/9 Loss: 0.4844\n",
      "fc.weight: Gradiente médio 0.012134715914726257\n",
      "fc.bias: Gradiente médio 0.09595143795013428\n",
      "fc_intermediate.weight: Gradiente médio 0.2556512951850891\n",
      "fc_intermediate.bias: Gradiente médio 0.4873362183570862\n",
      "Epoch 27 Batch 3/9 Loss: 0.4519\n",
      "fc.weight: Gradiente médio 0.005604242905974388\n",
      "fc.bias: Gradiente médio 0.03416883945465088\n",
      "fc_intermediate.weight: Gradiente médio 0.2577051818370819\n",
      "fc_intermediate.bias: Gradiente médio 0.4908455014228821\n",
      "Epoch 27 Batch 4/9 Loss: 0.4329\n",
      "fc.weight: Gradiente médio 0.003705251030623913\n",
      "fc.bias: Gradiente médio 0.0033371038734912872\n",
      "fc_intermediate.weight: Gradiente médio 0.25927066802978516\n",
      "fc_intermediate.bias: Gradiente médio 0.4927331805229187\n",
      "Epoch 27 Batch 5/9 Loss: 0.4885\n",
      "fc.weight: Gradiente médio 0.003874256042763591\n",
      "fc.bias: Gradiente médio 0.004484986886382103\n",
      "fc_intermediate.weight: Gradiente médio 0.26037997007369995\n",
      "fc_intermediate.bias: Gradiente médio 0.4934907555580139\n",
      "Epoch 27 Batch 6/9 Loss: 0.4516\n",
      "fc.weight: Gradiente médio 0.003974136896431446\n",
      "fc.bias: Gradiente médio 9.442493319511414e-05\n",
      "fc_intermediate.weight: Gradiente médio 0.26158249378204346\n",
      "fc_intermediate.bias: Gradiente médio 0.49598002433776855\n",
      "Epoch 27 Batch 7/9 Loss: 0.4205\n",
      "fc.weight: Gradiente médio 0.0069203185848891735\n",
      "fc.bias: Gradiente médio 0.04645179212093353\n",
      "fc_intermediate.weight: Gradiente médio 0.2634690999984741\n",
      "fc_intermediate.bias: Gradiente médio 0.5009239315986633\n",
      "Epoch 27 Batch 8/9 Loss: 0.4240\n",
      "fc.weight: Gradiente médio 0.00846533477306366\n",
      "fc.bias: Gradiente médio 0.04890723153948784\n",
      "fc_intermediate.weight: Gradiente médio 0.26425087451934814\n",
      "fc_intermediate.bias: Gradiente médio 0.5008466839790344\n",
      "Epoch 27 Batch 9/9 Loss: 0.4257\n",
      "Epoch 27 Training Loss: 0.4541\n",
      "fc.weight: Gradiente médio 0.01174499187618494\n",
      "fc.bias: Gradiente médio 0.09109669923782349\n",
      "fc_intermediate.weight: Gradiente médio 0.2652391791343689\n",
      "fc_intermediate.bias: Gradiente médio 0.5043079853057861\n",
      "Epoch 28 Batch 1/9 Loss: 0.4634\n",
      "fc.weight: Gradiente médio 0.0037541035562753677\n",
      "fc.bias: Gradiente médio 0.0012518921867012978\n",
      "fc_intermediate.weight: Gradiente médio 0.2669844925403595\n",
      "fc_intermediate.bias: Gradiente médio 0.5072563290596008\n",
      "Epoch 28 Batch 2/9 Loss: 0.4424\n",
      "fc.weight: Gradiente médio 0.0032772717531770468\n",
      "fc.bias: Gradiente médio 0.0035778547171503305\n",
      "fc_intermediate.weight: Gradiente médio 0.2683868706226349\n",
      "fc_intermediate.bias: Gradiente médio 0.5096685886383057\n",
      "Epoch 28 Batch 3/9 Loss: 0.4164\n",
      "fc.weight: Gradiente médio 0.004070565570145845\n",
      "fc.bias: Gradiente médio 0.016495008021593094\n",
      "fc_intermediate.weight: Gradiente médio 0.2693878412246704\n",
      "fc_intermediate.bias: Gradiente médio 0.5114396810531616\n",
      "Epoch 28 Batch 4/9 Loss: 0.4174\n",
      "fc.weight: Gradiente médio 0.007416211999952793\n",
      "fc.bias: Gradiente médio 0.039997637271881104\n",
      "fc_intermediate.weight: Gradiente médio 0.2716037929058075\n",
      "fc_intermediate.bias: Gradiente médio 0.5154637694358826\n",
      "Epoch 28 Batch 5/9 Loss: 0.4851\n",
      "fc.weight: Gradiente médio 0.006722159683704376\n",
      "fc.bias: Gradiente médio 0.04673752561211586\n",
      "fc_intermediate.weight: Gradiente médio 0.27339646220207214\n",
      "fc_intermediate.bias: Gradiente médio 0.5180415511131287\n",
      "Epoch 28 Batch 6/9 Loss: 0.3929\n",
      "fc.weight: Gradiente médio 0.009513077326118946\n",
      "fc.bias: Gradiente médio 0.07173334062099457\n",
      "fc_intermediate.weight: Gradiente médio 0.274755597114563\n",
      "fc_intermediate.bias: Gradiente médio 0.5202136635780334\n",
      "Epoch 28 Batch 7/9 Loss: 0.5306\n",
      "fc.weight: Gradiente médio 0.014575526118278503\n",
      "fc.bias: Gradiente médio 0.10898575186729431\n",
      "fc_intermediate.weight: Gradiente médio 0.27718526124954224\n",
      "fc_intermediate.bias: Gradiente médio 0.5261540412902832\n",
      "Epoch 28 Batch 8/9 Loss: 0.4687\n",
      "fc.weight: Gradiente médio 0.017637593671679497\n",
      "fc.bias: Gradiente médio 0.12845158576965332\n",
      "fc_intermediate.weight: Gradiente médio 0.28003036975860596\n",
      "fc_intermediate.bias: Gradiente médio 0.531846821308136\n",
      "Epoch 28 Batch 9/9 Loss: 0.5682\n",
      "Epoch 28 Training Loss: 0.4650\n",
      "fc.weight: Gradiente médio 0.004997297190129757\n",
      "fc.bias: Gradiente médio 0.0333624891936779\n",
      "fc_intermediate.weight: Gradiente médio 0.2809297442436218\n",
      "fc_intermediate.bias: Gradiente médio 0.5324684977531433\n",
      "Epoch 29 Batch 1/9 Loss: 0.4215\n",
      "fc.weight: Gradiente médio 0.01266055554151535\n",
      "fc.bias: Gradiente médio 0.09900354593992233\n",
      "fc_intermediate.weight: Gradiente médio 0.28345921635627747\n",
      "fc_intermediate.bias: Gradiente médio 0.5394953489303589\n",
      "Epoch 29 Batch 2/9 Loss: 0.5458\n",
      "fc.weight: Gradiente médio 0.01114930585026741\n",
      "fc.bias: Gradiente médio 0.08438850194215775\n",
      "fc_intermediate.weight: Gradiente médio 0.2843569815158844\n",
      "fc_intermediate.bias: Gradiente médio 0.5411969423294067\n",
      "Epoch 29 Batch 3/9 Loss: 0.3502\n",
      "fc.weight: Gradiente médio 0.016047408804297447\n",
      "fc.bias: Gradiente médio 0.12617716193199158\n",
      "fc_intermediate.weight: Gradiente médio 0.2852565050125122\n",
      "fc_intermediate.bias: Gradiente médio 0.5425559878349304\n",
      "Epoch 29 Batch 4/9 Loss: 0.4640\n",
      "fc.weight: Gradiente médio 0.009320978075265884\n",
      "fc.bias: Gradiente médio 0.06808356195688248\n",
      "fc_intermediate.weight: Gradiente médio 0.28643494844436646\n",
      "fc_intermediate.bias: Gradiente médio 0.5431334972381592\n",
      "Epoch 29 Batch 5/9 Loss: 0.5069\n",
      "fc.weight: Gradiente médio 0.01617148332297802\n",
      "fc.bias: Gradiente médio 0.1312180459499359\n",
      "fc_intermediate.weight: Gradiente médio 0.2876393496990204\n",
      "fc_intermediate.bias: Gradiente médio 0.5467520356178284\n",
      "Epoch 29 Batch 6/9 Loss: 0.4540\n",
      "fc.weight: Gradiente médio 0.0039005514699965715\n",
      "fc.bias: Gradiente médio 0.00702389283105731\n",
      "fc_intermediate.weight: Gradiente médio 0.2888859808444977\n",
      "fc_intermediate.bias: Gradiente médio 0.5460164546966553\n",
      "Epoch 29 Batch 7/9 Loss: 0.5418\n",
      "fc.weight: Gradiente médio 0.007117672823369503\n",
      "fc.bias: Gradiente médio 0.04848342016339302\n",
      "fc_intermediate.weight: Gradiente médio 0.28991374373435974\n",
      "fc_intermediate.bias: Gradiente médio 0.5478969812393188\n",
      "Epoch 29 Batch 8/9 Loss: 0.4625\n",
      "fc.weight: Gradiente médio 0.008306534960865974\n",
      "fc.bias: Gradiente médio 0.040480613708496094\n",
      "fc_intermediate.weight: Gradiente médio 0.2922816872596741\n",
      "fc_intermediate.bias: Gradiente médio 0.5533851385116577\n",
      "Epoch 29 Batch 9/9 Loss: 0.3683\n",
      "Epoch 29 Training Loss: 0.4572\n",
      "fc.weight: Gradiente médio 0.003128495067358017\n",
      "fc.bias: Gradiente médio 0.006128106266260147\n",
      "fc_intermediate.weight: Gradiente médio 0.29366737604141235\n",
      "fc_intermediate.bias: Gradiente médio 0.5571825504302979\n",
      "Epoch 30 Batch 1/9 Loss: 0.4186\n",
      "fc.weight: Gradiente médio 0.005418206565082073\n",
      "fc.bias: Gradiente médio 0.03323224186897278\n",
      "fc_intermediate.weight: Gradiente médio 0.2951990067958832\n",
      "fc_intermediate.bias: Gradiente médio 0.5612647533416748\n",
      "Epoch 30 Batch 2/9 Loss: 0.3762\n",
      "fc.weight: Gradiente médio 0.00348267937079072\n",
      "fc.bias: Gradiente médio 0.003195425495505333\n",
      "fc_intermediate.weight: Gradiente médio 0.2968558073043823\n",
      "fc_intermediate.bias: Gradiente médio 0.5630949139595032\n",
      "Epoch 30 Batch 3/9 Loss: 0.5094\n",
      "fc.weight: Gradiente médio 0.007031508721411228\n",
      "fc.bias: Gradiente médio 0.041727617383003235\n",
      "fc_intermediate.weight: Gradiente médio 0.29918304085731506\n",
      "fc_intermediate.bias: Gradiente médio 0.5663533210754395\n",
      "Epoch 30 Batch 4/9 Loss: 0.5358\n",
      "fc.weight: Gradiente médio 0.0055352081544697285\n",
      "fc.bias: Gradiente médio 0.03594112768769264\n",
      "fc_intermediate.weight: Gradiente médio 0.3003096282482147\n",
      "fc_intermediate.bias: Gradiente médio 0.5692954659461975\n",
      "Epoch 30 Batch 5/9 Loss: 0.3696\n",
      "fc.weight: Gradiente médio 0.005714458879083395\n",
      "fc.bias: Gradiente médio 0.035037338733673096\n",
      "fc_intermediate.weight: Gradiente médio 0.3022087514400482\n",
      "fc_intermediate.bias: Gradiente médio 0.5713238716125488\n",
      "Epoch 30 Batch 6/9 Loss: 0.5172\n",
      "fc.weight: Gradiente médio 0.0041400534100830555\n",
      "fc.bias: Gradiente médio 0.004483308643102646\n",
      "fc_intermediate.weight: Gradiente médio 0.3037162125110626\n",
      "fc_intermediate.bias: Gradiente médio 0.5734422206878662\n",
      "Epoch 30 Batch 7/9 Loss: 0.3862\n",
      "fc.weight: Gradiente médio 0.003802505787461996\n",
      "fc.bias: Gradiente médio 0.0009161978960037231\n",
      "fc_intermediate.weight: Gradiente médio 0.3053136169910431\n",
      "fc_intermediate.bias: Gradiente médio 0.5761549472808838\n",
      "Epoch 30 Batch 8/9 Loss: 0.4559\n",
      "fc.weight: Gradiente médio 0.010103398934006691\n",
      "fc.bias: Gradiente médio 0.06881854683160782\n",
      "fc_intermediate.weight: Gradiente médio 0.3062334954738617\n",
      "fc_intermediate.bias: Gradiente médio 0.5787160396575928\n",
      "Epoch 30 Batch 9/9 Loss: 0.5486\n",
      "Epoch 30 Training Loss: 0.4575\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs): \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(dataloader_train, 1):\n",
    "        images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "               print(f\"{name}: Gradiente médio {param.grad.abs().mean()}\")\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_labels.append(labels)\n",
    "        all_predictions.append(output)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Batch {batch_idx}/{len(dataloader_train)} Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {total_loss / len(dataloader_train):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5518\n",
      "Validation Accuracy: 0.7436\n",
      "Validation Precision: 0.7121\n",
      "Validation Recall: 0.7436\n",
      "Validation F1 Score: 0.6805\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "val_labels = []\n",
    "val_predictions = []\n",
    "\n",
    "model.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_eval:\n",
    "        images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        val_labels.append(labels)\n",
    "        val_predictions.append(output)\n",
    "\n",
    "val_labels = torch.cat(val_labels)\n",
    "val_predictions = torch.cat(val_predictions)\n",
    "val_accuracy = accuracy_score(val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy())\n",
    "val_precision = precision_score(val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(), average=\"weighted\", zero_division=0)\n",
    "val_recall = recall_score(val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(), average=\"weighted\", zero_division=0)\n",
    "val_f1 = f1_score(val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(), average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss / len(dataloader_eval):.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Evaluation:\n",
      "Test Loss: 0.5188\n",
      "Test Accuracy: 0.7244\n",
      "Test Precision: 0.6667\n",
      "Test Recall: 0.7244\n",
      "Test F1 Score: 0.6602\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_labels.append(labels)\n",
    "        test_predictions.append(output)\n",
    "\n",
    "test_labels = torch.cat(test_labels)\n",
    "test_predictions = torch.cat(test_predictions)\n",
    "test_accuracy = accuracy_score(test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy())\n",
    "test_precision = precision_score(test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), average=\"weighted\", zero_division=0)\n",
    "test_recall = recall_score(test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), average=\"weighted\", zero_division=0)\n",
    "test_f1 = f1_score(test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"\\nFinal Test Evaluation:\")\n",
    "print(f\"Test Loss: {test_loss / len(dataloader_test):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), labels=[0, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantumEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
